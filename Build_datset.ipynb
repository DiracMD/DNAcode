{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(file_dir):\n",
    "    fire = []\n",
    "    label_fire = []\n",
    "    soil = []\n",
    "    label_soil = []\n",
    "    #tree = []\n",
    "    #label_tree = []\n",
    "    #water = []\n",
    "    #label_water = []\n",
    "    \n",
    "    for file in os.listdir(file_dir+'/fire'):\n",
    "        fire.append(file_dir +'/fire'+'/'+ file)\n",
    "        label_fire.append(0)     #fire, soil, tree, water\n",
    "    for file in os.listdir(file_dir+'/soil'):\n",
    "        soil.append(file_dir +'/soil'+'/'+file)\n",
    "        label_soil.append(1)\n",
    "    image_list = np.hstack((fire,soil))\n",
    "    label_list = np.hstack((label_fire, label_soil))\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(float(i)) for i in label_list]\n",
    "    return image_list,label_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for file in os.listdir(file_dir+'/tree'):\n",
    "        soil.append(file_dir +'/tree'+'/'+file)\n",
    "        label_soil.append(2)\n",
    "    for file in os.listdir(file_dir+'/water'):\n",
    "        soil.append(file_dir +'/water'+'/'+file)\n",
    "        label_water.append(3)    #\n",
    "    image_list = np.hstack((fire,soil,tree,water))\n",
    "    label_list = np.hstack((label_fire, label_soil,label_tree,label_water))\n",
    "    \n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(float(i)) for i in label_list]\n",
    "    return image_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir='./fsNPY'\n",
    "image_list,label_list = get_files(train_dir)\n",
    "print(len(image_list))\n",
    "print(len(label_list))\n",
    "np.load(image_list[1]).shape\n",
    "#np.array(label_list[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10, 10)\n",
      "(1600, 1)\n"
     ]
    }
   ],
   "source": [
    "Train_image =  np.random.rand(len(image_list)-400,10,10)\n",
    "#.astype('float32')\n",
    "#Train_image = np.expand_dims(Train_image,axis=4)\n",
    "Train_label = np.random.rand(len(image_list)-400,1)\n",
    "#.astype('float32')\n",
    " \n",
    "Test_image =  np.random.rand(400, 10, 10)\n",
    "#.astype('float32')\n",
    "Test_label = np.random.rand(400,1)\n",
    "#.astype('float32')\n",
    "print(Train_image.shape)\n",
    "print(Train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10, 10, 1)\n",
      "(400, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_list)-400):\n",
    "    Train_image[i] = np.load(image_list[i])\n",
    "    Train_label[i] = np.array(label_list[i])\n",
    "Train_image = np.expand_dims(Train_image,axis=3)\n",
    "for i in range(len(image_list)-400, len(image_list)):\n",
    "    Test_image[i+400-len(image_list)] = np.load(image_list[i])\n",
    "    Test_label[i+400-len(image_list)] = np.array(label_list[i])\n",
    "Test_image = np.expand_dims(Test_image,axis=3)\n",
    "print(Train_image.shape)\n",
    "print(Test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('fsNPY.h5','w')\n",
    "f.create_dataset('x_train',data=Train_image)\n",
    "f.create_dataset('y_train',data=Train_label)\n",
    "f.create_dataset('x_test',data=Test_image)\n",
    "f.create_dataset('y_test',data=Test_label)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('2008.h5','r')\n",
    "train_set_x_orig = np.array(train_dataset['x_train'])\n",
    "train_set_y_orig = np.array(train_dataset['y_train'])\n",
    "test_set_x_orig = np.array(train_dataset['x_test'])\n",
    "test_set_y_orig = np.array(train_dataset['y_test'])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"east\",train_set_x_orig[1])\n",
    "#print(train_set_x_orig[1].shape)\n",
    "#y = np.squeeze(train_set_x_orig[45])\n",
    "#y.shape\n",
    "#np.savetxt(\"east\",y)\n",
    "#print(train_set_x_orig.max())\n",
    "#print(train_set_y_orig.max())\n",
    "\n",
    "#print(test_set_x_orig.shape)\n",
    "#print(test_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(train_set_x_orig[10])\n",
    "x=np.array(train_set_y_orig[2])\n",
    "np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
