{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "#from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout,GlobalMaxPool2D,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#inputshape=(height,width,deep)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import h5py\n",
    "import os \n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import numpy as np\n",
    "import PIL.ImageOps\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File(\"numbers_dataset_20200720-6.h5\",'r')\n",
    "X_train = np.array(train_dataset['x_train'][:])\n",
    "Y_train = np.array(train_dataset['y_train'][:])\n",
    "X_test = np.array(train_dataset['x_test'][:])\n",
    "Y_test = np.array(train_dataset['y_test'][:])\n",
    "train_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"]\n",
    "print(len(X_train))\n",
    "for i in range(64):\n",
    "    print(np.squeeze(X_train[i]),np.sum(X_train[i]==1))\n",
    "    print(class_names[int(Y_train[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of traning examples = \"+str(X_train.shape[0]))\n",
    "print(\"number of test examples = \"+str(X_test.shape[0]))\n",
    "print(\"X_train shape:\" + str(X_train.shape))\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))\n",
    "train_data=(X_train,Y_train)\n",
    "test_data=(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model\n",
    "def Pimodel(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    X=ZeroPadding2D(padding=(1,1))(X_input)\n",
    "    X=Conv2D(1,kernel_size=(3,6),strides=(3,6),use_bias=None)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    #X=Conv2D(1,kernel_size=(2,3),strides=(2,2))(X)\n",
    "    #X=Activation(\"sigmoid\")(X)\n",
    "    X=Flatten()(X)\n",
    "    Y=Activation('softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=Y,name=\"JSmodel\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel = Pimodel((10,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "picmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.0),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "picmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=picmodel.fit(x=X_train,y=Y_train,batch_size=80,epochs=150,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = picmodel.evaluate(x=X_test,y=Y_test)\n",
    "\n",
    "print('Test Loss=' + str(preds[0]))\n",
    "print(\"Test Accuracy =\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim((0, 1)) # Uncomment this when showing you model for pay raise\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(\"accuary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.load(\"./10dataset/eight/8-0.npy\")\n",
    "x=np.expand_dims(arr,axis=0)\n",
    "x=np.expand_dims(x,axis=3)\n",
    "print(picmodel.predict(x))\n",
    "class_names[np.argmax(picmodel.predict(x))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "picmodel.save(\"numbers_model_20200714.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel = load_model(\"./numbers_model_20200714.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def get_layer_output(model,x,index=-1):\n",
    "    layer = K.function([model.input],[model.layers[index].output])\n",
    "    return layer([x])[0]\n",
    "input_y=np.load(\"./dataset3/four/4-10952.npy\")\n",
    "input_x = np.expand_dims(input_y,axis=0)\n",
    "input_x = np.expand_dims(input_x,axis=3)\n",
    "layer_0 = get_layer_output(picmodel,input_x,index=0)\n",
    "layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "print(np.squeeze(layer_0))\n",
    "print(np.squeeze(layer_1))\n",
    "print(np.squeeze(layer_2))\n",
    "print(np.squeeze(layer_3))\n",
    "print(np.squeeze(layer_4))\n",
    "print(np.squeeze(layer_5))\n",
    "class_names[np.argmax(picmodel.predict(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_weights=np.squeeze(picmodel.get_weights())\n",
    "#print(kernel_weights.flatten())\n",
    "a1=np.squeeze(kernel_weights)[0:3,0:6].flatten()\n",
    "print(kernel_weights)\n",
    "N=abs(a1.flatten())[np.argmax(abs(a1.flatten()))]\n",
    "print(N)\n",
    "a1_nor=a1.flatten()/N\n",
    "print(a1_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the layer output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy\n",
    "import random\n",
    "import os,sys\n",
    "def get_layer_output(model,x,index=0):\n",
    "    layer = K.function([model.input],[model.layers[index].output])\n",
    "    return layer([x])[0]\n",
    "path=\"./dataset3/one/\"\n",
    "imlist=os.listdir(path)\n",
    "#rlist=random.sample(imlist,1000)\n",
    "one_t=[]\n",
    "One_t=[]\n",
    "fn_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./dataset/one/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/one/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    one_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"one\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        fn_t.append(FN_t)\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        One_t.append(elef) \n",
    "one1=collections.Counter(one_t)\n",
    "print(len(one_t),collections.Counter(one_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(One_t,1000):\n",
    "    print(elef)\n",
    "    input_x=np.load(\"./dataset2/one/\"+elef)\n",
    "    input_y=input_x.flatten()\n",
    "    index1=np.argwhere(input_y==1)\n",
    "    index2=index1.flatten()\n",
    "    input_y[np.random.choice(index2,1)]=0\n",
    "    inputy1=input_y.reshape(10,10)\n",
    "    #np.save(\"P2\"+elef,inputy1)\n",
    "    np.save(elef,input_x)\n",
    "    print(input_x)\n",
    "    #print(inputy1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def takesecond(elem):\n",
    "    return elem[1][0]\n",
    "fn_t.sort(key=takesecond,reverse=True)\n",
    "train=[]\n",
    "for i in fn_t:\n",
    "    #print(i)\n",
    "    if i[1][0]>0:\n",
    "        train.append(i[0])\n",
    "print(len(train))\n",
    "for i in train:\n",
    "    print(i)\n",
    "for elef in train:\n",
    "    im=Image.fromarray(np.load(\"./dataset/one/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    print(input_y)\n",
    "    np.save(elef,input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset2/two/\"\n",
    "imlist=os.listdir(path)\n",
    "#rlist=random.sample(imlist,1000)\n",
    "two_t=[]\n",
    "Two_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/two/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset2/two/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    two_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"two\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Two_t.append(elef)\n",
    "two1=collections.Counter(two_t)\n",
    "print(len(two_t),collections.Counter(two_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Two_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/two/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Two_t,238):\n",
    "    #print(elef)\n",
    "    input_x=np.load(\"./10dataset/two/\"+elef)\n",
    "    input_y=input_x.flatten()\n",
    "    index1=np.argwhere(input_y==1)\n",
    "    index2=index1.flatten()\n",
    "    input_y[np.random.choice(index2,1)]=0\n",
    "    inputy1=input_y.reshape(10,10)\n",
    "    np.save(\"P1-\"+elef,inputy1)\n",
    "    print(input_x)\n",
    "    print(inputy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/three/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "three_t=[]\n",
    "Three_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/three/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/three/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    three_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"three\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Three_t.append(elef)\n",
    "three1=collections.Counter(three_t)\n",
    "print(len(three_t),collections.Counter(three_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Three_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/three/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/four/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "four_t=[]\n",
    "Four_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/four/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/four/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    four_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"four\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Four_t.append(elef)\n",
    "four1=collections.Counter(four_t)\n",
    "print(len(four_t),collections.Counter(four_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Four_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/four/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/five/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "five_t=[]\n",
    "Five_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/five/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/five/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    five_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"five\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Five_t.append(elef)\n",
    "five1=collections.Counter(five_t)\n",
    "print(len(five_t),collections.Counter(five_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Five_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/five/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/six/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "six_t=[]\n",
    "Six_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/six/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/six/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    six_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"six\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Six_t.append(elef)\n",
    "six1=collections.Counter(six_t)\n",
    "print(len(six_t),collections.Counter(six_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in random.sample(Six_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/six/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/seven/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "seven_t=[]\n",
    "Seven_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./newdataset/seven/\"+elef))\n",
    "    im=PIL.ImageOps.invert(im)\n",
    "    im2=im.resize((10,10))\n",
    "    L=np.array(im2).flatten()\n",
    "    for i in range(100):\n",
    "        if L[i]>200:\n",
    "            L[i]=0\n",
    "        else:\n",
    "            L[i]=1\n",
    "    input_y=np.array(L).reshape(10,10)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/seven/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    seven_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"seven\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Seven_t.append(elef)\n",
    "seven1=collections.Counter(three_t)\n",
    "print(len(seven_t),collections.Counter(seven_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for elef in random.sample(Seven_t,1000):\n",
    "    print(elef)\n",
    "    arr=np.load(\"./dataset/seven/\"+elef)\n",
    "    np.save(elef,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./dataset3/eight/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "eight_t=[]\n",
    "Eight_t=[]\n",
    "for elef in imlist:\n",
    "    \"\"\"\n",
    "    im=Image.fromarray(np.load(\"./dataset/eight/\"+elef))\n",
    "    imt=im.resize((10,10))\n",
    "    arr=np.array(imt)\n",
    "    input_y=np.where(arr<1,arr,1)\n",
    "    \"\"\"\n",
    "    input_y=np.load(\"./dataset3/eight/\"+elef)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    eight_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"eight\":\n",
    "        print(elef,layer_4,class_names[np.argmax(layer_5)])\n",
    "        Eight_t.append(elef)\n",
    "eight1=collections.Counter(eight_t)\n",
    "print(len(eight_t),collections.Counter(eight_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for elef in Eight_t:\n",
    "    print(elef)\n",
    "    input_x=np.load(\"./dataset2/eight/\"+elef)\n",
    "    input_y=input_x.flatten()\n",
    "    index1=np.argwhere(input_y==1)\n",
    "    index2=index1.flatten()\n",
    "    input_y[np.random.choice(index2,1)]=0\n",
    "    inputy1=input_y.reshape(10,10)\n",
    "    np.save(\"P2\"+elef,inputy1)\n",
    "    #np.save(elef,input_x)\n",
    "    print(input_x)\n",
    "    print(inputy1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path=\"./dataset/nine/\"\n",
    "imlist=os.listdir(path)\n",
    "rmlist=random.sample(imlist,1000)\n",
    "nine_t=[]\n",
    "Nine_t=[]\n",
    "for elef in imlist:\n",
    "    im=Image.fromarray(np.load(\"./dataset/nine/\"+elef))\n",
    "    imt=im.resize((10,10))\n",
    "    arr=np.array(imt)\n",
    "    input_y=np.where(arr<1,arr,1)\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    nine_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"eight\":\n",
    "        print(elef,layer_5,class_names[np.argmax(layer_5)])\n",
    "        Nine_t.append(elef)\n",
    "nine1=collections.Counter(nine_t)\n",
    "print(len(nine_t),collections.Counter(nine_t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ele in Life_T:\n",
    "    input_x = np.array(np.load(r\"./dataset_200426/life/\"+ele))\n",
    "    print(input_x,np.sum(input_x==1))\n",
    "    np.save(\"o\"+ele,input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dict1 = pd.DataFrame(pd.Series(f1),columns=[\"numbers\"],index=[\"fire\",\"soil\",\"water\",\"wood\",\"gas\",\"sky\",\"human\",\"life\"])\n",
    "x=[\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"]\n",
    "dict1=pd.Series(one1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict1=dict1.fillna(0)\n",
    "print(dict1)\n",
    "print(dict1.fillna(0))\n",
    "#dict1[np.squeeze(np.argwhere(np.isnan(dict1)))]=0\n",
    "\n",
    "dict2=pd.Series(two1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "#dict2[np.squeeze(np.argwhere(np.isnan(dict2)))]=0\n",
    "dict2=dict2.fillna(0)\n",
    "dict3=pd.Series(three1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict3=dict3.fillna(0)\n",
    "#dict3[np.squeeze(np.argwhere(np.isnan(dict3)))]=0\n",
    "dict4=pd.Series(four1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict4=dict4.fillna(0)\n",
    "#dict4[np.squeeze(np.argwhere(np.isnan(dict4)))]=0\n",
    "dict5=pd.Series(five1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict5=dict5.fillna(0)\n",
    "#dict5[np.squeeze(np.argwhere(np.isnan(dict5)))]=0\n",
    "dict6=pd.Series(six1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict6=dict6.fillna(0)\n",
    "#dict6[np.squeeze(np.argwhere(np.isnan(dict6)))]=0\n",
    "dict7=pd.Series(seven1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict7=dict7.fillna(0)\n",
    "#dict7[np.squeeze(np.argwhere(np.isnan(dict7)))]=0\n",
    "dict8=pd.Series(eight1).reindex([\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\"])\n",
    "dict8=dict8.fillna(0)\n",
    "#dict8[np.squeeze(np.argwhere(np.isnan(dict8)))]=0\n",
    "plt.figure(figsize=(24,10))\n",
    "plt.subplot(241)\n",
    "plt.bar(x,dict1,color=\"red\")\n",
    "plt.title(\"one regonition\")\n",
    "for i,j in zip(x, dict1):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(242)\n",
    "plt.bar(x,dict2,color=\"yellow\")\n",
    "plt.title(\"two regonition\")\n",
    "for i,j in zip(x, dict2):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict2)\n",
    "plt.subplot(243)\n",
    "plt.bar(x,dict3,color=\"brown\")\n",
    "plt.title(\"three regonition\")\n",
    "for i,j in zip(x, dict3):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(244)\n",
    "plt.bar(x,dict4,color=\"blue\")\n",
    "plt.title(\"four regonition\")\n",
    "for i,j in zip(x, dict4):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(245)\n",
    "plt.bar(x,dict5,color=\"green\")\n",
    "plt.title(\"five regonition\")\n",
    "for i,j in zip(x, dict5):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(246)\n",
    "plt.bar(x,dict6,color=\"orange\")\n",
    "plt.title(\"six regonition\")\n",
    "for i,j in zip(x, dict6):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(247)\n",
    "plt.bar(x,dict7,color=\"black\")\n",
    "plt.title(\"seven regonition\")\n",
    "for i,j in zip(x, dict7):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(248)\n",
    "plt.bar(x,dict8,color=\"purple\")\n",
    "plt.title(\"eight regonition\")\n",
    "for i,j in zip(x, dict8):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "#list1=dict1.values.tolist()\n",
    "plt.savefig(\"regonition.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
