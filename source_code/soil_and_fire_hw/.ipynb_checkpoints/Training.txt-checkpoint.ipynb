{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "#from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout,GlobalMaxPool2D,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#inputshape=(height,width,deep)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import h5py\n",
    "import os \n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File(\"./datasets_soilandfire_20200614.h5\",'r')\n",
    "X_train = np.array(train_dataset['x_train'][:])\n",
    "Y_train = np.array(train_dataset['y_train'][:])\n",
    "X_test = np.array(train_dataset['x_test'][:])\n",
    "Y_test = np.array(train_dataset['y_test'][:])\n",
    "train_dataset.close()\n",
    "#train_data= create_dataset(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"fire\",\"soil\"]\n",
    "print(len(X_train))\n",
    "for i in range(25):\n",
    "    print(np.squeeze(X_train[i]),np.sum(X_train[i]==1))\n",
    "    print(class_names[int(Y_train[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of traning examples = \"+str(X_train.shape[0]))\n",
    "print(\"number of test examples = \"+str(X_test.shape[0]))\n",
    "print(\"X_train shape:\" + str(X_train.shape))\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))\n",
    "train_data=(X_train,Y_train)\n",
    "test_data=(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model\n",
    "def Pimodel(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    X=ZeroPadding2D(padding=(1,1))(X_input)\n",
    "    X=Conv2D(1,kernel_size=(6,6),strides=(6,6),use_bias=None)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D(pool_size=(2,1))(X)\n",
    "    #X=Conv2D(1,kernel_size=(1,2),strides=(1,1),use_bias=None)(X)\n",
    "    X=Flatten()(X)\n",
    "    Y=Activation('softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=Y,name=\"JSmodel\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel = Pimodel((10,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "picmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.0),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "picmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=picmodel.fit(x=X_train,y=Y_train,batch_size=2000,epochs=300,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = picmodel.evaluate(x=X_test,y=Y_test)\n",
    "\n",
    "print('val Loss=' + str(preds[0]))\n",
    "print(picmodel.name+\"Accuracy=\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(history.history[\"accuracy\"])):\n",
    "    print(history.history[\"accuracy\"][i],history.history[\"val_accuracy\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Two-categrorical model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(['train accuracy', 'val accuracy'], loc='center right')\n",
    "plt.savefig(\"Two-categrorical_acc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(history.history[\"loss\"])):\n",
    "    print(history.history[\"loss\"][i],history.history[\"val_loss\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Two-categrorical model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'val loss'], loc='center right')\n",
    "plt.savefig(\"Two-categrorical_loss.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "picmodel.save(\"model_20200630_6x12_soilandfire_rotate.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bias=np.squeeze(picmodel.layers[2].get_weights()[1])\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output the model weight and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_weights=picmodel.layers[2].get_weights()\n",
    "for i in np.squeeze(kernel_weights):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def get_layer_output(model,x,index=-1):\n",
    "    layer = K.function([model.input],[model.layers[index].output])\n",
    "    return layer([x])[0]\n",
    "input_y=np.load(\"./datasets/fire/120DP2ooodataset_original_fire(7).png_74c3dbc8-bacc-4d3e-a265-598ba6179cd4.png.npy\")\n",
    "input_x = np.expand_dims(input_y,axis=0)\n",
    "input_x = np.expand_dims(input_x,axis=3)\n",
    "layer_0 = get_layer_output(picmodel,input_x,index=0)\n",
    "layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "print(np.squeeze(layer_0)\n",
    "print(np.squeeze(layer_1))\n",
    "print(np.squeeze(layer_2))\n",
    "print(np.squeeze(layer_3))\n",
    "print(np.squeeze(layer_4))\n",
    "print(np.squeeze(layer_5))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a1=np.squeeze(kernel_weights)[0:3,0:6].flatten()\n",
    "N=abs(a1.flatten())[np.argmax(abs(a1.flatten()))]\n",
    "print(N)\n",
    "a1_nor=a1.flatten()/N\n",
    "print(a1_nor)\n",
    "b00=np.squeeze(layer_1)[0:3,0:6].flatten()\n",
    "b01=np.squeeze(layer_1)[0:3,6:12].flatten()\n",
    "b10=np.squeeze(layer_1)[3:6,0:6].flatten()\n",
    "b11=np.squeeze(layer_1)[3:6,6:12].flatten()\n",
    "b20=np.squeeze(layer_1)[6:9,0:6].flatten()\n",
    "b21=np.squeeze(layer_1)[6:9,6:12].flatten()\n",
    "b30=np.squeeze(layer_1)[9:12,0:6].flatten()\n",
    "b31=np.squeeze(layer_1)[9:12,6:12].flatten()\n",
    "#print(b00)\n",
    "c=[]\n",
    "print(np.dot(a1_nor,b00))\n",
    "for i in range(18):\n",
    "    c.append(a1_nor[i]*b00[i])\n",
    "print(np.sum(c))\n",
    "#print(np.squeeze(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(picmodel.summary())\n",
    "for i in np.squeeze(kernel_weights):\n",
    "    print(i)\n",
    "\n",
    "kernel_weights=np.squeeze(picmodel.get_weights())\n",
    "a1=np.squeeze(kernel_weights)[0:12,0:6].flatten()\n",
    "print(a1)\n",
    "N=abs(a1.flatten())[np.argmax(abs(a1.flatten()))]\n",
    "print(N)\n",
    "a1_nor=a1.flatten()/N\n",
    "noraml_kernel_weights=(kernel_weights/N)\n",
    "for j in noraml_kernel_weights:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy\n",
    "import os,sys\n",
    "def get_layer_output(model,x,index=0):\n",
    "    layer = K.function([model.input],[model.layers[index].output])\n",
    "    return layer([x])[0]\n",
    "\n",
    "path=\"./datasets/fire/\"\n",
    "imlist=os.listdir(path)\n",
    "fire_t=[]\n",
    "Fire_t=[]\n",
    "fn_t=[]\n",
    "for elef in imlist:\n",
    "    input_x = np.array(np.load(r\"./datasets/fire/\"+elef))\n",
    "    input_x = np.expand_dims(input_x,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    fire_t.append(class_names[np.argmax(layer_4)])\n",
    "    if class_names[np.argmax(layer_4)]==\"fire\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        FN_t.append(layer_5.flatten())\n",
    "        fn_t.append(FN_t)\n",
    "\n",
    "f1=collections.Counter(fire_t)\n",
    "print(len(fire_t),collections.Counter(fire_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takesecond(elem):\n",
    "    return elem[1][0]\n",
    "fn_t.sort(key=takesecond,reverse=True)\n",
    "print(len(fn_t))\n",
    "for i in fn_t:\n",
    "    print(i[0])\n",
    "    print(i[1]/N)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path=\"./dataset/fire/\"\n",
    "imlist=os.listdir(path)\n",
    "for ele in Fire_t:\n",
    "    input_x = np.array(np.load(r\"./dataset/fire/\"+ele))\n",
    "    print(input_x,np.sum(input_x==1))\n",
    "    print(ele[0:4])\n",
    "    #np.save(ele,input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./datasets/soil/\"\n",
    "imlist=os.listdir(path)\n",
    "soil_T=[]\n",
    "Soil_T=[]\n",
    "sn_t=[]\n",
    "for elef in imlist:\n",
    "    input_x = np.array(np.load(r\"./datasets/soil/\"+elef))\n",
    "    input_x = np.expand_dims(input_x,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    #print(class_names[np.argmax(layer_6)])\n",
    "    soil_T.append(class_names[np.argmax(layer_4)])\n",
    "    if class_names[np.argmax(layer_4)]==\"soil\":\n",
    "        SN_t=[]\n",
    "        SN_t.append(elef)\n",
    "        SN_t.append(layer_2.flatten())\n",
    "        SN_t.append(layer_4.flatten())\n",
    "        sn_t.append(SN_t)\n",
    "        Soil_T.append(elef)\n",
    "print(len(soil_T))\n",
    "s1=collections.Counter(soil_T)\n",
    "print(collections.Counter(soil_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takesecond(elem):\n",
    "    return elem[0][1]\n",
    "sn_t.sort(key=takesecond,reverse=True)\n",
    "print(len(sn_t))\n",
    "for i in sn_t:\n",
    "    print(i[0])\n",
    "    print(i[1]/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set(style=\"darkgrid\")\n",
    "f2=dict(f1)\n",
    "print(f2)\n",
    "s2=dict(s1)\n",
    "print(s2)\n",
    "dict1=pd.Series(f1).reindex([\"fire\",\"soil\"])\n",
    "print(dict1.index)\n",
    "print(dict1.values)\n",
    "#print(sns.barplot(dict1.index,dict1.values))\n",
    "#print(dict1.plot.bar())\n",
    "dict2=pd.Series(s2).reindex([\"fire\",\"soil\"])\n",
    "print(sns.barplot(dict1.index,dict1.values))\n",
    "plt.title(\"fire recongnition\")\n",
    "plt.savefig(\"fire_rec.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
