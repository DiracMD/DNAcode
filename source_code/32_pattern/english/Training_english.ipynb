{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#alphabet training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import collections\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout,GlobalMaxPool2D,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import pydot\n",
    "import random\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from IPython.display import SVG\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File(\"english_dataset_20200725-1.h5\",'r')\n",
    "X_train = np.array(train_dataset['x_train'][:])\n",
    "Y_train = np.array(train_dataset['y_train'][:])\n",
    "X_test = np.array(train_dataset['x_test'][:])\n",
    "Y_test = np.array(train_dataset['y_test'][:])\n",
    "train_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:6400 test:1600\n"
     ]
    }
   ],
   "source": [
    "#the class name sequence is right; show the datasets contain diffent characters\n",
    "class_names=[\"B\",\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",]\n",
    "print(\"train:\"+str(len(X_train)),\"test:\"+str(len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of traning examples = 6400\n",
      "number of test examples = 1600\n",
      "X_train shape:(6400, 10, 10, 1)\n",
      "Y_train shape:(6400, 1)\n",
      "X_test shape:(1600, 10, 10, 1)\n",
      "Y_test shape:(1600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of traning examples = \"+str(X_train.shape[0]))\n",
    "print(\"number of test examples = \"+str(X_test.shape[0]))\n",
    "print(\"X_train shape:\" + str(X_train.shape))\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))\n",
    "train_data=(X_train,Y_train)\n",
    "test_data=(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pimodel(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    X=ZeroPadding2D(padding=(1,1))(X_input)\n",
    "    X=Conv2D(1,kernel_size=(3,6),strides=(3,6),use_bias=None)(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=Flatten()(X)\n",
    "    Y=Activation('softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=Y,name=\"JSmodel\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel = Pimodel((10,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.0),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"JSmodel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10, 10, 1)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 12, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 2, 1)           18        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "picmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.0417 - accuracy: 0.2425 - val_loss: 2.0268 - val_accuracy: 0.2981\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.3498 - val_loss: 1.9341 - val_accuracy: 0.4075\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8526 - accuracy: 0.4381 - val_loss: 1.7754 - val_accuracy: 0.4450\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7237 - accuracy: 0.4453 - val_loss: 1.6727 - val_accuracy: 0.4675\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.6382 - accuracy: 0.4700 - val_loss: 1.5986 - val_accuracy: 0.4938\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5717 - accuracy: 0.4978 - val_loss: 1.5367 - val_accuracy: 0.5356\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 0.5217 - val_loss: 1.4821 - val_accuracy: 0.5550\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.4637 - accuracy: 0.5398 - val_loss: 1.4325 - val_accuracy: 0.5638\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4169 - accuracy: 0.5566 - val_loss: 1.3875 - val_accuracy: 0.5781\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3741 - accuracy: 0.5708 - val_loss: 1.3458 - val_accuracy: 0.5975\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3343 - accuracy: 0.5906 - val_loss: 1.3073 - val_accuracy: 0.6175\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2976 - accuracy: 0.6045 - val_loss: 1.2716 - val_accuracy: 0.6325\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2634 - accuracy: 0.6181 - val_loss: 1.2382 - val_accuracy: 0.6469\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.6311 - val_loss: 1.2072 - val_accuracy: 0.6581\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2012 - accuracy: 0.6406 - val_loss: 1.1777 - val_accuracy: 0.6644\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1729 - accuracy: 0.6497 - val_loss: 1.1503 - val_accuracy: 0.6694\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1463 - accuracy: 0.6569 - val_loss: 1.1243 - val_accuracy: 0.6750\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1210 - accuracy: 0.6652 - val_loss: 1.1000 - val_accuracy: 0.6781\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0973 - accuracy: 0.6722 - val_loss: 1.0768 - val_accuracy: 0.6856\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0747 - accuracy: 0.6803 - val_loss: 1.0549 - val_accuracy: 0.7000\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0533 - accuracy: 0.6908 - val_loss: 1.0340 - val_accuracy: 0.7075\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.6972 - val_loss: 1.0141 - val_accuracy: 0.7194\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0134 - accuracy: 0.7073 - val_loss: 0.9952 - val_accuracy: 0.7300\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9949 - accuracy: 0.7184 - val_loss: 0.9770 - val_accuracy: 0.7337\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9771 - accuracy: 0.7242 - val_loss: 0.9596 - val_accuracy: 0.7419\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9600 - accuracy: 0.7353 - val_loss: 0.9430 - val_accuracy: 0.7475\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9436 - accuracy: 0.7384 - val_loss: 0.9270 - val_accuracy: 0.7500\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9280 - accuracy: 0.7423 - val_loss: 0.9117 - val_accuracy: 0.7556\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9129 - accuracy: 0.7445 - val_loss: 0.8970 - val_accuracy: 0.7556\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8983 - accuracy: 0.7480 - val_loss: 0.8828 - val_accuracy: 0.7600\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8843 - accuracy: 0.7528 - val_loss: 0.8689 - val_accuracy: 0.7600\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8708 - accuracy: 0.7553 - val_loss: 0.8557 - val_accuracy: 0.7638\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8576 - accuracy: 0.7589 - val_loss: 0.8428 - val_accuracy: 0.7700\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8449 - accuracy: 0.7628 - val_loss: 0.8304 - val_accuracy: 0.7725\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8327 - accuracy: 0.7661 - val_loss: 0.8183 - val_accuracy: 0.7744\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8207 - accuracy: 0.7708 - val_loss: 0.8066 - val_accuracy: 0.7812\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8092 - accuracy: 0.7741 - val_loss: 0.7952 - val_accuracy: 0.7844\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.7767 - val_loss: 0.7842 - val_accuracy: 0.7862\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7871 - accuracy: 0.7794 - val_loss: 0.7736 - val_accuracy: 0.7894\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7766 - accuracy: 0.7825 - val_loss: 0.7631 - val_accuracy: 0.7919\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.7828 - val_loss: 0.7530 - val_accuracy: 0.7937\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7564 - accuracy: 0.7852 - val_loss: 0.7431 - val_accuracy: 0.7969\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.7897 - val_loss: 0.7335 - val_accuracy: 0.8050\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7964 - val_loss: 0.7242 - val_accuracy: 0.8106\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.8022 - val_loss: 0.7151 - val_accuracy: 0.8156\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.8045 - val_loss: 0.7062 - val_accuracy: 0.8175\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7103 - accuracy: 0.8058 - val_loss: 0.6977 - val_accuracy: 0.8200\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.8078 - val_loss: 0.6892 - val_accuracy: 0.8231\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.8123 - val_loss: 0.6811 - val_accuracy: 0.8306\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.8136 - val_loss: 0.6730 - val_accuracy: 0.8325\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.8164 - val_loss: 0.6652 - val_accuracy: 0.8388\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.8191 - val_loss: 0.6575 - val_accuracy: 0.8375\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.8189 - val_loss: 0.6501 - val_accuracy: 0.8394\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.8233 - val_loss: 0.6429 - val_accuracy: 0.8388\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.8253 - val_loss: 0.6358 - val_accuracy: 0.8419\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.8278 - val_loss: 0.6287 - val_accuracy: 0.8456\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.8325 - val_loss: 0.6219 - val_accuracy: 0.8469\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.8344 - val_loss: 0.6152 - val_accuracy: 0.8481\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.8372 - val_loss: 0.6087 - val_accuracy: 0.8512\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.8384 - val_loss: 0.6023 - val_accuracy: 0.8512\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.8394 - val_loss: 0.5961 - val_accuracy: 0.8531\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.8413 - val_loss: 0.5899 - val_accuracy: 0.8550\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.8427 - val_loss: 0.5840 - val_accuracy: 0.8569\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.8461 - val_loss: 0.5781 - val_accuracy: 0.8581\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.8498 - val_loss: 0.5723 - val_accuracy: 0.8606\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.8511 - val_loss: 0.5666 - val_accuracy: 0.8612\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8516 - val_loss: 0.5611 - val_accuracy: 0.8619\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.8531 - val_loss: 0.5557 - val_accuracy: 0.8662\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.8548 - val_loss: 0.5504 - val_accuracy: 0.8662\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.8564 - val_loss: 0.5452 - val_accuracy: 0.8669\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8564 - val_loss: 0.5400 - val_accuracy: 0.8675\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8567 - val_loss: 0.5349 - val_accuracy: 0.8675\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.8577 - val_loss: 0.5300 - val_accuracy: 0.8675\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.8577 - val_loss: 0.5251 - val_accuracy: 0.8675\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8811 - val_loss: 0.5203 - val_accuracy: 0.8888\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8755 - val_loss: 0.5156 - val_accuracy: 0.8888\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.8867 - val_loss: 0.5110 - val_accuracy: 0.8925\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8880 - val_loss: 0.5065 - val_accuracy: 0.8944\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.8894 - val_loss: 0.5020 - val_accuracy: 0.8931\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8897 - val_loss: 0.4975 - val_accuracy: 0.8956\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8917 - val_loss: 0.4932 - val_accuracy: 0.8969\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8923 - val_loss: 0.4890 - val_accuracy: 0.8994\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8925 - val_loss: 0.4848 - val_accuracy: 0.9013\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8952 - val_loss: 0.4807 - val_accuracy: 0.9050\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8955 - val_loss: 0.4766 - val_accuracy: 0.9038\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8961 - val_loss: 0.4726 - val_accuracy: 0.9050\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.8966 - val_loss: 0.4687 - val_accuracy: 0.9056\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8967 - val_loss: 0.4648 - val_accuracy: 0.9056\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8967 - val_loss: 0.4610 - val_accuracy: 0.9062\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.8978 - val_loss: 0.4573 - val_accuracy: 0.9087\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.9005 - val_loss: 0.4536 - val_accuracy: 0.9094\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.9009 - val_loss: 0.4499 - val_accuracy: 0.9100\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.9017 - val_loss: 0.4463 - val_accuracy: 0.9100\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.9022 - val_loss: 0.4428 - val_accuracy: 0.9106\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.9020 - val_loss: 0.4393 - val_accuracy: 0.9106\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.9030 - val_loss: 0.4359 - val_accuracy: 0.9112\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.9036 - val_loss: 0.4325 - val_accuracy: 0.9112\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.9044 - val_loss: 0.4291 - val_accuracy: 0.9131\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.9045 - val_loss: 0.4258 - val_accuracy: 0.9144\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9058 - val_loss: 0.4225 - val_accuracy: 0.9150\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.9059 - val_loss: 0.4194 - val_accuracy: 0.9150\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.9072 - val_loss: 0.4162 - val_accuracy: 0.9150\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.9070 - val_loss: 0.4130 - val_accuracy: 0.9150\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.9091 - val_loss: 0.4100 - val_accuracy: 0.9194\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.9120 - val_loss: 0.4069 - val_accuracy: 0.9206\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.9153 - val_loss: 0.4039 - val_accuracy: 0.9212\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4095 - accuracy: 0.9158 - val_loss: 0.4010 - val_accuracy: 0.9219\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.9158 - val_loss: 0.3981 - val_accuracy: 0.9219\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.9167 - val_loss: 0.3951 - val_accuracy: 0.9237\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.9186 - val_loss: 0.3923 - val_accuracy: 0.9237\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.9214 - val_loss: 0.3895 - val_accuracy: 0.9256\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.9208 - val_loss: 0.3868 - val_accuracy: 0.9250\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.9206 - val_loss: 0.3841 - val_accuracy: 0.9250\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.9225 - val_loss: 0.3814 - val_accuracy: 0.9262\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.9233 - val_loss: 0.3787 - val_accuracy: 0.9281\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.9258 - val_loss: 0.3761 - val_accuracy: 0.9281\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.9252 - val_loss: 0.3735 - val_accuracy: 0.9294\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.9264 - val_loss: 0.3709 - val_accuracy: 0.9294\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.9278 - val_loss: 0.3683 - val_accuracy: 0.9325\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.9281 - val_loss: 0.3658 - val_accuracy: 0.9325\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.9281 - val_loss: 0.3634 - val_accuracy: 0.9331\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.9283 - val_loss: 0.3610 - val_accuracy: 0.9331\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.9287 - val_loss: 0.3585 - val_accuracy: 0.9344\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.9297 - val_loss: 0.3562 - val_accuracy: 0.9356\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.9297 - val_loss: 0.3538 - val_accuracy: 0.9369\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.9308 - val_loss: 0.3514 - val_accuracy: 0.9369\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.9330 - val_loss: 0.3492 - val_accuracy: 0.9375\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.9327 - val_loss: 0.3469 - val_accuracy: 0.9400\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.9348 - val_loss: 0.3447 - val_accuracy: 0.9400\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.9352 - val_loss: 0.3425 - val_accuracy: 0.9406\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.9316 - val_loss: 0.3403 - val_accuracy: 0.9362\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.9345 - val_loss: 0.3381 - val_accuracy: 0.9369\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.9314 - val_loss: 0.3360 - val_accuracy: 0.9356\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.9345 - val_loss: 0.3338 - val_accuracy: 0.9369\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.9350 - val_loss: 0.3317 - val_accuracy: 0.9388\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.9361 - val_loss: 0.3297 - val_accuracy: 0.9394\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.9361 - val_loss: 0.3277 - val_accuracy: 0.9388\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.9391 - val_loss: 0.3256 - val_accuracy: 0.9425\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.9402 - val_loss: 0.3236 - val_accuracy: 0.9413\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.9409 - val_loss: 0.3217 - val_accuracy: 0.9425\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.9413 - val_loss: 0.3197 - val_accuracy: 0.9425\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.9414 - val_loss: 0.3178 - val_accuracy: 0.9425\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.9420 - val_loss: 0.3159 - val_accuracy: 0.9450\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.9436 - val_loss: 0.3140 - val_accuracy: 0.9450\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.9441 - val_loss: 0.3121 - val_accuracy: 0.9450\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.9447 - val_loss: 0.3103 - val_accuracy: 0.9450\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.9448 - val_loss: 0.3084 - val_accuracy: 0.9456\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.9455 - val_loss: 0.3066 - val_accuracy: 0.9456\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.9452 - val_loss: 0.3049 - val_accuracy: 0.9456\n",
      "Epoch 150/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.9455 - val_loss: 0.3031 - val_accuracy: 0.9463\n",
      "Epoch 151/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.9466 - val_loss: 0.3014 - val_accuracy: 0.9475\n",
      "Epoch 152/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.9469 - val_loss: 0.2996 - val_accuracy: 0.9475\n",
      "Epoch 153/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.9467 - val_loss: 0.2979 - val_accuracy: 0.9481\n",
      "Epoch 154/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.9472 - val_loss: 0.2963 - val_accuracy: 0.9494\n",
      "Epoch 155/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.9472 - val_loss: 0.2946 - val_accuracy: 0.9500\n",
      "Epoch 156/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.9477 - val_loss: 0.2929 - val_accuracy: 0.9513\n",
      "Epoch 157/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9483 - val_loss: 0.2913 - val_accuracy: 0.9531\n",
      "Epoch 158/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9503 - val_loss: 0.2896 - val_accuracy: 0.9538\n",
      "Epoch 159/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9519 - val_loss: 0.2880 - val_accuracy: 0.9538\n",
      "Epoch 160/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9506 - val_loss: 0.2865 - val_accuracy: 0.9538\n",
      "Epoch 161/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.9503 - val_loss: 0.2849 - val_accuracy: 0.9544\n",
      "Epoch 162/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9511 - val_loss: 0.2834 - val_accuracy: 0.9550\n",
      "Epoch 163/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.9508 - val_loss: 0.2819 - val_accuracy: 0.9519\n",
      "Epoch 164/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.9506 - val_loss: 0.2803 - val_accuracy: 0.9544\n",
      "Epoch 165/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.9527 - val_loss: 0.2788 - val_accuracy: 0.9550\n",
      "Epoch 166/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.9522 - val_loss: 0.2773 - val_accuracy: 0.9550\n",
      "Epoch 167/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.9522 - val_loss: 0.2758 - val_accuracy: 0.9563\n",
      "Epoch 168/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9531 - val_loss: 0.2744 - val_accuracy: 0.9544\n",
      "Epoch 169/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9519 - val_loss: 0.2730 - val_accuracy: 0.9556\n",
      "Epoch 170/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.9531 - val_loss: 0.2715 - val_accuracy: 0.9569\n",
      "Epoch 171/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.9530 - val_loss: 0.2701 - val_accuracy: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.9514 - val_loss: 0.2688 - val_accuracy: 0.9538\n",
      "Epoch 173/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.9514 - val_loss: 0.2673 - val_accuracy: 0.9538\n",
      "Epoch 174/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9516 - val_loss: 0.2660 - val_accuracy: 0.9538\n",
      "Epoch 175/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.9544 - val_loss: 0.2646 - val_accuracy: 0.9550\n",
      "Epoch 176/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.9533 - val_loss: 0.2633 - val_accuracy: 0.9544\n",
      "Epoch 177/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.9536 - val_loss: 0.2619 - val_accuracy: 0.9544\n",
      "Epoch 178/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.9547 - val_loss: 0.2606 - val_accuracy: 0.9569\n",
      "Epoch 179/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2633 - accuracy: 0.9531 - val_loss: 0.2593 - val_accuracy: 0.9550\n",
      "Epoch 180/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.9545 - val_loss: 0.2580 - val_accuracy: 0.9556\n",
      "Epoch 181/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.9547 - val_loss: 0.2567 - val_accuracy: 0.9563\n",
      "Epoch 182/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.9539 - val_loss: 0.2555 - val_accuracy: 0.9563\n",
      "Epoch 183/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.9550 - val_loss: 0.2542 - val_accuracy: 0.9563\n",
      "Epoch 184/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2568 - accuracy: 0.9552 - val_loss: 0.2530 - val_accuracy: 0.9556\n",
      "Epoch 185/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9552 - val_loss: 0.2518 - val_accuracy: 0.9563\n",
      "Epoch 186/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9538 - val_loss: 0.2506 - val_accuracy: 0.9556\n",
      "Epoch 187/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9542 - val_loss: 0.2493 - val_accuracy: 0.9556\n",
      "Epoch 188/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9563 - val_loss: 0.2481 - val_accuracy: 0.9575\n",
      "Epoch 189/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9566 - val_loss: 0.2470 - val_accuracy: 0.9575\n",
      "Epoch 190/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9564 - val_loss: 0.2458 - val_accuracy: 0.9569\n",
      "Epoch 191/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9563 - val_loss: 0.2447 - val_accuracy: 0.9575\n",
      "Epoch 192/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9569 - val_loss: 0.2435 - val_accuracy: 0.9575\n",
      "Epoch 193/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9570 - val_loss: 0.2424 - val_accuracy: 0.9569\n",
      "Epoch 194/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9563 - val_loss: 0.2412 - val_accuracy: 0.9569\n",
      "Epoch 195/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9573 - val_loss: 0.2401 - val_accuracy: 0.9575\n",
      "Epoch 196/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9575 - val_loss: 0.2390 - val_accuracy: 0.9569\n",
      "Epoch 197/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9564 - val_loss: 0.2380 - val_accuracy: 0.9569\n",
      "Epoch 198/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9569 - val_loss: 0.2369 - val_accuracy: 0.9569\n",
      "Epoch 199/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9564 - val_loss: 0.2358 - val_accuracy: 0.9569\n",
      "Epoch 200/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9569 - val_loss: 0.2347 - val_accuracy: 0.9569\n",
      "Epoch 201/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9570 - val_loss: 0.2337 - val_accuracy: 0.9569\n",
      "Epoch 202/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9575 - val_loss: 0.2326 - val_accuracy: 0.9569\n",
      "Epoch 203/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9578 - val_loss: 0.2316 - val_accuracy: 0.9569\n",
      "Epoch 204/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9570 - val_loss: 0.2305 - val_accuracy: 0.9569\n",
      "Epoch 205/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9573 - val_loss: 0.2296 - val_accuracy: 0.9569\n",
      "Epoch 206/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9577 - val_loss: 0.2285 - val_accuracy: 0.9569\n",
      "Epoch 207/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2303 - accuracy: 0.9583 - val_loss: 0.2276 - val_accuracy: 0.9588\n",
      "Epoch 208/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9575 - val_loss: 0.2266 - val_accuracy: 0.9569\n",
      "Epoch 209/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2283 - accuracy: 0.9569 - val_loss: 0.2256 - val_accuracy: 0.9569\n",
      "Epoch 210/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9598 - val_loss: 0.2246 - val_accuracy: 0.9600\n",
      "Epoch 211/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9600 - val_loss: 0.2236 - val_accuracy: 0.9594\n",
      "Epoch 212/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9591 - val_loss: 0.2227 - val_accuracy: 0.9600\n",
      "Epoch 213/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9598 - val_loss: 0.2217 - val_accuracy: 0.9600\n",
      "Epoch 214/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9597 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
      "Epoch 215/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9602 - val_loss: 0.2199 - val_accuracy: 0.9600\n",
      "Epoch 216/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9608 - val_loss: 0.2190 - val_accuracy: 0.9606\n",
      "Epoch 217/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9614 - val_loss: 0.2181 - val_accuracy: 0.9606\n",
      "Epoch 218/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9608 - val_loss: 0.2172 - val_accuracy: 0.9606\n",
      "Epoch 219/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9611 - val_loss: 0.2163 - val_accuracy: 0.9606\n",
      "Epoch 220/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2177 - accuracy: 0.9617 - val_loss: 0.2153 - val_accuracy: 0.9613\n",
      "Epoch 221/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9619 - val_loss: 0.2145 - val_accuracy: 0.9606\n",
      "Epoch 222/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9620 - val_loss: 0.2136 - val_accuracy: 0.9606\n",
      "Epoch 223/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9622 - val_loss: 0.2128 - val_accuracy: 0.9606\n",
      "Epoch 224/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9627 - val_loss: 0.2119 - val_accuracy: 0.9613\n",
      "Epoch 225/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9633 - val_loss: 0.2111 - val_accuracy: 0.9606\n",
      "Epoch 226/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9625 - val_loss: 0.2102 - val_accuracy: 0.9606\n",
      "Epoch 227/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9625 - val_loss: 0.2094 - val_accuracy: 0.9606\n",
      "Epoch 228/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9630 - val_loss: 0.2085 - val_accuracy: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9633 - val_loss: 0.2077 - val_accuracy: 0.9613\n",
      "Epoch 230/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9639 - val_loss: 0.2070 - val_accuracy: 0.9613\n",
      "Epoch 231/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9638 - val_loss: 0.2061 - val_accuracy: 0.9613\n",
      "Epoch 232/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9644 - val_loss: 0.2053 - val_accuracy: 0.9613\n",
      "Epoch 233/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2065 - accuracy: 0.9644 - val_loss: 0.2045 - val_accuracy: 0.9613\n",
      "Epoch 234/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9642 - val_loss: 0.2037 - val_accuracy: 0.9650\n",
      "Epoch 235/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9663 - val_loss: 0.2029 - val_accuracy: 0.9650\n",
      "Epoch 236/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9663 - val_loss: 0.2022 - val_accuracy: 0.9650\n",
      "Epoch 237/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9666 - val_loss: 0.2015 - val_accuracy: 0.9650\n",
      "Epoch 238/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9663 - val_loss: 0.2007 - val_accuracy: 0.9650\n",
      "Epoch 239/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2016 - accuracy: 0.9666 - val_loss: 0.1999 - val_accuracy: 0.9650\n",
      "Epoch 240/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9663 - val_loss: 0.1992 - val_accuracy: 0.9650\n",
      "Epoch 241/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9661 - val_loss: 0.1984 - val_accuracy: 0.9650\n",
      "Epoch 242/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9661 - val_loss: 0.1977 - val_accuracy: 0.9650\n",
      "Epoch 243/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9669 - val_loss: 0.1969 - val_accuracy: 0.9669\n",
      "Epoch 244/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9663 - val_loss: 0.1963 - val_accuracy: 0.9650\n",
      "Epoch 245/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.9664 - val_loss: 0.1955 - val_accuracy: 0.9663\n",
      "Epoch 246/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9673 - val_loss: 0.1948 - val_accuracy: 0.9663\n",
      "Epoch 247/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9678 - val_loss: 0.1941 - val_accuracy: 0.9669\n",
      "Epoch 248/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9675 - val_loss: 0.1934 - val_accuracy: 0.9650\n",
      "Epoch 249/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9666 - val_loss: 0.1927 - val_accuracy: 0.9663\n",
      "Epoch 250/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1934 - accuracy: 0.9664 - val_loss: 0.1920 - val_accuracy: 0.9663\n",
      "Epoch 251/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9670 - val_loss: 0.1914 - val_accuracy: 0.9650\n",
      "Epoch 252/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9675 - val_loss: 0.1906 - val_accuracy: 0.9669\n",
      "Epoch 253/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9677 - val_loss: 0.1900 - val_accuracy: 0.9663\n",
      "Epoch 254/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9680 - val_loss: 0.1893 - val_accuracy: 0.9669\n",
      "Epoch 255/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9677 - val_loss: 0.1886 - val_accuracy: 0.9669\n",
      "Epoch 256/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9686 - val_loss: 0.1879 - val_accuracy: 0.9675\n",
      "Epoch 257/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9684 - val_loss: 0.1873 - val_accuracy: 0.9663\n",
      "Epoch 258/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9677 - val_loss: 0.1867 - val_accuracy: 0.9675\n",
      "Epoch 259/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9686 - val_loss: 0.1860 - val_accuracy: 0.9669\n",
      "Epoch 260/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9678 - val_loss: 0.1855 - val_accuracy: 0.9663\n",
      "Epoch 261/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9680 - val_loss: 0.1848 - val_accuracy: 0.9663\n",
      "Epoch 262/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9675 - val_loss: 0.1841 - val_accuracy: 0.9663\n",
      "Epoch 263/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9681 - val_loss: 0.1835 - val_accuracy: 0.9663\n",
      "Epoch 264/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9686 - val_loss: 0.1829 - val_accuracy: 0.9675\n",
      "Epoch 265/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9678 - val_loss: 0.1823 - val_accuracy: 0.9663\n",
      "Epoch 266/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9678 - val_loss: 0.1817 - val_accuracy: 0.9675\n",
      "Epoch 267/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9689 - val_loss: 0.1811 - val_accuracy: 0.9675\n",
      "Epoch 268/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9689 - val_loss: 0.1805 - val_accuracy: 0.9669\n",
      "Epoch 269/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9695 - val_loss: 0.1799 - val_accuracy: 0.9675\n",
      "Epoch 270/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9694 - val_loss: 0.1793 - val_accuracy: 0.9675\n",
      "Epoch 271/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9695 - val_loss: 0.1788 - val_accuracy: 0.9675\n",
      "Epoch 272/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9694 - val_loss: 0.1782 - val_accuracy: 0.9675\n",
      "Epoch 273/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9686 - val_loss: 0.1776 - val_accuracy: 0.9669\n",
      "Epoch 274/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.9695 - val_loss: 0.1770 - val_accuracy: 0.9675\n",
      "Epoch 275/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9694 - val_loss: 0.1765 - val_accuracy: 0.9675\n",
      "Epoch 276/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9692 - val_loss: 0.1760 - val_accuracy: 0.9675\n",
      "Epoch 277/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9700 - val_loss: 0.1754 - val_accuracy: 0.9681\n",
      "Epoch 278/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9694 - val_loss: 0.1748 - val_accuracy: 0.9681\n",
      "Epoch 279/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9697 - val_loss: 0.1743 - val_accuracy: 0.9681\n",
      "Epoch 280/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9695 - val_loss: 0.1737 - val_accuracy: 0.9681\n",
      "Epoch 281/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9698 - val_loss: 0.1732 - val_accuracy: 0.9681\n",
      "Epoch 282/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9702 - val_loss: 0.1727 - val_accuracy: 0.9681\n",
      "Epoch 283/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9703 - val_loss: 0.1722 - val_accuracy: 0.9681\n",
      "Epoch 284/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9695 - val_loss: 0.1716 - val_accuracy: 0.9681\n",
      "Epoch 285/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9714 - val_loss: 0.1711 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9725 - val_loss: 0.1706 - val_accuracy: 0.9688\n",
      "Epoch 287/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9705 - val_loss: 0.1700 - val_accuracy: 0.9681\n",
      "Epoch 288/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9719 - val_loss: 0.1696 - val_accuracy: 0.9688\n",
      "Epoch 289/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9727 - val_loss: 0.1691 - val_accuracy: 0.9688\n",
      "Epoch 290/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9723 - val_loss: 0.1686 - val_accuracy: 0.9688\n",
      "Epoch 291/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9728 - val_loss: 0.1681 - val_accuracy: 0.9688\n",
      "Epoch 292/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9728 - val_loss: 0.1676 - val_accuracy: 0.9688\n",
      "Epoch 293/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9725 - val_loss: 0.1671 - val_accuracy: 0.9688\n",
      "Epoch 294/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1671 - accuracy: 0.9730 - val_loss: 0.1666 - val_accuracy: 0.9688\n",
      "Epoch 295/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9727 - val_loss: 0.1661 - val_accuracy: 0.9694\n",
      "Epoch 296/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9728 - val_loss: 0.1657 - val_accuracy: 0.9694\n",
      "Epoch 297/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9728 - val_loss: 0.1652 - val_accuracy: 0.9700\n",
      "Epoch 298/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9731 - val_loss: 0.1647 - val_accuracy: 0.9694\n",
      "Epoch 299/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9725 - val_loss: 0.1643 - val_accuracy: 0.9694\n",
      "Epoch 300/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9730 - val_loss: 0.1638 - val_accuracy: 0.9694\n",
      "Epoch 301/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9733 - val_loss: 0.1633 - val_accuracy: 0.9694\n",
      "Epoch 302/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9730 - val_loss: 0.1629 - val_accuracy: 0.9700\n",
      "Epoch 303/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9734 - val_loss: 0.1624 - val_accuracy: 0.9706\n",
      "Epoch 304/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9731 - val_loss: 0.1620 - val_accuracy: 0.9700\n",
      "Epoch 305/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9736 - val_loss: 0.1615 - val_accuracy: 0.9700\n",
      "Epoch 306/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9730 - val_loss: 0.1611 - val_accuracy: 0.9700\n",
      "Epoch 307/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9736 - val_loss: 0.1606 - val_accuracy: 0.9706\n",
      "Epoch 308/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9737 - val_loss: 0.1602 - val_accuracy: 0.9706\n",
      "Epoch 309/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9737 - val_loss: 0.1598 - val_accuracy: 0.9706\n",
      "Epoch 310/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9737 - val_loss: 0.1593 - val_accuracy: 0.9706\n",
      "Epoch 311/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9734 - val_loss: 0.1589 - val_accuracy: 0.9706\n",
      "Epoch 312/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9737 - val_loss: 0.1584 - val_accuracy: 0.9706\n",
      "Epoch 313/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9728 - val_loss: 0.1580 - val_accuracy: 0.9706\n",
      "Epoch 314/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9736 - val_loss: 0.1576 - val_accuracy: 0.9706\n",
      "Epoch 315/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9742 - val_loss: 0.1571 - val_accuracy: 0.9706\n",
      "Epoch 316/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9741 - val_loss: 0.1568 - val_accuracy: 0.9706\n",
      "Epoch 317/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9736 - val_loss: 0.1564 - val_accuracy: 0.9706\n",
      "Epoch 318/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9737 - val_loss: 0.1559 - val_accuracy: 0.9706\n",
      "Epoch 319/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9737 - val_loss: 0.1555 - val_accuracy: 0.9706\n",
      "Epoch 320/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9747 - val_loss: 0.1551 - val_accuracy: 0.9706\n",
      "Epoch 321/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9742 - val_loss: 0.1548 - val_accuracy: 0.9706\n",
      "Epoch 322/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9745 - val_loss: 0.1543 - val_accuracy: 0.9706\n",
      "Epoch 323/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9742 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 324/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9741 - val_loss: 0.1536 - val_accuracy: 0.9706\n",
      "Epoch 325/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9748 - val_loss: 0.1531 - val_accuracy: 0.9706\n",
      "Epoch 326/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9744 - val_loss: 0.1528 - val_accuracy: 0.9719\n",
      "Epoch 327/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9750 - val_loss: 0.1524 - val_accuracy: 0.9712\n",
      "Epoch 328/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9753 - val_loss: 0.1520 - val_accuracy: 0.9719\n",
      "Epoch 329/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9755 - val_loss: 0.1516 - val_accuracy: 0.9719\n",
      "Epoch 330/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9747 - val_loss: 0.1513 - val_accuracy: 0.9712\n",
      "Epoch 331/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9756 - val_loss: 0.1509 - val_accuracy: 0.9719\n",
      "Epoch 332/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9756 - val_loss: 0.1505 - val_accuracy: 0.9719\n",
      "Epoch 333/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9755 - val_loss: 0.1502 - val_accuracy: 0.9712\n",
      "Epoch 334/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9756 - val_loss: 0.1497 - val_accuracy: 0.9719\n",
      "Epoch 335/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9759 - val_loss: 0.1494 - val_accuracy: 0.9719\n",
      "Epoch 336/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9758 - val_loss: 0.1491 - val_accuracy: 0.9719\n",
      "Epoch 337/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9756 - val_loss: 0.1487 - val_accuracy: 0.9712\n",
      "Epoch 338/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9753 - val_loss: 0.1483 - val_accuracy: 0.9712\n",
      "Epoch 339/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9756 - val_loss: 0.1480 - val_accuracy: 0.9719\n",
      "Epoch 340/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9759 - val_loss: 0.1476 - val_accuracy: 0.9719\n",
      "Epoch 341/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9755 - val_loss: 0.1473 - val_accuracy: 0.9719\n",
      "Epoch 342/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9755 - val_loss: 0.1469 - val_accuracy: 0.9719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9753 - val_loss: 0.1466 - val_accuracy: 0.9719\n",
      "Epoch 344/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9755 - val_loss: 0.1462 - val_accuracy: 0.9719\n",
      "Epoch 345/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9755 - val_loss: 0.1459 - val_accuracy: 0.9706\n",
      "Epoch 346/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9753 - val_loss: 0.1455 - val_accuracy: 0.9719\n",
      "Epoch 347/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9755 - val_loss: 0.1452 - val_accuracy: 0.9719\n",
      "Epoch 348/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9753 - val_loss: 0.1449 - val_accuracy: 0.9719\n",
      "Epoch 349/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9755 - val_loss: 0.1446 - val_accuracy: 0.9712\n",
      "Epoch 350/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9752 - val_loss: 0.1443 - val_accuracy: 0.9712\n",
      "Epoch 351/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9758 - val_loss: 0.1438 - val_accuracy: 0.9719\n",
      "Epoch 352/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9752 - val_loss: 0.1436 - val_accuracy: 0.9719\n",
      "Epoch 353/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9753 - val_loss: 0.1432 - val_accuracy: 0.9719\n",
      "Epoch 354/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9758 - val_loss: 0.1429 - val_accuracy: 0.9719\n",
      "Epoch 355/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9755 - val_loss: 0.1426 - val_accuracy: 0.9712\n",
      "Epoch 356/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9752 - val_loss: 0.1423 - val_accuracy: 0.9706\n",
      "Epoch 357/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9753 - val_loss: 0.1419 - val_accuracy: 0.9719\n",
      "Epoch 358/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9755 - val_loss: 0.1417 - val_accuracy: 0.9719\n",
      "Epoch 359/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9761 - val_loss: 0.1413 - val_accuracy: 0.9725\n",
      "Epoch 360/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9758 - val_loss: 0.1410 - val_accuracy: 0.9719\n",
      "Epoch 361/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9764 - val_loss: 0.1407 - val_accuracy: 0.9719\n",
      "Epoch 362/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9762 - val_loss: 0.1404 - val_accuracy: 0.9719\n",
      "Epoch 363/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9764 - val_loss: 0.1401 - val_accuracy: 0.9725\n",
      "Epoch 364/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1393 - accuracy: 0.9770 - val_loss: 0.1398 - val_accuracy: 0.9731\n",
      "Epoch 365/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9769 - val_loss: 0.1395 - val_accuracy: 0.9725\n",
      "Epoch 366/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.9775 - val_loss: 0.1392 - val_accuracy: 0.9737\n",
      "Epoch 367/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9770 - val_loss: 0.1389 - val_accuracy: 0.9725\n",
      "Epoch 368/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9775 - val_loss: 0.1386 - val_accuracy: 0.9725\n",
      "Epoch 369/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9773 - val_loss: 0.1383 - val_accuracy: 0.9731\n",
      "Epoch 370/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9777 - val_loss: 0.1380 - val_accuracy: 0.9731\n",
      "Epoch 371/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9772 - val_loss: 0.1378 - val_accuracy: 0.9725\n",
      "Epoch 372/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9770 - val_loss: 0.1374 - val_accuracy: 0.9731\n",
      "Epoch 373/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9769 - val_loss: 0.1372 - val_accuracy: 0.9725\n",
      "Epoch 374/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9780 - val_loss: 0.1369 - val_accuracy: 0.9725\n",
      "Epoch 375/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9784 - val_loss: 0.1366 - val_accuracy: 0.9737\n",
      "Epoch 376/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9777 - val_loss: 0.1363 - val_accuracy: 0.9731\n",
      "Epoch 377/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9783 - val_loss: 0.1360 - val_accuracy: 0.9731\n",
      "Epoch 378/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9784 - val_loss: 0.1357 - val_accuracy: 0.9744\n",
      "Epoch 379/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9786 - val_loss: 0.1354 - val_accuracy: 0.9737\n",
      "Epoch 380/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9786 - val_loss: 0.1352 - val_accuracy: 0.9737\n",
      "Epoch 381/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9786 - val_loss: 0.1349 - val_accuracy: 0.9737\n",
      "Epoch 382/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9784 - val_loss: 0.1347 - val_accuracy: 0.9750\n",
      "Epoch 383/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9800 - val_loss: 0.1343 - val_accuracy: 0.9762\n",
      "Epoch 384/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9789 - val_loss: 0.1341 - val_accuracy: 0.9750\n",
      "Epoch 385/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9789 - val_loss: 0.1338 - val_accuracy: 0.9769\n",
      "Epoch 386/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9791 - val_loss: 0.1336 - val_accuracy: 0.9756\n",
      "Epoch 387/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9794 - val_loss: 0.1333 - val_accuracy: 0.9762\n",
      "Epoch 388/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9787 - val_loss: 0.1331 - val_accuracy: 0.9756\n",
      "Epoch 389/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9803 - val_loss: 0.1328 - val_accuracy: 0.9756\n",
      "Epoch 390/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9787 - val_loss: 0.1325 - val_accuracy: 0.9756\n",
      "Epoch 391/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9797 - val_loss: 0.1322 - val_accuracy: 0.9762\n",
      "Epoch 392/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9808 - val_loss: 0.1320 - val_accuracy: 0.9769\n",
      "Epoch 393/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9806 - val_loss: 0.1318 - val_accuracy: 0.9762\n",
      "Epoch 394/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9803 - val_loss: 0.1315 - val_accuracy: 0.9762\n",
      "Epoch 395/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9797 - val_loss: 0.1312 - val_accuracy: 0.9762\n",
      "Epoch 396/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9806 - val_loss: 0.1310 - val_accuracy: 0.9762\n",
      "Epoch 397/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9794 - val_loss: 0.1308 - val_accuracy: 0.9756\n",
      "Epoch 398/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9808 - val_loss: 0.1304 - val_accuracy: 0.9769\n",
      "Epoch 399/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9800 - val_loss: 0.1303 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9805 - val_loss: 0.1300 - val_accuracy: 0.9762\n",
      "Epoch 401/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9797 - val_loss: 0.1298 - val_accuracy: 0.9769\n",
      "Epoch 402/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9808 - val_loss: 0.1295 - val_accuracy: 0.9769\n",
      "Epoch 403/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9808 - val_loss: 0.1293 - val_accuracy: 0.9762\n",
      "Epoch 404/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9805 - val_loss: 0.1290 - val_accuracy: 0.9762\n",
      "Epoch 405/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.9802 - val_loss: 0.1288 - val_accuracy: 0.9762\n",
      "Epoch 406/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9806 - val_loss: 0.1285 - val_accuracy: 0.9762\n",
      "Epoch 407/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9805 - val_loss: 0.1283 - val_accuracy: 0.9769\n",
      "Epoch 408/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9806 - val_loss: 0.1281 - val_accuracy: 0.9769\n",
      "Epoch 409/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9805 - val_loss: 0.1278 - val_accuracy: 0.9769\n",
      "Epoch 410/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9808 - val_loss: 0.1276 - val_accuracy: 0.9769\n",
      "Epoch 411/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9808 - val_loss: 0.1273 - val_accuracy: 0.9769\n",
      "Epoch 412/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9806 - val_loss: 0.1271 - val_accuracy: 0.9769\n",
      "Epoch 413/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9808 - val_loss: 0.1269 - val_accuracy: 0.9769\n",
      "Epoch 414/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9808 - val_loss: 0.1267 - val_accuracy: 0.9769\n",
      "Epoch 415/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9808 - val_loss: 0.1265 - val_accuracy: 0.9769\n",
      "Epoch 416/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9806 - val_loss: 0.1262 - val_accuracy: 0.9775\n",
      "Epoch 417/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9809 - val_loss: 0.1260 - val_accuracy: 0.9775\n",
      "Epoch 418/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9808 - val_loss: 0.1257 - val_accuracy: 0.9769\n",
      "Epoch 419/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9809 - val_loss: 0.1255 - val_accuracy: 0.9775\n",
      "Epoch 420/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9808 - val_loss: 0.1254 - val_accuracy: 0.9769\n",
      "Epoch 421/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9808 - val_loss: 0.1251 - val_accuracy: 0.9775\n",
      "Epoch 422/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1238 - accuracy: 0.9808 - val_loss: 0.1249 - val_accuracy: 0.9781\n",
      "Epoch 423/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9809 - val_loss: 0.1246 - val_accuracy: 0.9775\n",
      "Epoch 424/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9808 - val_loss: 0.1244 - val_accuracy: 0.9769\n",
      "Epoch 425/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9809 - val_loss: 0.1243 - val_accuracy: 0.9775\n",
      "Epoch 426/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9808 - val_loss: 0.1240 - val_accuracy: 0.9781\n",
      "Epoch 427/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1227 - accuracy: 0.9806 - val_loss: 0.1238 - val_accuracy: 0.9781\n",
      "Epoch 428/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9811 - val_loss: 0.1235 - val_accuracy: 0.9787\n",
      "Epoch 429/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9811 - val_loss: 0.1234 - val_accuracy: 0.9781\n",
      "Epoch 430/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9808 - val_loss: 0.1232 - val_accuracy: 0.9781\n",
      "Epoch 431/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9806 - val_loss: 0.1230 - val_accuracy: 0.9781\n",
      "Epoch 432/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9812 - val_loss: 0.1227 - val_accuracy: 0.9781\n",
      "Epoch 433/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9811 - val_loss: 0.1225 - val_accuracy: 0.9781\n",
      "Epoch 434/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9812 - val_loss: 0.1224 - val_accuracy: 0.9781\n",
      "Epoch 435/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9811 - val_loss: 0.1222 - val_accuracy: 0.9794\n",
      "Epoch 436/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9809 - val_loss: 0.1219 - val_accuracy: 0.9781\n",
      "Epoch 437/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9811 - val_loss: 0.1218 - val_accuracy: 0.9787\n",
      "Epoch 438/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9812 - val_loss: 0.1215 - val_accuracy: 0.9794\n",
      "Epoch 439/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9816 - val_loss: 0.1214 - val_accuracy: 0.9794\n",
      "Epoch 440/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9811 - val_loss: 0.1212 - val_accuracy: 0.9781\n",
      "Epoch 441/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9811 - val_loss: 0.1209 - val_accuracy: 0.9794\n",
      "Epoch 442/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9811 - val_loss: 0.1208 - val_accuracy: 0.9794\n",
      "Epoch 443/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9811 - val_loss: 0.1206 - val_accuracy: 0.9794\n",
      "Epoch 444/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9814 - val_loss: 0.1203 - val_accuracy: 0.9794\n",
      "Epoch 445/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9812 - val_loss: 0.1202 - val_accuracy: 0.9794\n",
      "Epoch 446/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9811 - val_loss: 0.1200 - val_accuracy: 0.9794\n",
      "Epoch 447/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9812 - val_loss: 0.1198 - val_accuracy: 0.9794\n",
      "Epoch 448/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9811 - val_loss: 0.1196 - val_accuracy: 0.9781\n",
      "Epoch 449/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9812 - val_loss: 0.1194 - val_accuracy: 0.9794\n",
      "Epoch 450/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9812 - val_loss: 0.1192 - val_accuracy: 0.9794\n",
      "Epoch 451/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9812 - val_loss: 0.1190 - val_accuracy: 0.9794\n",
      "Epoch 452/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9814 - val_loss: 0.1188 - val_accuracy: 0.9794\n",
      "Epoch 453/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9816 - val_loss: 0.1187 - val_accuracy: 0.9794\n",
      "Epoch 454/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9814 - val_loss: 0.1184 - val_accuracy: 0.9794\n",
      "Epoch 455/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9814 - val_loss: 0.1183 - val_accuracy: 0.9794\n",
      "Epoch 456/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9814 - val_loss: 0.1181 - val_accuracy: 0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9812 - val_loss: 0.1179 - val_accuracy: 0.9794\n",
      "Epoch 458/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9811 - val_loss: 0.1177 - val_accuracy: 0.9794\n",
      "Epoch 459/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9812 - val_loss: 0.1175 - val_accuracy: 0.9794\n",
      "Epoch 460/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9812 - val_loss: 0.1174 - val_accuracy: 0.9794\n",
      "Epoch 461/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9812 - val_loss: 0.1172 - val_accuracy: 0.9794\n",
      "Epoch 462/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9794\n",
      "Epoch 463/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9814 - val_loss: 0.1168 - val_accuracy: 0.9794\n",
      "Epoch 464/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9814 - val_loss: 0.1166 - val_accuracy: 0.9794\n",
      "Epoch 465/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9814 - val_loss: 0.1164 - val_accuracy: 0.9794\n",
      "Epoch 466/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9812 - val_loss: 0.1163 - val_accuracy: 0.9794\n",
      "Epoch 467/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9811 - val_loss: 0.1161 - val_accuracy: 0.9794\n",
      "Epoch 468/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9812 - val_loss: 0.1160 - val_accuracy: 0.9794\n",
      "Epoch 469/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9814 - val_loss: 0.1157 - val_accuracy: 0.9794\n",
      "Epoch 470/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9812 - val_loss: 0.1156 - val_accuracy: 0.9794\n",
      "Epoch 471/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9814 - val_loss: 0.1154 - val_accuracy: 0.9794\n",
      "Epoch 472/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9814 - val_loss: 0.1152 - val_accuracy: 0.9794\n",
      "Epoch 473/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9814 - val_loss: 0.1151 - val_accuracy: 0.9794\n",
      "Epoch 474/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9812 - val_loss: 0.1150 - val_accuracy: 0.9794\n",
      "Epoch 475/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9812 - val_loss: 0.1148 - val_accuracy: 0.9794\n",
      "Epoch 476/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9812 - val_loss: 0.1146 - val_accuracy: 0.9794\n",
      "Epoch 477/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9811 - val_loss: 0.1144 - val_accuracy: 0.9794\n",
      "Epoch 478/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9811 - val_loss: 0.1143 - val_accuracy: 0.9794\n",
      "Epoch 479/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9816 - val_loss: 0.1140 - val_accuracy: 0.9806\n",
      "Epoch 480/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9811 - val_loss: 0.1140 - val_accuracy: 0.9794\n",
      "Epoch 481/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9811 - val_loss: 0.1137 - val_accuracy: 0.9794\n",
      "Epoch 482/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9811 - val_loss: 0.1135 - val_accuracy: 0.9794\n",
      "Epoch 483/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9809 - val_loss: 0.1134 - val_accuracy: 0.9806\n",
      "Epoch 484/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9811 - val_loss: 0.1133 - val_accuracy: 0.9794\n",
      "Epoch 485/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9809 - val_loss: 0.1131 - val_accuracy: 0.9794\n",
      "Epoch 486/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9814 - val_loss: 0.1129 - val_accuracy: 0.9806\n",
      "Epoch 487/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9814 - val_loss: 0.1128 - val_accuracy: 0.9794\n",
      "Epoch 488/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9811 - val_loss: 0.1126 - val_accuracy: 0.9794\n",
      "Epoch 489/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9811 - val_loss: 0.1125 - val_accuracy: 0.9794\n",
      "Epoch 490/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9812 - val_loss: 0.1123 - val_accuracy: 0.9794\n",
      "Epoch 491/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9809 - val_loss: 0.1121 - val_accuracy: 0.9794\n",
      "Epoch 492/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9812 - val_loss: 0.1119 - val_accuracy: 0.9794\n",
      "Epoch 493/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9812 - val_loss: 0.1118 - val_accuracy: 0.9806\n",
      "Epoch 494/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9811 - val_loss: 0.1116 - val_accuracy: 0.9794\n",
      "Epoch 495/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9811 - val_loss: 0.1115 - val_accuracy: 0.9794\n",
      "Epoch 496/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9814 - val_loss: 0.1114 - val_accuracy: 0.9794\n",
      "Epoch 497/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9811 - val_loss: 0.1112 - val_accuracy: 0.9794\n",
      "Epoch 498/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9812 - val_loss: 0.1110 - val_accuracy: 0.9794\n",
      "Epoch 499/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9811 - val_loss: 0.1109 - val_accuracy: 0.9794\n",
      "Epoch 500/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9812 - val_loss: 0.1107 - val_accuracy: 0.9794\n",
      "Epoch 501/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9811 - val_loss: 0.1106 - val_accuracy: 0.9794\n",
      "Epoch 502/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9812 - val_loss: 0.1104 - val_accuracy: 0.9794\n",
      "Epoch 503/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9812 - val_loss: 0.1103 - val_accuracy: 0.9794\n",
      "Epoch 504/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9812 - val_loss: 0.1101 - val_accuracy: 0.9806\n",
      "Epoch 505/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9811 - val_loss: 0.1100 - val_accuracy: 0.9806\n",
      "Epoch 506/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9812 - val_loss: 0.1099 - val_accuracy: 0.9794\n",
      "Epoch 507/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1080 - accuracy: 0.9814 - val_loss: 0.1097 - val_accuracy: 0.9794\n",
      "Epoch 508/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9816 - val_loss: 0.1096 - val_accuracy: 0.9794\n",
      "Epoch 509/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9812 - val_loss: 0.1095 - val_accuracy: 0.9794\n",
      "Epoch 510/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9812 - val_loss: 0.1093 - val_accuracy: 0.9806\n",
      "Epoch 511/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9817 - val_loss: 0.1092 - val_accuracy: 0.9794\n",
      "Epoch 512/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9816 - val_loss: 0.1091 - val_accuracy: 0.9800\n",
      "Epoch 513/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9814 - val_loss: 0.1089 - val_accuracy: 0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9817 - val_loss: 0.1088 - val_accuracy: 0.9794\n",
      "Epoch 515/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9814 - val_loss: 0.1086 - val_accuracy: 0.9794\n",
      "Epoch 516/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9816 - val_loss: 0.1085 - val_accuracy: 0.9794\n",
      "Epoch 517/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9817 - val_loss: 0.1083 - val_accuracy: 0.9800\n",
      "Epoch 518/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9819 - val_loss: 0.1082 - val_accuracy: 0.9800\n",
      "Epoch 519/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9814 - val_loss: 0.1080 - val_accuracy: 0.9806\n",
      "Epoch 520/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9814 - val_loss: 0.1079 - val_accuracy: 0.9794\n",
      "Epoch 521/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9816 - val_loss: 0.1078 - val_accuracy: 0.9800\n",
      "Epoch 522/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9819 - val_loss: 0.1077 - val_accuracy: 0.9800\n",
      "Epoch 523/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9820 - val_loss: 0.1075 - val_accuracy: 0.9800\n",
      "Epoch 524/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9820 - val_loss: 0.1074 - val_accuracy: 0.9800\n",
      "Epoch 525/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9819 - val_loss: 0.1073 - val_accuracy: 0.9800\n",
      "Epoch 526/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9819 - val_loss: 0.1071 - val_accuracy: 0.9800\n",
      "Epoch 527/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9819 - val_loss: 0.1070 - val_accuracy: 0.9800\n",
      "Epoch 528/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9819 - val_loss: 0.1068 - val_accuracy: 0.9800\n",
      "Epoch 529/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.9819 - val_loss: 0.1067 - val_accuracy: 0.9800\n",
      "Epoch 530/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9819 - val_loss: 0.1066 - val_accuracy: 0.9800\n",
      "Epoch 531/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9819 - val_loss: 0.1064 - val_accuracy: 0.9812\n",
      "Epoch 532/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9819 - val_loss: 0.1063 - val_accuracy: 0.9800\n",
      "Epoch 533/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9819 - val_loss: 0.1062 - val_accuracy: 0.9800\n",
      "Epoch 534/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9819 - val_loss: 0.1061 - val_accuracy: 0.9800\n",
      "Epoch 535/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9819 - val_loss: 0.1059 - val_accuracy: 0.9800\n",
      "Epoch 536/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9819 - val_loss: 0.1057 - val_accuracy: 0.9812\n",
      "Epoch 537/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.9819 - val_loss: 0.1056 - val_accuracy: 0.9812\n",
      "Epoch 538/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9820 - val_loss: 0.1056 - val_accuracy: 0.9800\n",
      "Epoch 539/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9819 - val_loss: 0.1054 - val_accuracy: 0.9800\n",
      "Epoch 540/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9820 - val_loss: 0.1053 - val_accuracy: 0.9800\n",
      "Epoch 541/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9819 - val_loss: 0.1052 - val_accuracy: 0.9800\n",
      "Epoch 542/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9820 - val_loss: 0.1050 - val_accuracy: 0.9812\n",
      "Epoch 543/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9820 - val_loss: 0.1049 - val_accuracy: 0.9800\n",
      "Epoch 544/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9819 - val_loss: 0.1047 - val_accuracy: 0.9812\n",
      "Epoch 545/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9819 - val_loss: 0.1047 - val_accuracy: 0.9800\n",
      "Epoch 546/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9819 - val_loss: 0.1045 - val_accuracy: 0.9812\n",
      "Epoch 547/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9819 - val_loss: 0.1044 - val_accuracy: 0.9800\n",
      "Epoch 548/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9820 - val_loss: 0.1043 - val_accuracy: 0.9812\n",
      "Epoch 549/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9819 - val_loss: 0.1042 - val_accuracy: 0.9800\n",
      "Epoch 550/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9820 - val_loss: 0.1040 - val_accuracy: 0.9812\n",
      "Epoch 551/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9819 - val_loss: 0.1039 - val_accuracy: 0.9800\n",
      "Epoch 552/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9819 - val_loss: 0.1037 - val_accuracy: 0.9812\n",
      "Epoch 553/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9820 - val_loss: 0.1037 - val_accuracy: 0.9812\n",
      "Epoch 554/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9819 - val_loss: 0.1036 - val_accuracy: 0.9800\n",
      "Epoch 555/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9819 - val_loss: 0.1035 - val_accuracy: 0.9800\n",
      "Epoch 556/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9819 - val_loss: 0.1033 - val_accuracy: 0.9800\n",
      "Epoch 557/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9817 - val_loss: 0.1033 - val_accuracy: 0.9800\n",
      "Epoch 558/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9819 - val_loss: 0.1031 - val_accuracy: 0.9812\n",
      "Epoch 559/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9817 - val_loss: 0.1029 - val_accuracy: 0.9800\n",
      "Epoch 560/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9819 - val_loss: 0.1029 - val_accuracy: 0.9800\n",
      "Epoch 561/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9819 - val_loss: 0.1027 - val_accuracy: 0.9812\n",
      "Epoch 562/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9819 - val_loss: 0.1026 - val_accuracy: 0.9812\n",
      "Epoch 563/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9819 - val_loss: 0.1025 - val_accuracy: 0.9812\n",
      "Epoch 564/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9819 - val_loss: 0.1025 - val_accuracy: 0.9800\n",
      "Epoch 565/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9819 - val_loss: 0.1023 - val_accuracy: 0.9800\n",
      "Epoch 566/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9817 - val_loss: 0.1022 - val_accuracy: 0.9800\n",
      "Epoch 567/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9817 - val_loss: 0.1020 - val_accuracy: 0.9812\n",
      "Epoch 568/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9817 - val_loss: 0.1019 - val_accuracy: 0.9812\n",
      "Epoch 569/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9800\n",
      "Epoch 570/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9820 - val_loss: 0.1017 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9817 - val_loss: 0.1016 - val_accuracy: 0.9800\n",
      "Epoch 572/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9819 - val_loss: 0.1015 - val_accuracy: 0.9800\n",
      "Epoch 573/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9817 - val_loss: 0.1013 - val_accuracy: 0.9812\n",
      "Epoch 574/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9817 - val_loss: 0.1013 - val_accuracy: 0.9800\n",
      "Epoch 575/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9817 - val_loss: 0.1011 - val_accuracy: 0.9800\n",
      "Epoch 576/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9817 - val_loss: 0.1010 - val_accuracy: 0.9800\n",
      "Epoch 577/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9817 - val_loss: 0.1009 - val_accuracy: 0.9800\n",
      "Epoch 578/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9819 - val_loss: 0.1008 - val_accuracy: 0.9812\n",
      "Epoch 579/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0985 - accuracy: 0.9817 - val_loss: 0.1007 - val_accuracy: 0.9800\n",
      "Epoch 580/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9819 - val_loss: 0.1006 - val_accuracy: 0.9812\n",
      "Epoch 581/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9819 - val_loss: 0.1004 - val_accuracy: 0.9800\n",
      "Epoch 582/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9819 - val_loss: 0.1003 - val_accuracy: 0.9800\n",
      "Epoch 583/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9817 - val_loss: 0.1003 - val_accuracy: 0.9800\n",
      "Epoch 584/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9817 - val_loss: 0.1002 - val_accuracy: 0.9800\n",
      "Epoch 585/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9817 - val_loss: 0.1000 - val_accuracy: 0.9812\n",
      "Epoch 586/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9817 - val_loss: 0.1000 - val_accuracy: 0.9800\n",
      "Epoch 587/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9817 - val_loss: 0.0998 - val_accuracy: 0.9800\n",
      "Epoch 588/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9817 - val_loss: 0.0997 - val_accuracy: 0.9800\n",
      "Epoch 589/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9817 - val_loss: 0.0995 - val_accuracy: 0.9812\n",
      "Epoch 590/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9819 - val_loss: 0.0994 - val_accuracy: 0.9800\n",
      "Epoch 591/1000\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.98 - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9819 - val_loss: 0.0993 - val_accuracy: 0.9812\n",
      "Epoch 592/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9819 - val_loss: 0.0992 - val_accuracy: 0.9812\n",
      "Epoch 593/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9817 - val_loss: 0.0991 - val_accuracy: 0.9812\n",
      "Epoch 594/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9819 - val_loss: 0.0990 - val_accuracy: 0.9812\n",
      "Epoch 595/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9817 - val_loss: 0.0990 - val_accuracy: 0.9800\n",
      "Epoch 596/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9819 - val_loss: 0.0988 - val_accuracy: 0.9812\n",
      "Epoch 597/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9819 - val_loss: 0.0987 - val_accuracy: 0.9812\n",
      "Epoch 598/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9819 - val_loss: 0.0986 - val_accuracy: 0.9812\n",
      "Epoch 599/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 0.9819 - val_loss: 0.0985 - val_accuracy: 0.9812\n",
      "Epoch 600/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9819 - val_loss: 0.0984 - val_accuracy: 0.9800\n",
      "Epoch 601/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9819 - val_loss: 0.0983 - val_accuracy: 0.9812\n",
      "Epoch 602/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9817 - val_loss: 0.0983 - val_accuracy: 0.9800\n",
      "Epoch 603/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9819 - val_loss: 0.0981 - val_accuracy: 0.9812\n",
      "Epoch 604/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9800\n",
      "Epoch 605/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9819 - val_loss: 0.0979 - val_accuracy: 0.9812\n",
      "Epoch 606/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9819 - val_loss: 0.0977 - val_accuracy: 0.9812\n",
      "Epoch 607/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9819 - val_loss: 0.0977 - val_accuracy: 0.9812\n",
      "Epoch 608/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9817 - val_loss: 0.0977 - val_accuracy: 0.9800\n",
      "Epoch 609/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9819 - val_loss: 0.0975 - val_accuracy: 0.9812\n",
      "Epoch 610/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9819 - val_loss: 0.0974 - val_accuracy: 0.9800\n",
      "Epoch 611/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9817 - val_loss: 0.0973 - val_accuracy: 0.9812\n",
      "Epoch 612/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9819 - val_loss: 0.0972 - val_accuracy: 0.9812\n",
      "Epoch 613/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9817 - val_loss: 0.0972 - val_accuracy: 0.9800\n",
      "Epoch 614/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9817 - val_loss: 0.0970 - val_accuracy: 0.9812\n",
      "Epoch 615/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9820 - val_loss: 0.0969 - val_accuracy: 0.9812\n",
      "Epoch 616/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9817 - val_loss: 0.0968 - val_accuracy: 0.9812\n",
      "Epoch 617/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9819 - val_loss: 0.0967 - val_accuracy: 0.9812\n",
      "Epoch 618/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9817 - val_loss: 0.0966 - val_accuracy: 0.9812\n",
      "Epoch 619/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.9819 - val_loss: 0.0966 - val_accuracy: 0.9800\n",
      "Epoch 620/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9817 - val_loss: 0.0965 - val_accuracy: 0.9800\n",
      "Epoch 621/1000\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9819 - val_loss: 0.0963 - val_accuracy: 0.9812\n",
      "Epoch 622/1000\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 0.0939 - accuracy: 0.9820 - val_loss: 0.0963 - val_accuracy: 0.9812\n",
      "Epoch 623/1000\n",
      "43/43 [==============================] - 1s 16ms/step - loss: 0.0938 - accuracy: 0.9817 - val_loss: 0.0962 - val_accuracy: 0.9812\n",
      "Epoch 624/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0937 - accuracy: 0.9819 - val_loss: 0.0961 - val_accuracy: 0.9812\n",
      "Epoch 625/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0936 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9812\n",
      "Epoch 626/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 0.9819 - val_loss: 0.0959 - val_accuracy: 0.9812\n",
      "Epoch 627/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9817 - val_loss: 0.0958 - val_accuracy: 0.9800\n",
      "Epoch 628/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0933 - accuracy: 0.9819 - val_loss: 0.0957 - val_accuracy: 0.9812\n",
      "Epoch 629/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 0.9817 - val_loss: 0.0956 - val_accuracy: 0.9800\n",
      "Epoch 630/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 0.9820 - val_loss: 0.0955 - val_accuracy: 0.9812\n",
      "Epoch 631/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9819 - val_loss: 0.0954 - val_accuracy: 0.9812\n",
      "Epoch 632/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9817 - val_loss: 0.0954 - val_accuracy: 0.9800\n",
      "Epoch 633/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9817 - val_loss: 0.0953 - val_accuracy: 0.9800\n",
      "Epoch 634/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9820 - val_loss: 0.0951 - val_accuracy: 0.9812\n",
      "Epoch 635/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9820 - val_loss: 0.0950 - val_accuracy: 0.9812\n",
      "Epoch 636/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9819 - val_loss: 0.0949 - val_accuracy: 0.9812\n",
      "Epoch 637/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9819 - val_loss: 0.0949 - val_accuracy: 0.9812\n",
      "Epoch 638/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9819 - val_loss: 0.0948 - val_accuracy: 0.9812\n",
      "Epoch 639/1000\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9819 - val_loss: 0.0947 - val_accuracy: 0.9800\n",
      "Epoch 640/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9819 - val_loss: 0.0946 - val_accuracy: 0.9812\n",
      "Epoch 641/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9819 - val_loss: 0.0945 - val_accuracy: 0.9812\n",
      "Epoch 642/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9820 - val_loss: 0.0944 - val_accuracy: 0.9812\n",
      "Epoch 643/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9819 - val_loss: 0.0944 - val_accuracy: 0.9800\n",
      "Epoch 644/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9817 - val_loss: 0.0942 - val_accuracy: 0.9812\n",
      "Epoch 645/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9822 - val_loss: 0.0941 - val_accuracy: 0.9812\n",
      "Epoch 646/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9817 - val_loss: 0.0941 - val_accuracy: 0.9800\n",
      "Epoch 647/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9819 - val_loss: 0.0940 - val_accuracy: 0.9812\n",
      "Epoch 648/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9820 - val_loss: 0.0939 - val_accuracy: 0.9812\n",
      "Epoch 649/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9819 - val_loss: 0.0938 - val_accuracy: 0.9800\n",
      "Epoch 650/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9820 - val_loss: 0.0937 - val_accuracy: 0.9812\n",
      "Epoch 651/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9819 - val_loss: 0.0937 - val_accuracy: 0.9800\n",
      "Epoch 652/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9819 - val_loss: 0.0935 - val_accuracy: 0.9812\n",
      "Epoch 653/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9820 - val_loss: 0.0935 - val_accuracy: 0.9800\n",
      "Epoch 654/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9819 - val_loss: 0.0933 - val_accuracy: 0.9812\n",
      "Epoch 655/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9822 - val_loss: 0.0933 - val_accuracy: 0.9812\n",
      "Epoch 656/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9817 - val_loss: 0.0932 - val_accuracy: 0.9800\n",
      "Epoch 657/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9820 - val_loss: 0.0931 - val_accuracy: 0.9812\n",
      "Epoch 658/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9819 - val_loss: 0.0930 - val_accuracy: 0.9800\n",
      "Epoch 659/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9822 - val_loss: 0.0929 - val_accuracy: 0.9812\n",
      "Epoch 660/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9822 - val_loss: 0.0928 - val_accuracy: 0.9812\n",
      "Epoch 661/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9822 - val_loss: 0.0928 - val_accuracy: 0.9800\n",
      "Epoch 662/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9819 - val_loss: 0.0926 - val_accuracy: 0.9812\n",
      "Epoch 663/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9820 - val_loss: 0.0925 - val_accuracy: 0.9812\n",
      "Epoch 664/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9820 - val_loss: 0.0925 - val_accuracy: 0.9812\n",
      "Epoch 665/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9822 - val_loss: 0.0925 - val_accuracy: 0.9800\n",
      "Epoch 666/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9820 - val_loss: 0.0924 - val_accuracy: 0.9800\n",
      "Epoch 667/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9819 - val_loss: 0.0923 - val_accuracy: 0.9800\n",
      "Epoch 668/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9820 - val_loss: 0.0922 - val_accuracy: 0.9812\n",
      "Epoch 669/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9820 - val_loss: 0.0921 - val_accuracy: 0.9812\n",
      "Epoch 670/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9819 - val_loss: 0.0921 - val_accuracy: 0.9800\n",
      "Epoch 671/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9820 - val_loss: 0.0920 - val_accuracy: 0.9812\n",
      "Epoch 672/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9822 - val_loss: 0.0919 - val_accuracy: 0.9812\n",
      "Epoch 673/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9820 - val_loss: 0.0918 - val_accuracy: 0.9800\n",
      "Epoch 674/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9822 - val_loss: 0.0917 - val_accuracy: 0.9812\n",
      "Epoch 675/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9820 - val_loss: 0.0917 - val_accuracy: 0.9812\n",
      "Epoch 676/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9822 - val_loss: 0.0915 - val_accuracy: 0.9812\n",
      "Epoch 677/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9823 - val_loss: 0.0915 - val_accuracy: 0.9812\n",
      "Epoch 678/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9820 - val_loss: 0.0913 - val_accuracy: 0.9812\n",
      "Epoch 679/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9820 - val_loss: 0.0914 - val_accuracy: 0.9800\n",
      "Epoch 680/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9823 - val_loss: 0.0912 - val_accuracy: 0.9812\n",
      "Epoch 681/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9823 - val_loss: 0.0912 - val_accuracy: 0.9812\n",
      "Epoch 682/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9820 - val_loss: 0.0911 - val_accuracy: 0.9819\n",
      "Epoch 683/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9822 - val_loss: 0.0910 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9820 - val_loss: 0.0910 - val_accuracy: 0.9812\n",
      "Epoch 685/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9825 - val_loss: 0.0908 - val_accuracy: 0.9819\n",
      "Epoch 686/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9820 - val_loss: 0.0908 - val_accuracy: 0.9812\n",
      "Epoch 687/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9823 - val_loss: 0.0907 - val_accuracy: 0.9819\n",
      "Epoch 688/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9825 - val_loss: 0.0906 - val_accuracy: 0.9819\n",
      "Epoch 689/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9819 - val_loss: 0.0906 - val_accuracy: 0.9812\n",
      "Epoch 690/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9822 - val_loss: 0.0905 - val_accuracy: 0.9819\n",
      "Epoch 691/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9825 - val_loss: 0.0904 - val_accuracy: 0.9819\n",
      "Epoch 692/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9827 - val_loss: 0.0904 - val_accuracy: 0.9819\n",
      "Epoch 693/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9825 - val_loss: 0.0902 - val_accuracy: 0.9819\n",
      "Epoch 694/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9823 - val_loss: 0.0902 - val_accuracy: 0.9819\n",
      "Epoch 695/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9820 - val_loss: 0.0902 - val_accuracy: 0.9806\n",
      "Epoch 696/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9827 - val_loss: 0.0900 - val_accuracy: 0.9819\n",
      "Epoch 697/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9820 - val_loss: 0.0900 - val_accuracy: 0.9806\n",
      "Epoch 698/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9823 - val_loss: 0.0898 - val_accuracy: 0.9819\n",
      "Epoch 699/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9827 - val_loss: 0.0898 - val_accuracy: 0.9819\n",
      "Epoch 700/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9827 - val_loss: 0.0897 - val_accuracy: 0.9819\n",
      "Epoch 701/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9822 - val_loss: 0.0897 - val_accuracy: 0.9819\n",
      "Epoch 702/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9823 - val_loss: 0.0896 - val_accuracy: 0.9819\n",
      "Epoch 703/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9827 - val_loss: 0.0895 - val_accuracy: 0.9819\n",
      "Epoch 704/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9827 - val_loss: 0.0895 - val_accuracy: 0.9819\n",
      "Epoch 705/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9822 - val_loss: 0.0894 - val_accuracy: 0.9806\n",
      "Epoch 706/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9822 - val_loss: 0.0893 - val_accuracy: 0.9819\n",
      "Epoch 707/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9827 - val_loss: 0.0892 - val_accuracy: 0.9819\n",
      "Epoch 708/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9827 - val_loss: 0.0891 - val_accuracy: 0.9819\n",
      "Epoch 709/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9827 - val_loss: 0.0890 - val_accuracy: 0.9819\n",
      "Epoch 710/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9825 - val_loss: 0.0890 - val_accuracy: 0.9819\n",
      "Epoch 711/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9822 - val_loss: 0.0890 - val_accuracy: 0.9819\n",
      "Epoch 712/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9822 - val_loss: 0.0888 - val_accuracy: 0.9819\n",
      "Epoch 713/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9827 - val_loss: 0.0887 - val_accuracy: 0.9819\n",
      "Epoch 714/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9823 - val_loss: 0.0888 - val_accuracy: 0.9819\n",
      "Epoch 715/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9827 - val_loss: 0.0886 - val_accuracy: 0.9819\n",
      "Epoch 716/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9827 - val_loss: 0.0885 - val_accuracy: 0.9819\n",
      "Epoch 717/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9827 - val_loss: 0.0885 - val_accuracy: 0.9819\n",
      "Epoch 718/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9827 - val_loss: 0.0884 - val_accuracy: 0.9819\n",
      "Epoch 719/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9827 - val_loss: 0.0883 - val_accuracy: 0.9819\n",
      "Epoch 720/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9825 - val_loss: 0.0883 - val_accuracy: 0.9819\n",
      "Epoch 721/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9827 - val_loss: 0.0882 - val_accuracy: 0.9819\n",
      "Epoch 722/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9828 - val_loss: 0.0881 - val_accuracy: 0.9819\n",
      "Epoch 723/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9827 - val_loss: 0.0880 - val_accuracy: 0.9819\n",
      "Epoch 724/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9830 - val_loss: 0.0880 - val_accuracy: 0.9825\n",
      "Epoch 725/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9828 - val_loss: 0.0879 - val_accuracy: 0.9819\n",
      "Epoch 726/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9827 - val_loss: 0.0878 - val_accuracy: 0.9819\n",
      "Epoch 727/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9828 - val_loss: 0.0878 - val_accuracy: 0.9819\n",
      "Epoch 728/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9828 - val_loss: 0.0877 - val_accuracy: 0.9819\n",
      "Epoch 729/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9831 - val_loss: 0.0877 - val_accuracy: 0.9825\n",
      "Epoch 730/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9828 - val_loss: 0.0876 - val_accuracy: 0.9812\n",
      "Epoch 731/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9827 - val_loss: 0.0875 - val_accuracy: 0.9825\n",
      "Epoch 732/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9833 - val_loss: 0.0874 - val_accuracy: 0.9825\n",
      "Epoch 733/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9830 - val_loss: 0.0874 - val_accuracy: 0.9825\n",
      "Epoch 734/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9830 - val_loss: 0.0873 - val_accuracy: 0.9825\n",
      "Epoch 735/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9831 - val_loss: 0.0872 - val_accuracy: 0.9825\n",
      "Epoch 736/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9828 - val_loss: 0.0872 - val_accuracy: 0.9812\n",
      "Epoch 737/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9830 - val_loss: 0.0871 - val_accuracy: 0.9825\n",
      "Epoch 738/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9830 - val_loss: 0.0870 - val_accuracy: 0.9825\n",
      "Epoch 739/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9827 - val_loss: 0.0870 - val_accuracy: 0.9831\n",
      "Epoch 740/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9833 - val_loss: 0.0869 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9834 - val_loss: 0.0868 - val_accuracy: 0.9831\n",
      "Epoch 742/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9834 - val_loss: 0.0868 - val_accuracy: 0.9831\n",
      "Epoch 743/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9827 - val_loss: 0.0867 - val_accuracy: 0.9831\n",
      "Epoch 744/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9831 - val_loss: 0.0866 - val_accuracy: 0.9831\n",
      "Epoch 745/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9830 - val_loss: 0.0866 - val_accuracy: 0.9831\n",
      "Epoch 746/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9831 - val_loss: 0.0865 - val_accuracy: 0.9825\n",
      "Epoch 747/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9831 - val_loss: 0.0864 - val_accuracy: 0.9831\n",
      "Epoch 748/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9833 - val_loss: 0.0863 - val_accuracy: 0.9831\n",
      "Epoch 749/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9831 - val_loss: 0.0863 - val_accuracy: 0.9831\n",
      "Epoch 750/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9831 - val_loss: 0.0862 - val_accuracy: 0.9831\n",
      "Epoch 751/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9828 - val_loss: 0.0862 - val_accuracy: 0.9831\n",
      "Epoch 752/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9828 - val_loss: 0.0861 - val_accuracy: 0.9831\n",
      "Epoch 753/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.9834 - val_loss: 0.0860 - val_accuracy: 0.9831\n",
      "Epoch 754/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9831 - val_loss: 0.0860 - val_accuracy: 0.9831\n",
      "Epoch 755/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9833 - val_loss: 0.0859 - val_accuracy: 0.9831\n",
      "Epoch 756/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9833 - val_loss: 0.0859 - val_accuracy: 0.9831\n",
      "Epoch 757/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9831 - val_loss: 0.0858 - val_accuracy: 0.9831\n",
      "Epoch 758/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9833 - val_loss: 0.0857 - val_accuracy: 0.9831\n",
      "Epoch 759/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9830 - val_loss: 0.0857 - val_accuracy: 0.9831\n",
      "Epoch 760/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9834 - val_loss: 0.0855 - val_accuracy: 0.9831\n",
      "Epoch 761/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9834 - val_loss: 0.0855 - val_accuracy: 0.9831\n",
      "Epoch 762/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9831 - val_loss: 0.0855 - val_accuracy: 0.9831\n",
      "Epoch 763/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9831 - val_loss: 0.0854 - val_accuracy: 0.9831\n",
      "Epoch 764/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9831 - val_loss: 0.0853 - val_accuracy: 0.9831\n",
      "Epoch 765/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9831 - val_loss: 0.0853 - val_accuracy: 0.9831\n",
      "Epoch 766/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9834 - val_loss: 0.0852 - val_accuracy: 0.9831\n",
      "Epoch 767/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9833 - val_loss: 0.0851 - val_accuracy: 0.9831\n",
      "Epoch 768/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9833 - val_loss: 0.0851 - val_accuracy: 0.9831\n",
      "Epoch 769/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9836 - val_loss: 0.0850 - val_accuracy: 0.9831\n",
      "Epoch 770/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9834 - val_loss: 0.0849 - val_accuracy: 0.9831\n",
      "Epoch 771/1000\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.0849 - val_accuracy: 0.9831\n",
      "Epoch 772/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.0848 - val_accuracy: 0.9831\n",
      "Epoch 773/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9834 - val_loss: 0.0847 - val_accuracy: 0.9831\n",
      "Epoch 774/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9834 - val_loss: 0.0847 - val_accuracy: 0.9831\n",
      "Epoch 775/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9837 - val_loss: 0.0847 - val_accuracy: 0.9831\n",
      "Epoch 776/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9836 - val_loss: 0.0846 - val_accuracy: 0.9831\n",
      "Epoch 777/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9836 - val_loss: 0.0844 - val_accuracy: 0.9831\n",
      "Epoch 778/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9836 - val_loss: 0.0845 - val_accuracy: 0.9831\n",
      "Epoch 779/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9836 - val_loss: 0.0845 - val_accuracy: 0.9831\n",
      "Epoch 780/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9836 - val_loss: 0.0843 - val_accuracy: 0.9831\n",
      "Epoch 781/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9836 - val_loss: 0.0842 - val_accuracy: 0.9831\n",
      "Epoch 782/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9834 - val_loss: 0.0842 - val_accuracy: 0.9831\n",
      "Epoch 783/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9834 - val_loss: 0.0841 - val_accuracy: 0.9831\n",
      "Epoch 784/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9836 - val_loss: 0.0840 - val_accuracy: 0.9831\n",
      "Epoch 785/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9836 - val_loss: 0.0840 - val_accuracy: 0.9831\n",
      "Epoch 786/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9833 - val_loss: 0.0840 - val_accuracy: 0.9831\n",
      "Epoch 787/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9836 - val_loss: 0.0839 - val_accuracy: 0.9831\n",
      "Epoch 788/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9836 - val_loss: 0.0838 - val_accuracy: 0.9831\n",
      "Epoch 789/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9834 - val_loss: 0.0838 - val_accuracy: 0.9831\n",
      "Epoch 790/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9836 - val_loss: 0.0837 - val_accuracy: 0.9831\n",
      "Epoch 791/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9836 - val_loss: 0.0836 - val_accuracy: 0.9831\n",
      "Epoch 792/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9836 - val_loss: 0.0835 - val_accuracy: 0.9831\n",
      "Epoch 793/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9836 - val_loss: 0.0836 - val_accuracy: 0.9831\n",
      "Epoch 794/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9836 - val_loss: 0.0835 - val_accuracy: 0.9831\n",
      "Epoch 795/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9836 - val_loss: 0.0834 - val_accuracy: 0.9831\n",
      "Epoch 796/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9837 - val_loss: 0.0834 - val_accuracy: 0.9831\n",
      "Epoch 797/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9836 - val_loss: 0.0832 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9836 - val_loss: 0.0832 - val_accuracy: 0.9831\n",
      "Epoch 799/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9836 - val_loss: 0.0831 - val_accuracy: 0.9831\n",
      "Epoch 800/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9836 - val_loss: 0.0831 - val_accuracy: 0.9831\n",
      "Epoch 801/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9836 - val_loss: 0.0831 - val_accuracy: 0.9831\n",
      "Epoch 802/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9836 - val_loss: 0.0830 - val_accuracy: 0.9831\n",
      "Epoch 803/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9836 - val_loss: 0.0829 - val_accuracy: 0.9831\n",
      "Epoch 804/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9836 - val_loss: 0.0828 - val_accuracy: 0.9831\n",
      "Epoch 805/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9836 - val_loss: 0.0828 - val_accuracy: 0.9831\n",
      "Epoch 806/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9836 - val_loss: 0.0828 - val_accuracy: 0.9831\n",
      "Epoch 807/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9836 - val_loss: 0.0827 - val_accuracy: 0.9831\n",
      "Epoch 808/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9836 - val_loss: 0.0827 - val_accuracy: 0.9831\n",
      "Epoch 809/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9836 - val_loss: 0.0826 - val_accuracy: 0.9831\n",
      "Epoch 810/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9836 - val_loss: 0.0825 - val_accuracy: 0.9831\n",
      "Epoch 811/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9836 - val_loss: 0.0825 - val_accuracy: 0.9831\n",
      "Epoch 812/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9836 - val_loss: 0.0824 - val_accuracy: 0.9831\n",
      "Epoch 813/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9837 - val_loss: 0.0825 - val_accuracy: 0.9831\n",
      "Epoch 814/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9836 - val_loss: 0.0823 - val_accuracy: 0.9831\n",
      "Epoch 815/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9836 - val_loss: 0.0823 - val_accuracy: 0.9831\n",
      "Epoch 816/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9836 - val_loss: 0.0823 - val_accuracy: 0.9831\n",
      "Epoch 817/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9836 - val_loss: 0.0821 - val_accuracy: 0.9831\n",
      "Epoch 818/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9836 - val_loss: 0.0821 - val_accuracy: 0.9831\n",
      "Epoch 819/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9836 - val_loss: 0.0821 - val_accuracy: 0.9831\n",
      "Epoch 820/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9836 - val_loss: 0.0820 - val_accuracy: 0.9831\n",
      "Epoch 821/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9836 - val_loss: 0.0819 - val_accuracy: 0.9831\n",
      "Epoch 822/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9836 - val_loss: 0.0819 - val_accuracy: 0.9831\n",
      "Epoch 823/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9836 - val_loss: 0.0818 - val_accuracy: 0.9831\n",
      "Epoch 824/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9836 - val_loss: 0.0818 - val_accuracy: 0.9831\n",
      "Epoch 825/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9836 - val_loss: 0.0817 - val_accuracy: 0.9831\n",
      "Epoch 826/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9836 - val_loss: 0.0817 - val_accuracy: 0.9831\n",
      "Epoch 827/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9836 - val_loss: 0.0817 - val_accuracy: 0.9831\n",
      "Epoch 828/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0786 - accuracy: 0.9836 - val_loss: 0.0815 - val_accuracy: 0.9831\n",
      "Epoch 829/1000\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.0785 - accuracy: 0.9834 - val_loss: 0.0815 - val_accuracy: 0.9831\n",
      "Epoch 830/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0785 - accuracy: 0.9836 - val_loss: 0.0814 - val_accuracy: 0.9831\n",
      "Epoch 831/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0784 - accuracy: 0.9836 - val_loss: 0.0814 - val_accuracy: 0.9831\n",
      "Epoch 832/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9836 - val_loss: 0.0813 - val_accuracy: 0.9831\n",
      "Epoch 833/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0783 - accuracy: 0.9836 - val_loss: 0.0813 - val_accuracy: 0.9831\n",
      "Epoch 834/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9836 - val_loss: 0.0812 - val_accuracy: 0.9831\n",
      "Epoch 835/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9836 - val_loss: 0.0812 - val_accuracy: 0.9831\n",
      "Epoch 836/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9834 - val_loss: 0.0811 - val_accuracy: 0.9831\n",
      "Epoch 837/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9836 - val_loss: 0.0811 - val_accuracy: 0.9831\n",
      "Epoch 838/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0780 - accuracy: 0.9836 - val_loss: 0.0811 - val_accuracy: 0.9831\n",
      "Epoch 839/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9836 - val_loss: 0.0810 - val_accuracy: 0.9831\n",
      "Epoch 840/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9834 - val_loss: 0.0809 - val_accuracy: 0.9831\n",
      "Epoch 841/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9834 - val_loss: 0.0809 - val_accuracy: 0.9831\n",
      "Epoch 842/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9836 - val_loss: 0.0809 - val_accuracy: 0.9831\n",
      "Epoch 843/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9834 - val_loss: 0.0808 - val_accuracy: 0.9831\n",
      "Epoch 844/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9836 - val_loss: 0.0808 - val_accuracy: 0.9831\n",
      "Epoch 845/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9834 - val_loss: 0.0807 - val_accuracy: 0.9831\n",
      "Epoch 846/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9834 - val_loss: 0.0806 - val_accuracy: 0.9831\n",
      "Epoch 847/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0775 - accuracy: 0.9834 - val_loss: 0.0806 - val_accuracy: 0.9831\n",
      "Epoch 848/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9834 - val_loss: 0.0804 - val_accuracy: 0.9831\n",
      "Epoch 849/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9836 - val_loss: 0.0804 - val_accuracy: 0.9831\n",
      "Epoch 850/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9836 - val_loss: 0.0805 - val_accuracy: 0.9831\n",
      "Epoch 851/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0773 - accuracy: 0.9836 - val_loss: 0.0804 - val_accuracy: 0.9831\n",
      "Epoch 852/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9834 - val_loss: 0.0803 - val_accuracy: 0.9831\n",
      "Epoch 853/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9834 - val_loss: 0.0803 - val_accuracy: 0.9831\n",
      "Epoch 854/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9834 - val_loss: 0.0802 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9834 - val_loss: 0.0802 - val_accuracy: 0.9831\n",
      "Epoch 856/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9834 - val_loss: 0.0801 - val_accuracy: 0.9831\n",
      "Epoch 857/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9834 - val_loss: 0.0800 - val_accuracy: 0.9831\n",
      "Epoch 858/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9834 - val_loss: 0.0800 - val_accuracy: 0.9831\n",
      "Epoch 859/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9834 - val_loss: 0.0799 - val_accuracy: 0.9831\n",
      "Epoch 860/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0769 - accuracy: 0.9834 - val_loss: 0.0799 - val_accuracy: 0.9831\n",
      "Epoch 861/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9836 - val_loss: 0.0799 - val_accuracy: 0.9831\n",
      "Epoch 862/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9834 - val_loss: 0.0798 - val_accuracy: 0.9831\n",
      "Epoch 863/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9834 - val_loss: 0.0797 - val_accuracy: 0.9831\n",
      "Epoch 864/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9834 - val_loss: 0.0797 - val_accuracy: 0.9831\n",
      "Epoch 865/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9834 - val_loss: 0.0797 - val_accuracy: 0.9831\n",
      "Epoch 866/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9834 - val_loss: 0.0795 - val_accuracy: 0.9837\n",
      "Epoch 867/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9834 - val_loss: 0.0795 - val_accuracy: 0.9831\n",
      "Epoch 868/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9834 - val_loss: 0.0795 - val_accuracy: 0.9831\n",
      "Epoch 869/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9834 - val_loss: 0.0795 - val_accuracy: 0.9831\n",
      "Epoch 870/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9837 - val_loss: 0.0794 - val_accuracy: 0.9831\n",
      "Epoch 871/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9834 - val_loss: 0.0794 - val_accuracy: 0.9831\n",
      "Epoch 872/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9834 - val_loss: 0.0793 - val_accuracy: 0.9831\n",
      "Epoch 873/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9834 - val_loss: 0.0793 - val_accuracy: 0.9831\n",
      "Epoch 874/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9834 - val_loss: 0.0792 - val_accuracy: 0.9831\n",
      "Epoch 875/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9834 - val_loss: 0.0792 - val_accuracy: 0.9831\n",
      "Epoch 876/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9834 - val_loss: 0.0791 - val_accuracy: 0.9831\n",
      "Epoch 877/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9836 - val_loss: 0.0791 - val_accuracy: 0.9837\n",
      "Epoch 878/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9834 - val_loss: 0.0790 - val_accuracy: 0.9831\n",
      "Epoch 879/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9834 - val_loss: 0.0790 - val_accuracy: 0.9831\n",
      "Epoch 880/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9834 - val_loss: 0.0790 - val_accuracy: 0.9831\n",
      "Epoch 881/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9834 - val_loss: 0.0789 - val_accuracy: 0.9837\n",
      "Epoch 882/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9833 - val_loss: 0.0788 - val_accuracy: 0.9837\n",
      "Epoch 883/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9834 - val_loss: 0.0788 - val_accuracy: 0.9831\n",
      "Epoch 884/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9834 - val_loss: 0.0788 - val_accuracy: 0.9831\n",
      "Epoch 885/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9834 - val_loss: 0.0787 - val_accuracy: 0.9831\n",
      "Epoch 886/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0755 - accuracy: 0.9836 - val_loss: 0.0786 - val_accuracy: 0.9831\n",
      "Epoch 887/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0755 - accuracy: 0.9834 - val_loss: 0.0786 - val_accuracy: 0.9831\n",
      "Epoch 888/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9834 - val_loss: 0.0786 - val_accuracy: 0.9831\n",
      "Epoch 889/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9834 - val_loss: 0.0785 - val_accuracy: 0.9837\n",
      "Epoch 890/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9834 - val_loss: 0.0785 - val_accuracy: 0.9831\n",
      "Epoch 891/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9834 - val_loss: 0.0785 - val_accuracy: 0.9831\n",
      "Epoch 892/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9834 - val_loss: 0.0784 - val_accuracy: 0.9831\n",
      "Epoch 893/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9834 - val_loss: 0.0783 - val_accuracy: 0.9831\n",
      "Epoch 894/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9836 - val_loss: 0.0783 - val_accuracy: 0.9837\n",
      "Epoch 895/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9837 - val_loss: 0.0783 - val_accuracy: 0.9831\n",
      "Epoch 896/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.0782 - val_accuracy: 0.9831\n",
      "Epoch 897/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.0781 - val_accuracy: 0.9837\n",
      "Epoch 898/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.0781 - val_accuracy: 0.9837\n",
      "Epoch 899/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9834 - val_loss: 0.0780 - val_accuracy: 0.9837\n",
      "Epoch 900/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9837 - val_loss: 0.0780 - val_accuracy: 0.9831\n",
      "Epoch 901/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9836 - val_loss: 0.0780 - val_accuracy: 0.9831\n",
      "Epoch 902/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9837 - val_loss: 0.0779 - val_accuracy: 0.9837\n",
      "Epoch 903/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9834 - val_loss: 0.0778 - val_accuracy: 0.9837\n",
      "Epoch 904/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0747 - accuracy: 0.9834 - val_loss: 0.0778 - val_accuracy: 0.9831\n",
      "Epoch 905/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9837 - val_loss: 0.0778 - val_accuracy: 0.9831\n",
      "Epoch 906/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9837 - val_loss: 0.0778 - val_accuracy: 0.9831\n",
      "Epoch 907/1000\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0745 - accuracy: 0.9836 - val_loss: 0.0777 - val_accuracy: 0.9831\n",
      "Epoch 908/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0745 - accuracy: 0.9836 - val_loss: 0.0776 - val_accuracy: 0.9831\n",
      "Epoch 909/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9836 - val_loss: 0.0775 - val_accuracy: 0.9837\n",
      "Epoch 910/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9837 - val_loss: 0.0775 - val_accuracy: 0.9831\n",
      "Epoch 911/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9839 - val_loss: 0.0775 - val_accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9837 - val_loss: 0.0774 - val_accuracy: 0.9837\n",
      "Epoch 913/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9837 - val_loss: 0.0775 - val_accuracy: 0.9837\n",
      "Epoch 914/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9836 - val_loss: 0.0774 - val_accuracy: 0.9831\n",
      "Epoch 915/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9836 - val_loss: 0.0773 - val_accuracy: 0.9837\n",
      "Epoch 916/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9837 - val_loss: 0.0773 - val_accuracy: 0.9837\n",
      "Epoch 917/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9839 - val_loss: 0.0772 - val_accuracy: 0.9837\n",
      "Epoch 918/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9837 - val_loss: 0.0772 - val_accuracy: 0.9837\n",
      "Epoch 919/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9837 - val_loss: 0.0772 - val_accuracy: 0.9837\n",
      "Epoch 920/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9833 - val_loss: 0.0771 - val_accuracy: 0.9837\n",
      "Epoch 921/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9837 - val_loss: 0.0771 - val_accuracy: 0.9831\n",
      "Epoch 922/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9837 - val_loss: 0.0770 - val_accuracy: 0.9837\n",
      "Epoch 923/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9839 - val_loss: 0.0770 - val_accuracy: 0.9837\n",
      "Epoch 924/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9837 - val_loss: 0.0769 - val_accuracy: 0.9837\n",
      "Epoch 925/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9836 - val_loss: 0.0769 - val_accuracy: 0.9837\n",
      "Epoch 926/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9839 - val_loss: 0.0768 - val_accuracy: 0.9837\n",
      "Epoch 927/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9839 - val_loss: 0.0768 - val_accuracy: 0.9837\n",
      "Epoch 928/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9837 - val_loss: 0.0768 - val_accuracy: 0.9837\n",
      "Epoch 929/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0735 - accuracy: 0.9834 - val_loss: 0.0767 - val_accuracy: 0.9837\n",
      "Epoch 930/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9837 - val_loss: 0.0767 - val_accuracy: 0.9837\n",
      "Epoch 931/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9837 - val_loss: 0.0766 - val_accuracy: 0.9837\n",
      "Epoch 932/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9841 - val_loss: 0.0766 - val_accuracy: 0.9837\n",
      "Epoch 933/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9841 - val_loss: 0.0766 - val_accuracy: 0.9837\n",
      "Epoch 934/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9837 - val_loss: 0.0764 - val_accuracy: 0.9837\n",
      "Epoch 935/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9837 - val_loss: 0.0765 - val_accuracy: 0.9837\n",
      "Epoch 936/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9841 - val_loss: 0.0764 - val_accuracy: 0.9837\n",
      "Epoch 937/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9837 - val_loss: 0.0764 - val_accuracy: 0.9837\n",
      "Epoch 938/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9841 - val_loss: 0.0764 - val_accuracy: 0.9837\n",
      "Epoch 939/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9841 - val_loss: 0.0763 - val_accuracy: 0.9837\n",
      "Epoch 940/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9841 - val_loss: 0.0763 - val_accuracy: 0.9837\n",
      "Epoch 941/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9839 - val_loss: 0.0762 - val_accuracy: 0.9837\n",
      "Epoch 942/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9841 - val_loss: 0.0762 - val_accuracy: 0.9837\n",
      "Epoch 943/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9837 - val_loss: 0.0761 - val_accuracy: 0.9837\n",
      "Epoch 944/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9841 - val_loss: 0.0761 - val_accuracy: 0.9837\n",
      "Epoch 945/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9841 - val_loss: 0.0761 - val_accuracy: 0.9837\n",
      "Epoch 946/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9836 - val_loss: 0.0759 - val_accuracy: 0.9837\n",
      "Epoch 947/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9839 - val_loss: 0.0759 - val_accuracy: 0.9837\n",
      "Epoch 948/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9839 - val_loss: 0.0759 - val_accuracy: 0.9837\n",
      "Epoch 949/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9837 - val_loss: 0.0759 - val_accuracy: 0.9837\n",
      "Epoch 950/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9837 - val_loss: 0.0758 - val_accuracy: 0.9837\n",
      "Epoch 951/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9837 - val_loss: 0.0758 - val_accuracy: 0.9837\n",
      "Epoch 952/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9841 - val_loss: 0.0757 - val_accuracy: 0.9837\n",
      "Epoch 953/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9841 - val_loss: 0.0757 - val_accuracy: 0.9837\n",
      "Epoch 954/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9839 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 955/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9837 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 956/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0723 - accuracy: 0.9837 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 957/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0723 - accuracy: 0.9837 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 958/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0723 - accuracy: 0.9841 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 959/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0722 - accuracy: 0.9837 - val_loss: 0.0754 - val_accuracy: 0.9837\n",
      "Epoch 960/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9841 - val_loss: 0.0754 - val_accuracy: 0.9837\n",
      "Epoch 961/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9839 - val_loss: 0.0754 - val_accuracy: 0.9837\n",
      "Epoch 962/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 0.9841 - val_loss: 0.0754 - val_accuracy: 0.9837\n",
      "Epoch 963/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 0.9839 - val_loss: 0.0753 - val_accuracy: 0.9837\n",
      "Epoch 964/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 0.9842 - val_loss: 0.0753 - val_accuracy: 0.9837\n",
      "Epoch 965/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 0.9841 - val_loss: 0.0752 - val_accuracy: 0.9837\n",
      "Epoch 966/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9841 - val_loss: 0.0751 - val_accuracy: 0.9837\n",
      "Epoch 967/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9841 - val_loss: 0.0751 - val_accuracy: 0.9837\n",
      "Epoch 968/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9841 - val_loss: 0.0751 - val_accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0718 - accuracy: 0.9841 - val_loss: 0.0750 - val_accuracy: 0.9837\n",
      "Epoch 970/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 0.9841 - val_loss: 0.0750 - val_accuracy: 0.9837\n",
      "Epoch 971/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9841 - val_loss: 0.0750 - val_accuracy: 0.9837\n",
      "Epoch 972/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0717 - accuracy: 0.9837 - val_loss: 0.0749 - val_accuracy: 0.9837\n",
      "Epoch 973/1000\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0716 - accuracy: 0.9839 - val_loss: 0.0749 - val_accuracy: 0.9837\n",
      "Epoch 974/1000\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9839 - val_loss: 0.0749 - val_accuracy: 0.9837\n",
      "Epoch 975/1000\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.98 - 0s 8ms/step - loss: 0.0716 - accuracy: 0.9841 - val_loss: 0.0749 - val_accuracy: 0.9837\n",
      "Epoch 976/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9841 - val_loss: 0.0748 - val_accuracy: 0.9837\n",
      "Epoch 977/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9841 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 978/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9841 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 979/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.9837 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 980/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9837 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 981/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9841 - val_loss: 0.0746 - val_accuracy: 0.9837\n",
      "Epoch 982/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0713 - accuracy: 0.9842 - val_loss: 0.0745 - val_accuracy: 0.9837\n",
      "Epoch 983/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9842 - val_loss: 0.0745 - val_accuracy: 0.9837\n",
      "Epoch 984/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9841 - val_loss: 0.0745 - val_accuracy: 0.9837\n",
      "Epoch 985/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9841 - val_loss: 0.0744 - val_accuracy: 0.9837\n",
      "Epoch 986/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9839 - val_loss: 0.0743 - val_accuracy: 0.9837\n",
      "Epoch 987/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9841 - val_loss: 0.0744 - val_accuracy: 0.9837\n",
      "Epoch 988/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9841 - val_loss: 0.0742 - val_accuracy: 0.9831\n",
      "Epoch 989/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9841 - val_loss: 0.0743 - val_accuracy: 0.9837\n",
      "Epoch 990/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9841 - val_loss: 0.0743 - val_accuracy: 0.9837\n",
      "Epoch 991/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9839 - val_loss: 0.0741 - val_accuracy: 0.9831\n",
      "Epoch 992/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9841 - val_loss: 0.0742 - val_accuracy: 0.9837\n",
      "Epoch 993/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9839 - val_loss: 0.0741 - val_accuracy: 0.9837\n",
      "Epoch 994/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9841 - val_loss: 0.0741 - val_accuracy: 0.9837\n",
      "Epoch 995/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9841 - val_loss: 0.0740 - val_accuracy: 0.9837\n",
      "Epoch 996/1000\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9837 - val_loss: 0.0739 - val_accuracy: 0.9831\n",
      "Epoch 997/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9839 - val_loss: 0.0740 - val_accuracy: 0.9837\n",
      "Epoch 998/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9841 - val_loss: 0.0740 - val_accuracy: 0.9837\n",
      "Epoch 999/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9841 - val_loss: 0.0739 - val_accuracy: 0.9837\n",
      "Epoch 1000/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9839 - val_loss: 0.0738 - val_accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "history=picmodel.fit(x=X_train,y=Y_train,batch_size=150,epochs=1000,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9837\n",
      "Test Loss=0.0738297700881958\n",
      "Test Accuacy =0.9837499856948853\n"
     ]
    }
   ],
   "source": [
    "preds = picmodel.evaluate(x=X_test,y=Y_test)\n",
    "print('Test Loss=' + str(preds[0]))\n",
    "print(\"Test Accuacy =\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim((0, 1)) # Uncomment this when showing you model for pay raise\n",
    "plt.text(100,0.6,\"accuracy=\"+str(round(preds[1],3)))\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "#plt.savefig(\"accuary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.text(100,1.25,\"loss=\"+str(round(preds[0],3)))\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "#plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "picmodel.save(\"alphabet_model_20200729.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "picmodel = load_model(\"./english_model_20200729.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0373114   7.549035    1.4696196  -1.5160872   0.15948755  1.5815539 ]\n",
      " [-6.677024   -2.5409868  -1.0440102   1.9445404   1.9279445  -0.8973275 ]\n",
      " [-8.051447    0.5946708   3.2355623   3.1867304   0.35500947 -1.5447552 ]]\n",
      "8.051447\n",
      "[ 0.12883541  0.9375998   0.18252863 -0.18829997  0.01980856  0.19643103\n",
      " -0.8292949  -0.3155938  -0.1296674   0.2415144   0.23945318 -0.11144922\n",
      " -1.          0.07385887  0.40186098  0.395796    0.04409263 -0.19186057]\n"
     ]
    }
   ],
   "source": [
    "kernel_weights=np.squeeze(picmodel.get_weights())\n",
    "#print(kernel_weights.flatten())\n",
    "a1=np.squeeze(kernel_weights)[0:3,0:6].flatten()\n",
    "print(kernel_weights)\n",
    "N=abs(a1.flatten())[np.argmax(abs(a1.flatten()))]\n",
    "print(N)\n",
    "a1_nor=a1.flatten()/N\n",
    "print(a1_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"JSmodel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 10, 1)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 12, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 2, 1)           18        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 2, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "picmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the layer output, you need run the part with raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output every laryer result\n",
    "def get_layer_output(model,x,index=0):\n",
    "    layer = K.function([model.input],[model.layers[index].output])\n",
    "    return layer([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000 Counter({'A': 993, 'F': 4, 'D': 2, 'E': 1})\n"
     ]
    }
   ],
   "source": [
    "#check ouput for \"A\"\n",
    "\n",
    "path=\"./twolayerdata_english/A/\"\n",
    "imlist=os.listdir(path)\n",
    "print(len(imlist))\n",
    "#rlist=random.sample(imlist,1000)\n",
    "one_t=[]\n",
    "One_t=[]\n",
    "fn_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/A/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    one_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"A\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        fn_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)])\n",
    "        One_t.append(elef) \n",
    "one1=collections.Counter(one_t)\n",
    "print(len(one_t),collections.Counter(one_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'B': 974, 'E': 18, 'C': 8})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/B/\"\n",
    "imlist=os.listdir(path)\n",
    "#rlist=random.sample(imlist,1000)\n",
    "two_t=[]\n",
    "Two_t=[]\n",
    "B_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/B/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    two_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_4)]==\"B\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        B_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)]) \n",
    "        Two_t.append(elef)\n",
    "two1=collections.Counter(two_t)\n",
    "print(len(two_t),collections.Counter(two_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'C': 898, 'H': 60, 'D': 34, 'E': 8})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/C/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "three_t=[]\n",
    "Three_t=[]\n",
    "C_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/C/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    three_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_4)]==\"C\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        C_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)])\n",
    "        Three_t.append(elef)\n",
    "three1=collections.Counter(three_t)\n",
    "print(len(three_t),collections.Counter(three_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'D': 996, 'E': 2, 'H': 1, 'C': 1})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/D/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "four_t=[]\n",
    "Four_t=[]\n",
    "D_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/D/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    four_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_2)]==\"D\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        D_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_4)])\n",
    "        Four_t.append(elef)\n",
    "four1=collections.Counter(four_t)\n",
    "print(len(four_t),collections.Counter(four_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'E': 989, 'H': 6, 'F': 2, 'A': 1, 'C': 1, 'D': 1})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/E/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "five_t=[]\n",
    "Five_t=[]\n",
    "E_t=[]\n",
    "#print(len(imlist))\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/E/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    five_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_4)]==\"E\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        E_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_4)])\n",
    "        Five_t.append(elef)\n",
    "five1=collections.Counter(five_t)\n",
    "print(len(five_t),collections.Counter(five_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'F': 980, 'D': 20})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/F/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "six_t=[]\n",
    "Six_t=[]\n",
    "F_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/F/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    six_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"F\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        F_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)])\n",
    "        Six_t.append(elef)\n",
    "six1=collections.Counter(six_t)\n",
    "print(len(six_t),collections.Counter(six_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'G': 917, 'C': 57, 'E': 24, 'H': 2})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/G/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "seven_t=[]\n",
    "Seven_t=[]\n",
    "G_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/G/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    seven_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"G\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        G_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)])\n",
    "        Seven_t.append(elef)\n",
    "seven1=collections.Counter(seven_t)\n",
    "print(len(seven_t),collections.Counter(seven_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Counter({'H': 995, 'D': 5})\n"
     ]
    }
   ],
   "source": [
    "path=\"./twolayerdata_english/H/\"\n",
    "imlist=os.listdir(path)\n",
    "#rmlist=random.sample(imlist,1000)\n",
    "eight_t=[]\n",
    "Eight_t=[]\n",
    "H_t=[]\n",
    "for elef in imlist:\n",
    "    input_y=np.load(\"./twolayerdata_english/H/\"+elef)\n",
    "    input_y=input_y[0][1:11,1:11]\n",
    "    input_x = np.expand_dims(input_y,axis=0)\n",
    "    input_x = np.expand_dims(input_x,axis=3)\n",
    "    layer_1 = get_layer_output(picmodel,input_x,index=1)\n",
    "    layer_2 = get_layer_output(picmodel,input_x,index=2)\n",
    "    layer_3 = get_layer_output(picmodel,input_x,index=3)\n",
    "    layer_4 = get_layer_output(picmodel,input_x,index=4)\n",
    "    layer_5 = get_layer_output(picmodel,input_x,index=5)\n",
    "    eight_t.append(class_names[np.argmax(layer_5)])\n",
    "    if class_names[np.argmax(layer_5)]==\"H\":\n",
    "        FN_t=[]\n",
    "        FN_t.append(elef)\n",
    "        FN_t.append(layer_2.flatten())\n",
    "        H_t.append(FN_t)\n",
    "        #print(elef,layer_2.flatten(),class_names[np.argmax(layer_5)])\n",
    "        Eight_t.append(elef)\n",
    "eight1=collections.Counter(eight_t)\n",
    "print(len(eight_t),collections.Counter(eight_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output the model accuracy on every character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "C:\\Users\\dirac\\miniconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWkAAAJOCAYAAADF44XfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABtsUlEQVR4nO3de5xVdb3/8ddH0LzjjRABxVJRFESb0tKTHsk0K9EOFaUJ/jBOalbe9XhOdTrVUdNMKysLA9PygqaWZllqHS+RqIS3OnK8ASqSdzEv4Of3x15Dm2FgmNtea2Zez8djHrPXZe/9nsXms9d85ru+OzITSZIkSZIkSVI51ig7gCRJkiRJkiT1ZTZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aaVCRGwZES9HRL9V7PNyRLytkbkkqbey7kpSY7VVUyPi/ojYu3GJJKn38lxX7WWTVt0mIm6JiOci4i1lZ1kdmfl4Zq6fmUthWf4jWuyzfmY+XE5CSWpdRDwaEX8vTvKei4jrImJY2bnaYt2V1FNFxCcjYlZRd5+MiF9FxJ5l52pLfU2NiGkR8dUW23fMzFtKCSdJrag7z30pIp6PiNsj4jMRUfl+lue6aq/Kv6jVM0XEcOCfgAQObMf9oicUW0mqoA9n5vrAYGAh8O3VuZN1V5LaJyKOA74FfB0YBGwJnA+MW837r3RElSSpVR/OzA2ArYDTgZOBqatzR8911ZP4QlV3OQz4IzANmLiqHYu/Jn0tIm4DXgHeFhHbR8SNEfFsRPw1Ij5Wt/+mEfGLiHgxIu6MiK9GxK11299TrH+h+P6eFs/1XxFxW/GXuN9ExGbFtuERkRHRPyK+Rq3J/J1ihMR3in0yIrYpbg+IiIsiYlFEPBYR/95c/CNiUkTcGhFnFaPaHomID3TNoZWklcvMV4EZwMiV7WPdlaSOiYgBwFeAozPzqsxcnJlvZOYvMvPEldxnWkR8LyKuj4jFwD9HxBYRcWVRzx6JiM/V7b9OREwvatmDEXFSRMyv275DUVufj9r0BAe2eK7vRu2KipciYmZEvL1ue0bENhExBTgEOKmoub8otj8aEe8rbr8lIr4VEU8UX9+K4gq5iNg7IuZHxPER8XTURhMf3qUHW5JayMwXMvNa4OPAxIjYqbX9PNdVT2WTVt3lMOCS4mu/iBjUxv6fAqYAGwCLgBuBnwJvBSYA50dEc8Phu8BiYHNqDeBlTeCI2AS4DjgP2BT4JnBdRGxa91yfBA4vHnst4ISWYTLzNOB/gM8Wlx98tpXM3wYGAG8D9ip+5vqT092AvwKbAWcCUyMi2jgOktQpEbEutRPXP7axq3VXktrv3cDawM/beb9PAl+jVnNvB34B/BkYAowFvhAR+xX7fgkYTq3W7Qsc2vwgEbFmcd/fUKupxwCXRMSIuueaAPwnsDEwt3je5WTmBdTO088sau6HW8l8GrA7MAbYGXgX8O912zenVpOHAJOB70bExqtzMCSpMzLzT8B8ak3PlfFcVz2OTVp1uajNx7UVcHlm3gX8H7WitSrTMvP+zFwC7A88mpk/zswlmXkPcCXw0ahdHvYvwJcy85XMfACYXvc4HwQeysyfFPf9GfAXoP7E88eZ+b+Z+Xfgcmonnu39GftRK+ynZuZLmfkocDa1N4Jmj2XmD4v5Z6ZTuwS5rWa1JHXU1RHxPPACtV/qv9HG/tZdSWq/TYG/FbWzPa7JzNsy801gFDAwM7+Sma8XcxH+kFqNA/gY8PXMfC4z51NrDDTbHVgfOL24703AL4FP1O3z88z8U5HxEjpQcwuHAF/JzKczcxG1xm99zX2j2P5GZl4PvAyMaOVxJKk7PAFssortnuuqx+lfdgD1ShOB32Tm34rlnxbrzlnFfebV3d4K2K1oNjTrD/wEGFjcrt+//vYWwGMtHvsxan/hb/ZU3e1XqJ3ottdmwJotnmulz5OZrxR/4OrIc0nS6jgoM39bnOCNA34fESMz86mV7G/dlaT2ewbYLCL6t7NR27LmbtGi5vajNsIKanV1VTV3XtHsbdYdNbf5uVrW3C3qlp9pcQw681yS1F5DgGdXsd1zXfU4jqRVl4qIdaj99X+viHgqIp4CjgV2joidV3HXrLs9D/h9Zm5U97V+Zh5J7TKFJcDQuv3rP8H8CWoFuN6WwIIO/Di5im1/ozZ6oP65Ovo8ktRlMnNpZl4FLAVW9Unj1l1Jar87gNeAg9p5v5Y195EWNXeDzDyg2P4kq665w2L5D8Hpjprb/Fwta+4THXgeSepSEfFOas3LW1exm+e66nFs0qqrHUStMTCS2hD/McAO1EYGHLaaj/FLYLuI+FRErFl8vTMidiiG9V8FfDki1o2I7Vs87vXFfT9ZTM798SLLLzvwsyykNhfMCooclwNfi4gNImIr4Djg4g48jyR1magZR20uwgdX827WXUlaDZn5AvBFavOvHlTUxTUj4gMRceZqPsyfgJci4uSofUhYv4jYqWg6QK3WnRoRG0fEEKB+3sKZ1EZpnVQ8797ULrm9tAM/zkprbuFnwL9HxMDiQ3C+iDVXUokiYsOI+BC1mndxZt67mnf1XFc9gk1adbWJ1OZjeTwzn2r+Ar4DHBIRbU6xkZkvAe+nNh/LE9SG9J8BvKXY5bPUJtN+itrlCT+jNqKBzHwG+BBwPLXL0U4CPlQ39UJ7nAuMLz458bxWth9DbXLxh6n9Be+nwIUdeB5J6gq/iIiXgRepfUjMxMy8f3XuaN2VpNWXmWdT+8X536mNwJpHrU5evZr3X0qtbo4BHqE2eupH1OoswFeofSDOI8BvgRn8o+a+Tq0p+4HifucDh2XmXzrwo0wFRkbE8xHRWvavArOAOcC9wN3FOklqtF9ExEvU6u1p1D686/BV3+UfPNdVTxGZbV3lIlVbRJwBbJ6ZE9vcWZLUadZdSWqciDgSmJCZe5WdRZL6As91VRZH0qrHiYjtI2J0cUnvu4DJwM/LziVJvZV1V5IaJyIGR8QeEbFGRIygNnrLmitJ3cRzXVVFm5eeSxW0AbXLD7agNqfL2cA1pSaSpN7NuitJjbMW8ANga+B5anMvnl9mIEnq5TzXVSU43YEkSZIkSZIklcjpDiRJkiRJkiSpRJWe7mCzzTbL4cOHlx1DUh931113/S0zB5adoxGsu5KqoK/UXWuupCqw5kpSY62s7la6STt8+HBmzZpVdgxJfVxEPFZ2hkax7kqqgr5Sd625kqrAmitJjbWyuut0B5IkSZIkSZJUol7RpP3+97/PTjvtxMiRIznqqKNYunQpL774Ih//+McZNWoUo0aN4tprr122/wknnMDo0aPZZZdd2HPPPbn33ntLTC9Jy4uICyPi6Yi4r27dJhFxY0Q8VHzfuFgfEXFeRMyNiDkRsWvdfSYW+z8UERPL+FkapbX3gXPOOYcxY8Ys+1pzzTW55prlP6T18ssvJyK45ZZbygkuSeoS1113HTvvvDNjxozhPe95Dw8++CBLlizhM5/5DDvttBM77rgjF1xwwbL9Fy1axP7778/OO+/MyJEj+cEPflBieklSZ7S3JwRw+umnM2LECEaNGsXEib36VyX1ID2+SXv//ffzjW98g9tuu40HHniAiOCSSy7ha1/7GkOGDOHee+/l97//Paeeeiovv/wyAP/xH//BnDlzuOeeezjppJM46qijSv4pJGk504D9W6w7BfhdZm4L/K5YBvgAsG3xNQX4HtSausCXgN2AdwFfam7s9jYrex849thjmT17NrNnz+bnP/8566+/Pvvtt9+y+z377LOcd9557LbbbiWmlyR1hU9/+tNceumlzJ49m0MPPZQvfvGL/PCHP+Rvf/sbc+bMYdasWUydOpVHH30UgHPOOYedd96ZP//5z/z+97/nxBNP5KWXXir3h5AktVtHekKXXnopt912G/feey/33nsv3/jGN0r+KaSaHt+kfeCBB2hqamLAgAEA7Lffflx22WXcd9997LvvvgBssskmjBgxgl/96lcAy/YFePHFF4mIxgeXpJXIzD8Az7ZYPQ6YXtyeDhxUt/6irPkjsFFEDAb2A27MzGcz8zngRlZs/PYKK3sfqHfxxRczfvx41l577WXrjj/+eP7zP/9zuXWSpJ5pjTXW4MUXXwTghRdeYPDgwdx3332MHTuWNdZYg3XWWYc99tiDK664Ytn+L7/8MpnJyy+/zEYbbcRaa61V5o8gSeqAjvSEzj33XL785S8vq/tvfetbywkvtdDjm7SjR4/mjjvu4Mknn2Tp0qVcccUVzJs3j1122YUZM2bw5ptvMm/ePG677TbmzZu37H5f/OIX2XrrrTn11FO9vElSTzAoM58sbj8FDCpuDwHm1e03v1i3svUriIgpETErImYtWrSoa1M3wMreB+pdfPHFHHbYYcuWb7zxRt58803Gjh3b6LiSpG5w8cUX86EPfYhhw4Yxbdo0vvjFL7LLLrtwzTXX8Nprr/Hcc8/x61//etn7wwknnMCDDz7IkCFDGDVqFOeccw5vectbSv4pJEnt1ZGe0F/+8hd+85vfsNtuu7HHHntw0003lfxTSDVtNmmrPjfiiBEj+PrXv86HP/xh9txzT7bcckv69evHqaeeSv/+/dl11135zGc+w1577UW/fv2W3e8rX/kKjzzyCN/97nc54YQTuiqOJHW7zEwgu/DxLsjMpsxsGjhwYFc9bMOs7H2g2cyZM3njjTfYc889AXjllVc49dRTOeuss8qKLEnqQkuWLOGMM87gpptuYt68eZxwwglMmjSJww8/nDFjxrDbbrvxL//yL+yxxx7L3h8uu+wy/umf/oknnniCBx98kBNPPJHHH3+85J9EktReHekJLVmyhJdeeomZM2dywQUXcMghh/DCCy+U/JNIqzeSdhoVnxvx0EMPZdasWdxxxx2MGTOG7bffnvXWW48f/OAHzJ49m+uuu47Fixez/fbbr3DfAw88kD/96U/87W9/66o4ktQdFhbTGFB8f7pYvwAYVrff0GLdytb3Sq29DzT7yU9+wqGHHrpsapv/+7//4/HHH+ed73wnw4cP549//CMTJkzgF7/4RVnxJUmdMHv2bJ599llGjRoFwCGHHMLNN99Mv379OP3005k9ezY33XQTa6655rL3h29/+9tMmDABgGHDhtHU1MTMmTNL+xmkvqLqg8DUM7W3JzRs2DA++tGPArDjjjsybNgwHnrooTJ/BAlYjSZtT5gbceHChUBt/qkzzzyTY445hhdeeIHXXnsNgD/84Q88/vjjy+Yj+ctf/rLsvrfccgtrrrkmm266aVfFkaTucC3QfAI6Ebimbv1hxUns7sALxbQIvwbeHxEbFye67y/W9UqtvQ8AvPHGG1x22WXLTXUwatQonn76aR599FEeffRRdt99dy699FI+/OEPl5JdktQ5Q4cOZe7cuSxYUPtb5A033MDIkSP5+9//vuzDwB544AFuuOEGPvnJTwKw1VZb8dvf/haA5557jjvvvJMddtihnB9A6lumUfFBYOp52tsTGj9+/LL3gHnz5vH444/z9re/vZzwUp3+Hbxft86NSK0As+WWW65WmAkTJrBw4UIykxNPPJH3vOc9/OlPf+KQQw6hf//+DBo0iBkzZrDGGrWe9Be+8AXmz59P//792XDDDbn66qv98DBJlRERPwP2BjaLiPnUTkJPBy6PiMnAY8DHit2vBw4A5gKvAIcDZOazEfFfwJ3Ffl/JzJZ/cOs1WnsfAPjVr37FtttuyzbbbFNyQklSd9l8880566yzeP/730///v1Zb731mDp1Kn/729/Yd999WWONNVh//fW55JJL2GCDDQA455xzmDJlCj/84Q9ZsmQJxx13HDvttFPJP4nU+2XmHyJieIvV46id+0JtENgtwMnUDQID/hgRzYPA9qYYBAYQEc2DwH7W3flVTe3tCZ144olMmjSJnXbaiX79+vGDH/yAjTe2z6/yRa3etbFTrYj+MjN3Kpafz8yN6rY/l5kbR8QvgdMz89Zi/e+oFde9gbUz86vF+v8A/p6Zq5wQsKmpKWfNmtWRn0uSukxE3JWZTWXnaATrrqQq6Ct115orqQoaXXNX1V+I2uip5zJzo67oL7QYBPaOxx57rJt/Oklq28rqbkdH0i6MiMGZ+WQ75kbcu8X6W9r7pJ886ZIOhe2Mn555SMOfU5LUurvOPKLhz/mOk37U8OeUJK1o0o8/X8rzTjv83FKeV+qLMjMjoks/IBe4AGp/GOuqx1U5rj/s8IY/5wEX/bjhz6m+a3U+OKw1zo0oSZIkSZI6yw/IlSRWo0lbzI14BzAiIuYX8yGeDuwbEQ8B7yuWoTY34sPU5kb8IXAU1OZGBJrnRryTXj43oiRJkiRJWi0OApMkVmO6g8z8xEo2jW1l3wSOXsnjXAhc2K50kiRJkiSpV/ADciVp5To6J60kSZIkSdJqcxCYJK1cR+eklSRJkiRJkiR1AZu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSVIrIuLYiLg/Iu6LiJ9FxNoRsXVEzIyIuRFxWUSsVez7lmJ5brF9eMnxJUmS1IPYpJUkSZJaiIghwOeApszcCegHTADOAM7JzG2A54DJxV0mA88V688p9pMkSZJWi01aSZIkqXX9gXUioj+wLvAksA8wo9g+HTiouD2uWKbYPjYionFRJUmS1JPZpJUkSZJayMwFwFnA49Sasy8AdwHPZ+aSYrf5wJDi9hBgXnHfJcX+m7Z83IiYEhGzImLWokWLuveHkCRJUo9hk1aSJElqISI2pjY6dmtgC2A9YP/OPm5mXpCZTZnZNHDgwM4+nCRJknoJm7SSJEnSit4HPJKZizLzDeAqYA9go2L6A4ChwILi9gJgGECxfQDwTGMjS5IkqaeySStJkiSt6HFg94hYt5hbdizwAHAzML7YZyJwTXH72mKZYvtNmZkNzCtJkqQezCatJEmS1EJmzqT2AWB3A/dSO2++ADgZOC4i5lKbc3ZqcZepwKbF+uOAUxoeWpIkST1W/7Z3kSRJkvqezPwS8KUWqx8G3tXKvq8CH21ELkmSJPU+jqSVJEmSJEmSpBLZpJUkSZIkSZKkEtmklSRJkiRJkqQS2aSVJEmSJEmSpBLZpJUkSZIkSZKkEtmklSRJkiRJkqQS2aSVJEmSJEmSpBLZpJWkHiQijo2I+yPivoj4WUSsHRFbR8TMiJgbEZdFxFrFvm8plucW24eXHF+SJEmSJLXCJq0k9RARMQT4HNCUmTsB/YAJwBnAOZm5DfAcMLm4y2TguWL9OcV+kiRJkiSpYmzSSlLP0h9YJyL6A+sCTwL7ADOK7dOBg4rb44pliu1jIyIaF1WSJEmSJK0Om7SS1ENk5gLgLOBxas3ZF4C7gOczc0mx23xgSHF7CDCvuO+SYv9NWz5uREyJiFkRMWvRokXd+0NIkiRJkqQVdKpJ69yIktQ4EbExtdGxWwNbAOsB+3f2cTPzgsxsysymgQMHdvbhJEmSpHazvyCpr+twk9a5ESWp4d4HPJKZizLzDeAqYA9go2L6A4ChwILi9gJgGECxfQDwTGMjS5IkSatmf0GSOj/dgXMjSlLjPA7sHhHrFvVzLPAAcDMwvthnInBNcfvaYpli+02ZmQ3MK0mSJK0u+wuS+rQON2mdG1GSGiszZ1I7Cb0buJdaDb8AOBk4LiLmUqurU4u7TAU2LdYfB5zS8NCSJElSG+wvSFLtL1Ud0mJuxOeBK+iiuRGpNR1oampyxJck1cnMLwFfarH6YeBdrez7KvDRRuSSJEmSOsr+giR1broD50aUJEmSJEmdZX9BUp/XmSatcyNKkiRJkqTOsr8gqc/rzJy0zo0oSZIkSZI6xf6CJHViTlpwbkRJkiRJktR59hck9XWdme5AkiRJkiRJktRJNmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkqRWRMRGETEjIv4SEQ9GxLsjYpOIuDEiHiq+b1zsGxFxXkTMjYg5EbFr2fklSZLUc9iklSRJklp3LnBDZm4P7Aw8CJwC/C4ztwV+VywDfADYtviaAnyv8XElSZLUU9mklSRJklqIiAHAe4GpAJn5emY+D4wDphe7TQcOKm6PAy7Kmj8CG0XE4IaGliRJUo9lk1aSJEla0dbAIuDHEXFPRPwoItYDBmXmk8U+TwGDittDgHl1959frFtOREyJiFkRMWvRokXdGF+SJEk9iU1aSZIkaUX9gV2B72XmLsBi/jG1AQCZmUC250Ez84LMbMrMpoEDB3ZZWEmSJPVsNmklSZKkFc0H5mfmzGJ5BrWm7cLmaQyK708X2xcAw+ruP7RYJ0mSJLXJJq0kSZLUQmY+BcyLiBHFqrHAA8C1wMRi3UTgmuL2tcBhUbM78ELdtAiSJEnSKvUvO4AkSZJUUccAl0TEWsDDwOHUBjlcHhGTgceAjxX7Xg8cAMwFXin2lSRJklaLTVpJkiSpFZk5G2hqZdPYVvZN4OjuziRJkqTeyekOJEmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJakHiYiNImJGRPwlIh6MiHdHxCYRcWNEPFR837jYNyLivIiYGxFzImLXsvNLkiRJkqQV2aSVpJ7lXOCGzNwe2Bl4EDgF+F1mbgv8rlgG+ACwbfE1Bfhe4+NKkiRJkqS22KSVpB4iIgYA7wWmAmTm65n5PDAOmF7sNh04qLg9Drgoa/4IbBQRgxsaWpIkSZIktalTTVovu5WkhtoaWAT8OCLuiYgfRcR6wKDMfLLY5ylgUHF7CDCv7v7zi3XLiYgpETErImYtWrSoG+NLkiRJkqTWdHYkrZfdSlLj9Ad2Bb6XmbsAi/lHjQUgMxPI9jxoZl6QmU2Z2TRw4MAuCytJkiStLgeBSerrOtyk9bJbSWq4+cD8zJxZLM+g1rRd2FxPi+9PF9sXAMPq7j+0WCdJkiRVjYPAJPVpnRlJ62W3ktRAmfkUMC8iRhSrxgIPANcCE4t1E4FritvXAocVIw12B16oq8+SJElSJTgITJI616T1sltJarxjgEsiYg4wBvg6cDqwb0Q8BLyvWAa4HngYmAv8EDiq4WklSZKktjkITFKf178T923tsttTKC67zcwnvexWkrpWZs4GmlrZNLaVfRM4urszSZIkSZ3UPAjsmMycGRHn0sogsIho9yAw4AKApqamdt1XkhqtwyNpvexWkiRJkiR1AT97QVKf15mRtPCPy27XonZJ7eHUGr+XR8Rk4DHgY8W+1wMHULvs9pViX0mSJEmS1Idl5lMRMS8iRmTmX/nHILAHqA3+Op0VB4F9NiIuBXbDQWCSeoFONWm97FaSJEmSJHUBB4FJ6tM6O5JWkiRJkiSpUxwEJqmv6/CctJIkSZIkSZKkzrNJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiStRET0i4h7IuKXxfLWETEzIuZGxGURsVax/i3F8txi+/BSg0uSJKlHsUkrSZIkrdzngQfrls8AzsnMbYDngMnF+snAc8X6c4r9JEmSpNVik1aSJElqRUQMBT4I/KhYDmAfYEaxy3TgoOL2uGKZYvvYYn9JkiSpTTZpJUmSpNZ9CzgJeLNY3hR4PjOXFMvzgSHF7SHAPIBi+wvF/suJiCkRMSsiZi1atKgbo0uSJKknsUkrSZIktRARHwKezsy7uvJxM/OCzGzKzKaBAwd25UNLkiSpB+tfdgBJkiSpgvYADoyIA4C1gQ2Bc4GNIqJ/MVp2KLCg2H8BMAyYHxH9gQHAM42PLUmSpJ7IkbSSJElSC5l5amYOzczhwATgpsw8BLgZGF/sNhG4prh9bbFMsf2mzMwGRpYkSVIPZpNWkiRJWn0nA8dFxFxqc85OLdZPBTYt1h8HnFJSPkmSJPVATncgSZIkrUJm3gLcUtx+GHhXK/u8Cny0ocEkSZLUaziSVpJ6kIjoFxH3RMQvi+WtI2JmRMyNiMsiYq1i/VuK5bnF9uGlBpckSZIkSSvV6SatDQNJaqjPAw/WLZ8BnJOZ2wDPAZOL9ZOB54r15xT7SZIkSZKkCuqKkbQ2DCSpASJiKPBB4EfFcgD7ADOKXaYDBxW3xxXLFNvHFvtLkiRJleQgMEl9WaeatDYMJKmhvgWcBLxZLG8KPJ+ZS4rl+cCQ4vYQYB5Asf2FYv8VRMSUiJgVEbMWLVrUTdElSZKkNjkITFKf1dmRtN+iixsGNgskaUUR8SHg6cy8q6sfOzMvyMymzGwaOHBgVz+8JEmS1CYHgUnq6zrcpO2uhoHNAklq1R7AgRHxKHAptRPWc4GNIqJ/sc9QYEFxewEwDKDYPgB4ppGBJUmSpHb4Fg4Ck9SHdWYkrQ0DSWqQzDw1M4dm5nBgAnBTZh4C3AyML3abCFxT3L62WKbYflNmZgMjS5IkSavFQWCS1IkmrQ0DSaqEk4HjImIutdEDU4v1U4FNi/XHAaeUlE+SJElqi4PAJPV5/dvepd1OBi6NiK8C97B8w+AnRcPgWWqNXUlSO2XmLcAtxe2HgXe1ss+rwEcbGkySJEnqgMw8FTgVICL2Bk7IzEMi4gpqg7wupfVBYHfgIDBJvUSXNGltGEiSJEmSpC7mIDBJfUZ3jKSVJEmSJElqNweBSeqrOvPBYZIkSZIkSZKkTrJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiS1EBHDIuLmiHggIu6PiM8X6zeJiBsj4qHi+8bF+oiI8yJibkTMiYhdy/0JJEmS1JPYpJUkSZJWtAQ4PjNHArsDR0fESOAU4HeZuS3wu2IZ4APAtsXXFOB7jY8sSZKknsomrSRJktRCZj6ZmXcXt18CHgSGAOOA6cVu04GDitvjgIuy5o/ARhExuLGpJUmS1FPZpJUkSZJWISKGA7sAM4FBmflksekpYFBxewgwr+5u84t1LR9rSkTMiohZixYt6r7QkiRJ6lFs0kpSD+H8iJLUeBGxPnAl8IXMfLF+W2YmkO15vMy8IDObMrNp4MCBXZhUkiRJPVmHm7Q2CySp4ZwfUZIaKCLWpNagvSQzrypWL2yexqD4/nSxfgEwrO7uQ4t1kqQ22F+QpM6NpLVZIEkN5PyIktQ4ERHAVODBzPxm3aZrgYnF7YnANXXrDysaB7sDL9RNiyBJWjX7C5L6vA43aW0WSFJ5nB9RkrrdHsCngH0iYnbxdQBwOrBvRDwEvK9YBrgeeBiYC/wQOKqEzJLUI9lfkCTo3xUP0slmwXIjDCJiCrW/hLHlllt2RTxJ6lVazo9YG+xVk5kZEe2eHxG4AKCpqald95Wk3iozbwViJZvHtrJ/Akd3ayhJ6gPsL0jqqzr9wWF+mIIkNY7zI0qSJKm3sr8gqS/rVJPWZoEkNY7zI0qSJKm3sr8gqa/rcJPWZoEkNZzzI0qSJKnXsb8gSZ2bk7a5WXBvRMwu1v0btebA5RExGXgM+Fix7XrgAGrNgleAwzvx3JLU5zg/oiRJknop+wuS+rwON2ltFkiSJEmSpM6yvyBJXfDBYZIkSZIkSZKkjrNJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSVKFLV68mEmTJjFixAh23HFHzj//fADOPfdcttlmG7bZZhvOO++8klNKkjqjf9kBJEmSJEnSyh1//PFst912TJs2DYCnn36ahx56iO985zvcc889AOy6664ccMABbLPNNiUmlSR1lCNpJUmSJEmqqJdeeomrr76aE088cdm6t771rVx11VV89KMfZYMNNmCDDTZg/PjxXHXVVSUmlSR1hk1aSZIkSZIq6uGHH2bgwIF8/vOfZ9ddd2XcuHE8+uijzJ8/n2HDhi3bb8stt2TevHklJpUkdYZNWkmSJEmSKmrJkiXcd999jBs3jrvvvptx48YxceJEMrPsaJKkLmSTVpIkSZKkiho6dCgDBgxgv/32A2DChAncddddDBs2bLmRs48//jhDhw4tK6YkqZNs0kqSJElSN9prr73YeeedGT16NOPHj+fFF19ctu2NN95gzJgx7L333uUFVKUNGjSI0aNHc+eddwJw4403MmrUKA4++GCuuOIKXnrpJV566SWuuOIKDj744JLTSpI6qn/ZASRJkiSpN7v22msZMGAAAMcddxzf+MY3+K//+i8AzjzzTEaNGuVcolql73//+xxxxBEsXryYAQMGcOGFF7Lddttx1FFHMWbMGACOOeYYtttuu3KDSpI6zCatJEmSJHWj5gbtm2++yeLFi1l//fUB+Otf/8of/vAHTjnlFP7zP/+zzIiquJEjR3L77bevsP7YY4/l2GOPLSGRJKmr2aSVJEmSpG52wAEHcOedd7Ljjjty9tlnk5kcddRRfPe73+Wpp54qO55KcvbZZ5fyvMcff3wpzytJWjmbtJIkSZLUza6//nqWLl3Kqaeeyvnnn88GG2zAHnvswfbbb2+TVpIk+cFhkiSpXEceeSRDhgwhIpaty0w+97nPseOOO7LDDjtw5JFHsnTp0hJTSlLn9evXj4kTJ3LRRRdx6623Mm3aNIYPH86ECRP44x//yNixY8uOKEmSSmKTVpIkleoTn/gEd99993LrbrzxRu666y7mzJnDfffdx+zZs7nhhhtKSihJHffcc8+xcOHCZctXXnklO+20E5dccgmPP/44jz76KJdeeim77747v/vd70pMKkmSymSTVpKkBrruuuvYeeedGTNmDO95z3t48MEHy45Uuve+970MGjRouXVrrLEGr776Kq+//jqvvfYar7/+OptvvnlJCSWp45577jk+9KEPMXr0aEaNGsV9993HueeeW3asZXxfkiSpGmzSSj3Y0UcfvdzlwZKq79Of/jSXXnops2fP5tBDD+WLX/xi2ZEqaezYsey1114MHjyYLbbYgr333pt3vOMdZceSpHZ729vexp133smcOXO49957ufzyy1f4w9Tee+/NLbfcUko+35ckSaoGPziswe677z4OO+wwXnrpJXbYYQcuueQSNthgAzMV5s2bx6RJk3jiiSdYY401+OAHP8gZZ5xRaiPyyCOP5Nprr+WJJ54gM0vL0dL//M//8PLLL5cdA6jWa6jKmfoCj3vb1lhjDV588UUAXnjhBQYPHlxqnqr+m911113MmzePJ598EoADDzyQGTNmMH78+IZnqeIxqlqmquXpS6p27KuWp7tdf9jhDX/OAy76cZc+XtXel6B6r6Oq5VF5qvZaqFqeqv7uXCVV7HlU7XVUtTyNfF07krbBPvOZz/DVr36Vhx56iO23354zzzyz7EiVytS/f3/OOOMMHnzwQe655x5mzpzJVVddVVoeaH2uxLK99tprnHLKKZx11lllRwGq9Rqqcqa+wOPetosvvpgPfehDDBs2jGnTppU+Yqmq/2bTpk1jn332YZ111mGdddbh4IMP5uabby4lSxWPUdUyVS1PX1K1Y1+1PGpb1d6XoHqvo6rlUXmq9lqoWp4q/u5cNVXseVTtdVS1PI18XdukbaCFCxfyyCOPcMABBwAwefJkrrzySjPVGTx4ME1NTQCstdZajB49mnnz5pWWB1qfK7FsX/nKV5g8eTIDBw4sO0rlXkNVzdQXeNzbtmTJEs444wxuuukm5s2bxwknnMCkSZNKy1Plf7OtttqKm2++mTfffJOlS5fy29/+lpEjRzY8RxWPUdUyVS1PX1K1Y1+1PGpb1d6XoHqvo6rlUXmq9lqoWh6o5u/OVVO1nkfVXkdVywONfV3bpG2g+fPnM3To0GXLW265ZekNyCpmavbMM89w9dVXs99++5UdpVLmzJnDzJkzOfzwxl9e15oqvoaqmKkv8Li3bfbs2Tz77LOMGjUKgEMOOaS00aFQnX+zI444YlmOoUOHcsQRR3D00Uez5pprstNOOzF69Gg22WQTpkyZ0vBsVTlG9aqWqWp5+pKqHfuq5VHbqva+BNV7HVUtj8pTtddC1fKo/arQ86ja66hqeRrNOWkbqIpzslQxE9Qu5x8/fjxf+MIX2GGHHcqOUym33XYbDzzwAFtvvfWydcOHD+fOO+8sZWRtFV9DVczUF3jc2zZ06FDmzp3LggULGDJkCDfccEMpo0ObVeXf7Ec/+lGr6y+55JIGJ1lRVY5RvaplqlqevqRqx75qedS2qr0vQfVeR1XLo/JU7bVQtTxqn6r0PKr2OqpankazSdtAQ4cOZf78+cuWH3/88eX+QlCGKmZaunQphxxyCLvssgvHH398qVmq6Mgjj+TII49cthwRPProo6XlqeJrqIqZ+gKPe9s233xzzjrrLN7//vfTv39/1ltvPaZOnVpankb8m339tBld+nir49++1nUfLlbF13XVMlUtT19StWNftTxqW9Xel6B6r6Oq5VF5qvZaqFoerb4q9Tyq9jqqWp5Ga/h0BxGxf0T8NSLmRsQpjX7+Mm2++eYMHz6c66+/HoCpU6fykY98xEwt/Ou//isbbLABZ599dqk5tHqq+BqqYqayNLLmetxXz+GHH87999/Pn//8Z26//XZGjx5dWhb/zdpWxWNUtUxVy1OmRp/nVu3YVy2PVk+V3pegeq+jquXR8vryuW7V8mj1VannUbXXUdXyNFo0cihxRPQD/hfYF5gP3Al8IjMfaG3/pqamnDVr1rLlT57U+Msef3rmIV36eHPmzGHixIm8/PLLjBgxgksuuYQBAwZ06XP05Ey33XYbe+65JzvttBP9+vUD4P/9v//H5z73uVLyQG2uxBtuuGHZZWD777//Si/N7auq9BrqjkwRcVdmNnVxxG7X3poLK9bd9uru18JdZx7RZY+1ut5x0sr/v0/68ecbmKRm2uHndunjdfe/WU8fSQu9v8ZVMU9PrLtl1Fzo/a+FemXUXFh13b3+sMZ/RsABF/14pdt6Q82FvvW6LqtJUz96ryfWXOh8f6Ej+tJrsyO6+3fnqtXcjqhiz6Nqr6Oq5emO1/XK6m6jpzt4FzA3Mx8uQl0KjANWevLa24wePZp77rmn7BjLqVKmPfbYo3JzkHR3Q/abp/5rtz5+a4777x906eNV6TXUrIqZStDwmutx73n8N2tbFY9R1TJVLU9JSjnPrdqxr1oe9UxVex1VLY+W6fPnulXL42CmtlWx51G111HV8jTydd3okbTjgf0z84hi+VPAbpn52bp9pgDNH988AvhrFz39ZsDfuuixuoJ52la1TOZpW9UydVWerTKz8Z/K1kmrU3OL9d1Rd3vra6ErVS2TedpWtUxVywN9uO5ac1dQtUzmaVvVMlUtD1QvU5+tuWB/oQXztK1qmaqWB6qXqTfnabXuVu6DwzLzAuCCrn7ciJhVpUs4zNO2qmUyT9uqlqlqeaqqO+pu1Y591fJA9TKZp21Vy1S1PFDNTFXTF2ouVC+TedpWtUxVywPVy1S1PFVkf6EcVcsD1ctUtTxQvUx9MU+jPzhsATCsbnlosU6S1PWsuZLUONZcSWos666kXqXRTdo7gW0jYuuIWAuYAFzb4AyS1FdYcyWpcay5ktRY1l1JvUpDpzvIzCUR8Vng10A/4MLMvL9BT9/llzh0knnaVrVM5mlb1TJVLU9DWXOXU7U8UL1M5mlb1TJVLQ9UM1NDWHNXULVM5mlb1TJVLQ9UL1PV8jSUdXc55mlb1TJVLQ9UL1Ofy9PQDw6TJEmSJEmSJC2v0dMdSJIkSZIkSZLq2KSVJEmSJEmSpBL1+iZtRBwUERkR21cgy9KImB0Rf46IuyPiPRXItHlEXBoR/xcRd0XE9RGxXYl5mo/R/cVxOj4iSn2d1mVq/jqlzDwryTS8xCyDIuKnEfFw8Rq6IyIOLitPkenlFsuTIuI7ZeXpa6y7bWaqTN215nY40/CS81Sq7lpzy2XNbTNTZWpukce62/48w0vOY83VMlWquVC9umvNbVemStTclWQaXnKePlt3G/rBYSX5BHBr8f1LJWf5e2aOAYiI/YD/BvYqK0xEBPBzYHpmTijW7QwMAv63pFj1x+itwE+BDSn3325ZpgqpRKbiNXQ1tdfQJ4t1WwEHlplLpbPurkQF6641d/VUJpN1V62w5q5EBWsuWHdXR2XyWHPViirVXKhQ3bXmtj9ThVQmU1+vu716JG1ErA/sCUwGJpQcp6UNgedKzvDPwBuZ+f3mFZn558z8nxIzLZOZTwNTgM8W/1FVPfsAr7d4DT2Wmd8uMZNKZN1tU2XrrjW3x7DuahlrbpsqW3PButtDWHO1TMVrLpRfd6256gp9uu729pG044AbMvN/I+KZiHhHZt5VYp51ImI2sDYwmNqLr0w7AWUejzZl5sMR0Q94K7CwpBjN/27N/jszLyspS7P6TI9kZllD/3cE7i7puVel5b/ZJsC1JWXpa6y7q1bpumvNXamq1FyoZt215pbHmrtqla65YN1dCWvuqllzy1O1mgvVqrvW3NVTtZoL1t22NKzu9vYm7SeAc4vblxbLZRaN+qH27wYuioidMjNLzKS2VWbof50qZiIivkvtr8uvZ+Y7S4yy3PGJiElAU2lp+hbrrjqrivWtipmAytRda255rLnqClWrcVXLs4w1t8+rWs0F625PVMUaV8VMQN+ru722SRsRm1D7K9KoiEigH5ARcWIVClZm3hERmwEDgadLinE/ML6k514tEfE2YCnlHSOt2v3AvzQvZObRxet6VnmRVBbr7mqpdN215vYI1l0B1tzVVOmaC9bdHsCaK6D6NRcqUXetueoKfbru9uY5accDP8nMrTJzeGYOAx4B/qnkXABE7dMg+wHPlBjjJuAtETGleUVEjI6IqhyjgcD3ge9U5Y1PK7gJWDsijqxbt25ZYVQ6627bKlt3rbk9hnVXzay5batszQXrbg9hzVWzStdcqETdteaqK/TputtrR9JSu/TgjBbrrizW/6HxcYDl57EIYGJmLi0pC5mZEXEw8K2IOBl4FXgU+EJZmfjHMVoTWAL8BPhmiXlgxflHbsjMU8oKUyXFa+gg4JyIOAlYBCwGTi41mMpi3W1DBeuuNbeHse6qjjW3DRWsuWDd7VGsuapTxZoLFaq71tzVZs1dhb5ed8M/IEiSJEmSJElSeXrzdAeSJEmSJEmSVHk2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJUmSJEmSJKlENmmlOhFxf0TsvYrtv4qIiY1LJEm9U0R8PyL+YxXb/y0iftTITJLU20XElhHxckT0W8U+L0fE2xqZS5J6o4g4JCJ+s4rt/xQRf21kJlVbZGbZGdQLRcSjwCBgad3qaZn52XIStV9EfBnYJjMPLTuLJK3KSmrudpn5RDmJ2qf449jFmTm05CiStFoiYgJwLLATsBh4BJgOfC970C9YEXELtfrrH8UkVVJxnntEZv62bt2kYt2eZeXqiIhIYNvMnFt2FlWTI2nVnT6cmevXfa1WgzYi+nd3MEnqhVrW3DYbtNZbSWq/iDgeOBf4BrA5tT+SfQbYA1hrNe4fEeHvYZLUAJ7vqifx5ECli4gvR8SMiLg4Il4EJkXEgIiYGhFPRsSCiPhq82VZEdEvIs6OiL9FxCMR8dmIyObiGxFbRMS1EfFsRMyNiE+3eK7LI+KiiHipmN6gqW77oxHxvojYH/g34OPFJV9/LrbfEhFHFLfXiIh/j4jHIuLp4jEHFNuGF5kmRsTjRdbTGnZQJakVEbF3RMyPiJMj4ingx0UtOyUi/i8inilq5CZ19zmsqHPPRMR/NNfJYttbIuJbEfFE8fWtiHhLi+c6vqiRT0bE4XWPO62o7esBvwK2KOrty0Ud/3JEXFy3/4FFzX6+qMU71G17NCJOiIg5EfFCRFwWEWs34JBK6mOKc72vAEdl5ozMfClr7snMQzLztZXc75aI+FpE3Aa8ArwtIraPiBuLc9a/RsTH6vbfNCJ+EREvRsSdRb28tW77e4r1LxTf39Piuf4rIm4rznd/ExGbFduaz1H7R8TXgH8CvlPU3u8U+2REbNP88xbnuIuK94J/j6LBHBGTIuLWiDgrIp6L2nn5B7r6mEtSexV17OiIeAh4qFj3oYiYXZxL3h4Ro+v23zUi7ilq5hXFueRX67Z/Omq9hWej1mvYosVzfSYiHioe+7sREcW2Sc21OyL+UNzlz0XN/Xjz+XLdY+1Q1PDni/PeA+u2TSse+7oi58yIeHt3HUOVwyatqmIcMAPYCLgEmAYsAbYBdgHeDxxR7Ptp4APAGGBX4KAWj3UpMB/YAhgPfD0i9qnbfmCxz0bAtcB3WobJzBuArwOXFSPSdm4l86Ti65+BtwHrt/JYewIjgLHAF+ubCpJUks2BTYCtgCnAMdTq6F7U6uZzwHcBImIkcD5wCDAYGAAMqXus04DdqdXjnYF3Af/e4rma7zMZ+G5EbFwfJjMXU6vpT6xsFHBEbAf8DPgCMBC4HvhFRNSPWPsYsD+wNTCaWn2WpK72buAtwDUduO+nqNXdDYBFwI3AT4G3AhOA84u6C7U6vJhaHZ1YfAEQtT+kXQecB2wKfBO4LiI2rXuuTwKHF4+9FnBCyzCZeRrwP8BnV3HV27ep1fG3UXufOKx43Ga7AX8FNgPOBKY2NyckqWQHUatRIyNiF+BC4F+p1c0fANdGbcDBWsDPqfUgNqF2znlw84MUvYT/pnauORh4jFo/od6HgHdSOwf9GLBfyzCZ+d7i5s5Fzb2sfntErAn8AvgNtdp9DHBJRIyo220C8J/AxsBc4GurfTTUI9ikVXe6uvgLUPPXp1ex7x2ZeXVmvglsCBwAfCEzF2fm08A51AoS1IreuZk5PzOfA05vfpCIGEbtUrOTM/PVzJwN/IjaCWWzWzPz+sxcCvyEWmOhIw4BvpmZD2fmy8CpwIRY/nKK/8zMv2fmn4E/d+K5JKkt9TX36lXs9ybwpcx8LTP/Tu0S3dOKmvoa8GVgfFHLxgO/yMxbM/N14ItA/VyLhwBfycynM3MRtZPGT9Vtf6PY/kZmXg+8TO0PV+31ceC6zLwxM98AzgLWAd5Tt895mflEZj5L7QR3TAeeR5Lashnwt8xc0ryiGJH1fET8PSLeu4r7TsvM+4v77g88mpk/zswlmXkPcCXw0ahdPfYv1Gr1K5n5ALX5bpt9EHgoM39S3PdnwF+AD9ft8+PM/N+izl9OB2pikWMCcGoxYvhR4GyWr/OPZeYPi/Pq6dQaGIPa+1yS1IblegvUBhG05b8z89miDk4BfpCZMzNzaWZOB16jNthgd6A/tXPJNzLzKuBPdY9zCHBhZt5dnCufCrw7IobX7XN6Zj6fmY8DN9Ox89DdqQ38Oj0zX8/Mm4BfAp+o2+fnmfmn4n3kkg4+jyrMuTnUnQ6qn9y7DfPqbm8FrAk8WfeH+DXq9tmixf71t7cAns3Ml+rWPQY01S0/VXf7FWDtiOhff7K9mrYoHrv+efqz/Ilpy+dav53PIUmra3Vr7qLMfLVueSvg5xHxZt26pdRq2XL1NjNfiYhn6vZrrQ5uUbf8TIva2tE6uNzzZOabETGP5Uf1tqy39Tkkqas8A2xWf+6Yme8BKC5ZXdUgmJbnu7sVzYZm/akNIBhY3F7V+W597aVYXlVN7Ejt3YzaOXnLOt/q8xTvEXTwuSRpVZY7z43ig8PauE/LmjsxIo6pW7cWtXqawIIWH/rYsube3byQmS8X58NDgEeL1V1Rc7cA5hUD15p1R21XhTmSVlXRsiC+BmyWmRsVXxtm5o7F9ieB+k8AH1Z3+wlgk4jYoG7dlsCCTmZqzRPUin398ywBFnbguSSpUVrWtnnAB+rq7UaZuXZmLqBFvY2IdahdItastTrY5geWrUamlpZ7nuJS2mF0rLZLUmfcQe08dVwH7tvyfPf3LWrv+pl5JLWpEJaw6vPd+toL3XO++zdqV0S0rPPWXkk9Qcua+7UWNXfd4kqEJ4EhLaZqWWnNjdrnKWxK19fCJ4BhsfwHS1pz+xibtKqczHyS2jwsZ0fEhlH7UJu3R8RexS6XA5+PiCERsRFwct195wG3A/8dEWsXk4FPBi6m/RYCw2Pln777M+DYiNg6ItbnH3PYtndEriSV6fvA1yJiK4CIGBgRzc2HGcCHo/YBNWtRmwqh/gT2Z8C/F/fZjNp0CB2tt5tG8eGLrbgc+GBEjC3m6zqeWpPk9g48lyR1WGY+T21ql/MjYnxEbFCcq44B1mvHQ/0S2C4iPhURaxZf74yIHYqpA64CvhwR60bE9iw/ddf1xX0/GbUPAPs4MLJ4zPZaSG2+2RUUOS6n9h6xQfE+cRwdq/OSVKYfAp+JiN2iZr2I+GAxuOsOaleRfbaoqeOofc5Cs58Bh0fEmKh9QO7XgZnFFDDttdKaC8ykNjr2pOI9YW9q09i0nP9WvZhNWnWnX8Q/Pqn75Yj4eTvuexi1yw8eoPYhNjOozXEFtQL7G2AOcA+1E9Ul1Aor1OZsGU7tL1E/pzaf1+pOu1DviuL7MxFxdyvbL6R2SdofgEeAV6lN7i1JPcm51D5E8TcR8RLwR2ofskBm3k+trl1KbZTBy8DT1BqkAF8FZlGrx/dSuxTsq7RTZv6F2gnww8VcY1u02P5X4FBqH2DzN2onrB8u5smVpIbKzDOpNStPovYL90JqH0JzMqv5x6Niaq73U5vz9Qlql7CeQe1DyQA+S+0Du56idr75M4ram5nPUPuQmuOpTb9wEvChzPxbB36cc6nNQ/5cRJzXyvZjqH2A2cPArdQ+6OzCDjyPJJUmM2dR+wDy71DrL8yl+JDZ4nzyI9QGdz1P7Zzzl/yj5v4W+A9q84Y/Cbydf3xeTnt9GZhenO9+rEXG16md436A2vnu+cBhxXmy+ohYftoNqeeJiA8A38/Mlpd9SZK6UHHVwPPAtpn5SMlxJKnPiIgzgM0zc2LZWSSpt4uImdR6DD8uO4v6FkfSqseJiHUi4oDiUoQhwJeojZiVJHWxiPhwcbntesBZ1EbMPlpuKknq3SJi+4gYXVyW+y5qI7w835WkbhARe0XE5kWPYSIwGrih7Fzqe2zSqicKanOBPUdtuoMHqc2DKEnqeuOoXYr7BLAtMCG9DEeSutsG1OalXQxcBpwNXFNqIknqvUYAf6Z2xdjxwPjis3KkhnK6A0mSJEmSJEkqkSNpJUmSJEmSJKlE/csOsCqbbbZZDh8+vOwYkvq4u+6662+ZObDsHI1g3ZVUBX2l7lpzJVWBNVeSGmtldbfSTdrhw4cza9assmNI6uMi4rGyMzSKdVdSFfSVumvNlVQF1lxJaqyV1V2nO5AK3//+99lpp50YOXIkRx11FEuXLiUz+dznPseOO+7IDjvswJFHHsnSpUsBuP/++3nve9/L6NGj2WOPPfjf//3fkn8CSVJHtfc9YMmSJRx++OFss802jBw5kt///vcl/wSSpM5o7X3g//7v/3jve9/Leuutx6RJk5bb/5//+Z8ZM2YMY8aM4e1vfzsbb7xxOcElSV2itfeBF198kY9//OOMGjWKUaNGce211y7bf9KkSWy55ZbL3gsuuuiiTmewSStRa7h+4xvf4LbbbuOBBx4gIrjkkku48cYbueuuu5gzZw733Xcfs2fP5oYbbgDg//2//8cJJ5zAnDlz+OY3v8mRRx5Z8k8hSeqIjrwHTJs2jcWLFzN37lwuu+wyDj/8cN58882SfxJJUkes7H1go4024owzzuDss89e4T4333wzs2fPZvbs2XzqU5/iYx/7WAnJJUldYWXvA1/72tcYMmQI9957L7///e859dRTefnll5fd7ytf+cqy94LDDjus0zls0krAAw88QFNTEwMGDABgv/3247LLLmONNdbg1Vdf5fXXX+e1117j9ddfZ/PNNwfgvvvuY9999wVgt912Y/bs2SxatKi0n0G9R0RcGBFPR8R9des2iYgbI+Kh4vvGxfqIiPMiYm5EzImIXevuM7HY/6GImFjGzyL1BB15D7jyyis54ogjABg1ahSDBg3yEkpJ6qFW9j6w6aab8u53v5u11157lfe/+OKLu+SXc0lSOVb2PlDf99lkk00YMWIEv/rVr7oth01aCRg9ejR33HEHTz75JEuXLuWKK65g3rx5jB07lr322ovBgwezxRZbsPfee/OOd7wDgF122YXLLrsMgF//+tc8++yzzJs3r8wfQ73HNGD/FutOAX6XmdsCvyuWAT4AbFt8TQG+B7WmLvAlYDfgXcCXmhu7kpbXkfeA+fPnM2zYsGWPseWWW/oeIEk91MreB1bH7bffDsAee+zRnRElSd1oZe8Du+yyCzNmzODNN99k3rx53Hbbbcu9P3z1q19l9OjRfOpTn+Kpp57qdI42m7SO6FJfMGLECL7+9a/z4Q9/mD333JMtt9ySfv36cddddzFv3jyefPJJnnzySebMmcOMGTOA2qWuM2bMYNddd+Wqq65ixx13pF+/fiX/JOoNMvMPwLMtVo8Dphe3pwMH1a2/KGv+CGwUEYOB/YAbM/PZzHwOuJEVG7+S6Nh7QGaWnFqS1FVW9j6wOn7yk59w6KGHdnNCSVJ3Wtn7wKmnnkr//v3Zdddd+cxnPsNee+217P3h61//Og899BCzZ89m5MiRTJzY+Vbn6oyknYYjutQHHHroocyaNYs77riDMWPGsP322zNt2jT22Wcf1llnHdZZZx0OPvhgbr75ZgC22WYbfvnLX3L33Xfz7W9/m0WLFvH2t7+95J9CvdigzHyyuP0UMKi4PQSoH+oxv1i3svUriIgpETErImY5ZYf6qva+BwwbNmy5v6I//vjjDB06tKz4kqROau19oC2vv/46V1xxhVMdtIODwCRVVWvvA+uttx4/+MEPmD17Ntdddx2LFy9e9v6wxRZbEBGsscYaHHPMMcuurOiMNpu0juhSX7Fw4UIAXnjhBc4880yOOeYYttpqK26++WbefPNNli5dym9/+1tGjhwJwNNPP73svt/4xjcYN24c66+/finZ1bdkbQhflw3jy8wLMrMpM5sGDhzYVQ8r9SjtfQ/4yEc+wtSpUwG49957eeqpp3jnO99ZWn5JUue09j7Qluuuu47tt9+et73tbd0drzeZhoPAJFVQa+8DL7zwAq+99hoAf/jDH3j88ceXzVH7xBNPLLvvZZddxujRozudoX8H79etI7qoFWC23HLLDsaT2m/ChAksXLiQzOTEE0/kPe95D2PGjOHTn/40O+20ExHBu9/9bqZMmQLAFVdcwbe+9S0igt13353zzz+/5J9AvdzCiBicmU8Wf/xq/ivBAmBY3X5Di3ULgL1brL+lATmlHqm97wGTJk3i1ltv5e1vfztrrbUWF154IWus4VT/ktRTtfY+8OKLLzJy5EheeeUVXnvtNX77298ydepU9ttvP6A21YGjaNsnM/8QEcNbrB7HP85bp1M7Zz2ZukFgwB8jonkQ2N4Ug8AAIqJ5ENjPuju/pN6rtfeBP/3pTxxyyCH079+fQYMGMWPGjGXn/IcddhgLFy4kIhg8eDDTpk3rdIaONmmXycyMiC4d0QVcANDU1OSEb2qY5ktY66277rpccsklre5/9NFHc/TRR3d3LKnZtcBE4PTi+zV16z8bEZdSG03wQtHI/TXw9bpRBe8HTm1wZqnHaO97wJprrsn06dNb3SZJ6nlaex/YcMMNmT9//krvc9VVV3VnpL7EQWCSStfa+8C73vUuHnrooVb3/+1vf9vlGTrapHVEl3qsr582o+HP+W9fG9/w51TPFRE/o1YzN4uI+dQu5zoduDwiJgOPAR8rdr8eOACYC7wCHA6Qmc9GxH8Bdxb7faV5tIHUl33z1H9t+HMe998/aPhzSpJa9+fzb2n4c+581N4Nf86eykFgkrrb2Wef3fDnPP7441drv442aR3RJUndJDM/sZJNY1vZN4FWh3Rn5oXAhV0YTZIkSepqDgKTJFbjg8OKEV13ACMiYn4xiut0YN+IeAh4X7EMtRFdD1Mb0fVD4CiojegCmkd03YkjuiRJkiRJ0j8GgcGKg8AOi5rdKQaBAb8G3h8RGxcDwd5frJOkHq3NkbSO6JIkSZIkSZ3ltF6StHKd/uAwSZIkSZKktjgITJJWrs3pDiRJkiRJkiRJ3ccmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmS1IqIODYi7o+I+yLiZxGxdkRsHREzI2JuRFwWEWsV+76lWJ5bbB9ecnxJkiT1IDZpJUmSpBYiYgjwOaApM3cC+gETgDOAczJzG+A5YHJxl8nAc8X6c4r9JEmSpNVik1aSJElqXX9gnYjoD6wLPAnsA8wotk8HDipujyuWKbaPjYhoXFRJkiT1ZDZpJUmSpBYycwFwFvA4tebsC8BdwPOZuaTYbT4wpLg9BJhX3HdJsf+mLR83IqZExKyImLVo0aLu/SEkSZLUY9iklSRJklqIiI2pjY7dGtgCWA/Yv7OPm5kXZGZTZjYNHDiwsw8nSZKkXsImrSRJkrSi9wGPZOaizHwDuArYA9iomP4AYCiwoLi9ABgGUGwfADzT2MiSJEnqqWzSSpIkSSt6HNg9ItYt5pYdCzwA3AyML/aZCFxT3L62WKbYflNmZgPzSpIkqQezSStJkiS1kJkzqX0A2N3AvdTOmy8ATgaOi4i51OacnVrcZSqwabH+OOCUhoeWJElSj9W/7V0kSZKkviczvwR8qcXqh4F3tbLvq8BHG5FLkiRJvY8jaSVJkiRJkiSpRDZpJUmSJEmSJKlENmklSZIkSZIkqUQ2aSVJkiRJkiSpRDZpJakHiYhjI+L+iLgvIn4WEWtHxNYRMTMi5kbEZRGxVrHvW4rlucX24SXHlyRJkiRJrehUk9ZmgSQ1TkQMAT4HNGXmTkA/YAJwBnBOZm4DPAdMLu4yGXiuWH9OsZ8kSZIkSaqYDjdpbRZIUin6A+tERH9gXeBJYB9gRrF9OnBQcXtcsUyxfWxEROOiSpIkSZKk1dHZ6Q5sFkhSg2TmAuAs4HFq9fYF4C7g+cxcUuw2HxhS3B4CzCvuu6TYf9OWjxsRUyJiVkTMWrRoUff+EJIkSVIrvFJXUl/X4SatzQJJaqyI2JjaH7y2BrYA1gP27+zjZuYFmdmUmU0DBw7s7MNJkiRJ7eKVupLUuekObBZIUmO9D3gkMxdl5hvAVcAewEbFFQ0AQ4EFxe0FwDCAYvsA4JnGRpYkSZJWi1fqSurTOjPdgc0CSWqsx4HdI2Ld4iR0LPAAcDMwvthnInBNcfvaYpli+02ZmQ3MK0mSJLXJK3UlqXNNWpsFktRAmTmT2kiBu4F7qdXwC4CTgeMiYi61k9OpxV2mApsW648DTml4aEmSJKkNXqkrSbXLCTokM2dGRHOzYAlwD7VmwXXApRHx1WJdfbPgJ0Wz4Flq88tIktohM78EfKnF6oeBd7Wy76vARxuRS5IkSeqEZVfqAkTEclfqFqNlW7tSd75X6krqLTrcpAWbBZIkSZIkqdOWXakL/J3albqz+MeVupfS+pW6d+CVupJ6ic5MdyBJkiRJktQpTuslSZ0cSStJkiRJktRZXqkrqa9zJK0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmSJEmSJJXIJq0kSZIkSZIklcgmrSRJkiRJkiSVyCatJEmS1IqI2CgiZkTEXyLiwYh4d0RsEhE3RsRDxfeNi30jIs6LiLkRMScidi07vyRJknoOm7SSJElS684FbsjM7YGdgQeBU4DfZea2wO+KZYAPANsWX1OA7zU+riRJknoqm7SSJElSCxExAHgvMBUgM1/PzOeBccD0YrfpwEHF7XHARVnzR2CjiBjc0NCSJEnqsWzSSpIkSSvaGlgE/Dgi7omIH0XEesCgzHyy2OcpYFBxewgwr+7+84t1y4mIKRExKyJmLVq0qBvjS5IkqSexSStJkiStqD+wK/C9zNwFWMw/pjYAIDMTyPY8aGZekJlNmdk0cODALgsrSZKkns0mrSRJkrSi+cD8zJxZLM+g1rRd2DyNQfH96WL7AmBY3f2HFuskSZKkNtmklSRJklrIzKeAeRExolg1FngAuBaYWKybCFxT3L4WOCxqdgdeqJsWQZIkSVql/mUHkCRJkirqGOCSiFgLeBg4nNogh8sjYjLwGPCxYt/rgQOAucArxb6SJEnSarFJK0mSJLUiM2cDTa1sGtvKvgkc3d2ZJEmS1Ds53YEkSZIkSZIklcgmrST1IBGxUUTMiIi/RMSDEfHuiNgkIm6MiIeK7xsX+0ZEnBcRcyNiTkTsWnZ+SZIkSZK0ok41aW0WSFLDnQvckJnbAzsDDwKnAL/LzG2B3xXLAB8Ati2+pgDfa3xcSZIkSZLUls6OpLVZIEkNEhEDgPcCUwEy8/XMfB4YB0wvdpsOHFTcHgdclDV/BDaKiMENDS1JkiStBgeBSerrOtyktVkgSQ23NbAI+HFE3BMRP4qI9YBBmflksc9TwKDi9hBgXt395xfrlhMRUyJiVkTMWrRoUTfGlyRJklbKQWCS+rTOjKS1WSBJjdUf2BX4XmbuAizmHyeqwLJPF8/2PGhmXpCZTZnZNHDgwC4LK0mSJK0OB4FJUueatDYLJKmx5gPzM3NmsTyDWh1e2HxSWnx/uti+ABhWd/+hxTpJkiSpShwEJqnP60yT1maBJDVQZj4FzIuIEcWqscADwLXAxGLdROCa4va1wGHFnF27Ay/UneRKkiRJVeEgMEl9XoebtDYLJKkUxwCXRMQcYAzwdeB0YN+IeAh4X7EMcD3wMDAX+CFwVMPTSpIkSW1zEJikPq9/J+/f3CxYi1oj4HBqjd/LI2Iy8BjwsWLf64EDqDULXin2lSS1Q2bOBppa2TS2lX0TOLq7M0mSJEmdkZlPRcS8iBiRmX/lH4PAHqA2+Ot0VhwE9tmIuBTYDQeBSeoFOtWktVkgSZIkSZK6gIPAJPVpnR1JK0mSJEmS1CkOApPU13Xmg8MkSZIkSZIkSZ1kk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJkiRJkkpkk1aSJEmSJEmSSmSTVpIkSZIkSZJKZJNWkiRJWomI6BcR90TEL4vlrSNiZkTMjYjLImKtYv1biuW5xfbhpQaXJElSj2KTVpIkSVq5zwMP1i2fAZyTmdsAzwGTi/WTgeeK9ecU+0mSJEmrxSatJEmS1IqIGAp8EPhRsRzAPsCMYpfpwEHF7XHFMsX2scX+kiRJUpts0kqSJEmt+xZwEvBmsbwp8HxmLimW5wNDittDgHkAxfYXiv2XExFTImJWRMxatGhRN0aXJElST2KTVpIkSWohIj4EPJ2Zd3Xl42bmBZnZlJlNAwcO7MqHliRJUg/Wv+wAkiRJUgXtARwYEQcAawMbAucCG0VE/2K07FBgQbH/AmAYMD8i+gMDgGcaH1uSJEk9kSNpJUmSpBYy89TMHJqZw4EJwE2ZeQhwMzC+2G0icE1x+9pimWL7TZmZDYwsSZKkHswmrST1IBHRLyLuiYhfFstbR8TMiJgbEZdFxFrF+rcUy3OL7cNLDS5JvcfJwHERMZfanLNTi/VTgU2L9ccBp5SUT5IkST1Qp5u0NgwkqaE+DzxYt3wGcE5mbgM8B0wu1k8GnivWn1PsJ0nqgMy8JTM/VNx+ODPflZnbZOZHM/O1Yv2rxfI2xfaHy00tST2P/QVJfVlXjKS1YSBJDRARQ4EPAj8qlgPYB5hR7DIdOKi4Pa5Yptg+tthfkiRJqir7C5L6rE41aW0YSFJDfQs4CXizWN4UeL748BqA+cCQ4vYQYB5Asf2FYv8VRMSUiJgVEbMWLVrUTdElSZKklbO/IKmv6+xI2m/RxQ0DmwWStKKI+BDwdGbe1dWPnZkXZGZTZjYNHDiwqx9ekiRJWh3fwv6CpD6sw03a7moY2CyQpFbtARwYEY8Cl1IbVXAusFFE9C/2GQosKG4vAIYBFNsHAM80MrAkSZK0OuwvSFLnRtLaMJCkBsnMUzNzaGYOByYAN2XmIcDNwPhit4nANcXta4tliu03ZWY2MLIkSZK0uuwvSOrzOtyktWEgSZVwMnBcRMyldonX1GL9VGDTYv1xwCkl5ZMkSZJWyf6CJEH/tndpt5OBSyPiq8A9LN8w+EnRMHiWWuGVJLVTZt4C3FLcfhh4Vyv7vAp8tKHBJEmSpK5lf0FSn9ElTVobBpIkSZIkqbPsL0jqqzozJ60kSZIkSZIkqZNs0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEmSJElSiWzSSpIkSZIkSVKJbNJKkiRJkiRJUols0kqSJEktRMSwiLg5Ih6IiPsj4vPF+k0i4saIeKj4vnGxPiLivIiYGxFzImLXcn8CSZIk9SQ2aSVJkqQVLQGOz8yRwO7A0RExEjgF+F1mbgv8rlgG+ACwbfE1Bfhe4yNLkiSpp7JJK0mSJLWQmU9m5t3F7ZeAB4EhwDhgerHbdOCg4vY44KKs+SOwUUQMbmxqSZIk9VQ2aSVJkqRViIjhwC7ATGBQZj5ZbHoKGFTcHgLMq7vb/GJdy8eaEhGzImLWokWLui+0JEmSepQON2mdp0uSGsu6K0mNFxHrA1cCX8jMF+u3ZWYC2Z7Hy8wLMrMpM5sGDhzYhUklqefyPFeSOjeS1nm6JKmxrLuS1EARsSa1Bu0lmXlVsXph8zQGxfeni/ULgGF1dx9arJMktc3zXEl9XoebtM7TJUmNZd2VpMaJiACmAg9m5jfrNl0LTCxuTwSuqVt/WDG6a3fghbppESRJq+B5riR10Zy0ztMlSY1l3ZWkbrcH8Clgn4iYXXwdAJwO7BsRDwHvK5YBrgceBuYCPwSOKiGzJPV4nudK6qv6d/YBWs7TVRt0UJOZGRHtnqcLuACgqampXfeVpL7AuitJ3S8zbwViJZvHtrJ/Akd3ayhJ6uU8z5XUl3VqJK3zdElSY1l3JUmS1Bt5niupr+twk9Z5uiSpsay7kiRJ6o08z5Wkzk130DxP170RMbtY92/U5uW6PCImA48BHyu2XQ8cQG2erleAwzvx3JLUF1l3JUmS1Bt5niupz+twk9Z5uiSpsay7kiRJ6o08z5WkTs5JK0mSJEmSJEnqHJu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVCKbtJIkSZIkSZJUIpu0kiRJkiRJklQim7SSJEmSJEmSVKL+ZQeQJEmSpK4yfPhw1l13XdZaay0AfvrTn/LrX/+a6dOnL9vn/vvvZ8aMGYwbN66smJIkScuxSStJkiSpV7n++usZPnz4suWRI0dy7LHHAvDII4+w6667st9++5WUTpIkaUVOdyBJkiSpz7j44osZP348a6+9dtlRJEmSlrFJK0mSJKlXOeigg9h555057bTTeOONN5bbdvHFF3PYYYeVlEySJKl1NmklSZIk9Rq33nors2fP5rbbbuOBBx7grLPOWrZt5syZvPHGG+y5554lJpQkSVqRTVpJkiRJvcbQoUMBWH/99Zk8eTK33377sm0/+clPOPTQQ4mIsuJJkiS1yg8OkyRJktQrLF68mKVLl7LhhhuyZMkSrrzySkaPHg3AG2+8wWWXXcYdd9xRckpJkqQV2aSVJEmS1CssXLiQj3zkI7z55pssXbqUd7/73Zx22mkA/OpXv2Lbbbdlm222KTmlJEnSimzSSpIkSeoV3va2tzF79uxWtx144IEceOCBjQ0kSZK0mmzSSpIkSaq8ST/+fCnPO+3wc0t53u4yb948Jk2axBNPPMEaa6zBBz/4Qc4444xl8/Q+//zz7Ljjjuy7775Mmzat3LCSJPUhfnCYJEl9yLx58xg7diw77LADO+64IyeddBKZCcC5557LNttswzbbbMN5551XclJJUnfo378/Z5xxBg8++CD33HMPM2fO5Kqrrlq2/aSTTmKfffYpMaEkSX2TI2klSepDmn85b2pq4vXXX2ffffflqquuYvTo0XznO9/hnnvuAWDXXXflgAMOcO5GSeplBg8ezODBgwFYa621GD16NPPmzQPg5ptv5rXXXmPs2LHccsstJaaUJKnvcSStJEl9yODBg2lqagKW/+X8qquu4qMf/SgbbLABG2ywAePHj19uZJUkqfd55plnuPrqq9lvv/34+9//zqmnnspZZ51VdixJkvokm7SSeqXFixczadIkRowYwY477sj5559fdiSpcup/OZ8/fz7Dhg1btm3LLbdcNrJKktT7vPbaa4wfP54vfOEL7LDDDnz5y19mypQpDBw4sOxokiT1SU53IPUwbX3Yg2qOP/54tttuu2UfePH000+XG0iqmJa/nDfPSytJ6v2WLl3KIYccwi677MLxxx8PwO23385ll13GV77yFV5++WVeffVVMpPp06eXnFb1/F1Aap/hw4ez7rrrstZaawHw05/+lJEjR5acSmpdrx5Je+SRRzJkyJBKvWHdd9997Lrrrmy77bYceOCBvPTSS6XmqeIxqmKmKmnrwx7KULXX9UsvvcTVV1/NiSeeuGzdW9/61hIT9R1Vey1UMVMV8rT2y/mwYcOWGzn7+OOPM3To0IZng2oco6qr2jGqWp6+pGrHvmp5qqgKx+hf//Vf2WCDDTj77LOXrfuf//kfHn30UR599FHOOussxo8fX1qDtgrHqKqq+LtAX1K112bV8lQ10/XXX8/s2bOZPXt2JRq0VTtG5qmOXt2k/cQnPsHdd99ddozlfOYzn+GrX/0qDz30ENtvvz1nnnlmqXmqeIyqmKlKVjafZJmq9rp++OGHGThwIJ///OfZddddGTduHI8++mipmfqKqr0WqpipCnla++X84IMP5oorruCll17ipZde4oorruDggw9ueDaoxjGquqodo6rl6UuqduyrlqeKyj5Gt912G1OnTmXWrFnssssujBkzhvPOO6+hGdpS9jGqsir+LtCXVO21WbU8Vc1UNVU7Ruapjl7dpH3ve9/LoEGDyo6xzMKFC3nkkUc44IADAJg8eTJXXnllqZmqdoygmpmqqn4+ybJU8XW9ZMkS7rvvPsaNG8fdd9/NuHHjmDhxYqmZ+oIqvhaqlqkKeVb2y/l2223HUUcdxZgxYxgzZgyf/exn2W677RqaDapxjKquaseoann6kqod+6rlqaIqHKM99tiDzOTee+9dNrLsc5/73HL7TJo0admUUY1WhWPUU1Thd4G+pGqvzarlqWomgIMOOoidd96Z0047jTfeeKPULFU7RuapFuekbaD58+cvd+moH8qizmg5n2RZqvi6Hjp0KAMGDFh2wjphwoQVfvlQ16via6FqmaqQp/mX89Yce+yxHHvssQ3N01IVjlHVVe0YVS1PX1K1Y1+1PFXU3cfo66fN6LLHWl3/9rXxXfp4vo5WT1V+F+hLqvbarFoeqGamW2+9laFDh/Lyyy/zqU99irPOOotTTz21tDxVO0bmqRabtA3kh7Koq7Q2n2RZqvi6HjRoEKNHj+bOO+/kne98JzfeeCOjRo0qO1avV8XXQtUydXee6w87vFsff2UOuOjHXfZYVfs3q6KqHaOq5elLqnbsq5anijxGbfMYta1Kvwv0JVV7bVYtD1QzU3PDb/3112fy5Mn84Ac/KDVP1Y6RearFJm0DDR06lPnz5y9bLvNDWdSztTafZFmq+rr+/ve/zxFHHMHixYsZMGAAF154YdmRer0qvhaqlqlqearIY9S2qh2jquXpS6p27KuWp4o8Rm3zGLWtSr8L9CVVe21WLQ9UL9PixYtZunQpG264IUuWLOHKK69k9OjRpeWB6h0j81RLw+ekjYj9I+KvETE3Ik5p9POXafPNN2f48OFcf/31AEydOpWPfOQjJadST1O1D3uo6ut65MiR3H777fz5z3/mD3/4Q5+9DKyRNbeKr4WqZapaniryGLWtaseoannK1Ojz3Kod+6rlqSKPUds8RqtWtd8FytaXz3WrlqeKmRYuXMh73/teRo8ezc4770y/fv047bTTSssD1TtG5qmWaORQ4ojoB/wvsC8wH7gT+ERmPtDa/k1NTTlr1qwOP98RRxzBDTfcwIIFCxgyZAj7778/P/rRjzr8eF1hzpw5TJw4kZdffpkRI0ZwySWXMGDAgNLyVPEYdXem3jBXV9V09+u6jFEC9ZeORcRdmdnU8BCd1N6aC52vu1WrcVXM1J15esN0B9C9x+ibp/5rlzxOexz3311/WV1vf133xLpbRs2F3v9aqDfpx5/vksdpr2mHn9ulj9edx6i3nOd25zH68/m3dMnjtMfOR+3d8Odsj55Yc6Hx/QXoWzW3N2Wqmqodo76Wp+z+Aqy87jZ6uoN3AXMz8+Ei1KXAOGClJ6+dUXazsTWjR4/mnnvuKTvGMlU8RlXM1J16Q8Ogaq9rLdPQmgvVfC1ULVPV8lSRx6htVTtGVctTkobXXKjesa9aniryGLWtLx2jsqYs6CVz2fb5c92q5YHuzVTGgISuHowA1ft3M091NHok7Xhg/8w8olj+FLBbZn62bp8pwJRicQTw1y56+s2Av3XRY3UF87StapnM07aqZeqqPFtl5sAueJyGWp2aW6zvjrrbW18LXalqmczTtqplqloe6MN115q7gqplMk/bqpapanmgepn6bM0F+wstmKdtVctUtTxQvUy9OU+rdbdyHxyWmRcAF3T140bErCpdwmGetlUtk3naVrVMVctTVd1Rd6t27KuWB6qXyTxtq1qmquWBamaqmr5Qc6F6mczTtqplqloeqF6mquWpIvsL5ahaHqhepqrlgepl6ot5Gv3BYQuAYXXLQ4t1kqSuZ82VpMax5kpSY1l3JfUqjW7S3glsGxFbR8RawATg2gZnkKS+wporSY1jzZWkxrLuSupVGjrdQWYuiYjPAr8G+gEXZub9DXr6Lr/EoZPM07aqZTJP26qWqWp5Gsqau5yq5YHqZTJP26qWqWp5oJqZGsKau4KqZTJP26qWqWp5oHqZqpanoay7yzFP26qWqWp5oHqZ+lyehn5wmCRJkiRJkiRpeY2e7kCSJEmSJEmSVMcmrSRJkiRJkiSVqNc3aSPioIjIiNi+AlmWRsTsiPhzRNwdEe+pQKbNI+LSiPi/iLgrIq6PiO1KzNN8jO4vjtPxEVHq67QuU/PXKWXmWUmm4SVmGRQRP42Ih4vX0B0RcXBZeYpML7dYnhQR3ykrT19j3W0zU2XqrjW3w5mGl5ynUnXXmlsua26bmSpTc4s81t325xlech5rrpapUs2F6tVda267MlWi5q4k0/CS8/TZutvQDw4rySeAW4vvXyo5y98zcwxAROwH/DewV1lhIiKAnwPTM3NCsW5nYBDwvyXFqj9GbwV+CmxIuf92yzJVSCUyFa+hq6m9hj5ZrNsKOLDMXCqddXclKlh3rbmrpzKZrLtqhTV3JSpYc8G6uzoqk8eaq1ZUqeZChequNbf9mSqkMpn6et3t1SNpI2J9YE9gMjCh5DgtbQg8V3KGfwbeyMzvN6/IzD9n5v+UmGmZzHwamAJ8tviPqurZB3i9xWvoscz8domZVCLrbpsqW3etuT2GdVfLWHPbVNmaC9bdHsKaq2UqXnOh/LprzVVX6NN1t7ePpB0H3JCZ/xsRz0TEOzLzrhLzrBMRs4G1gcHUXnxl2gko83i0KTMfjoh+wFuBhSXFaP53a/bfmXlZSVma1Wd6JDPLGvq/I3B3Sc+9Ki3/zTYBri0pS19j3V21Stdda+5KVaXmQjXrrjW3PNbcVat0zQXr7kpYc1fNmlueqtVcqFbdteaunqrVXLDutqVhdbe3N2k/AZxb3L60WC6zaNQPtX83cFFE7JSZWWImta0yQ//rVDETEfFdan9dfj0z31lilOWOT0RMAppKS9O3WHfVWVWsb1XMBFSm7lpzy2PNVVeoWo2rWp5lrLl9XtVqLlh3e6Iq1rgqZgL6Xt3ttU3aiNiE2l+RRkVEAv2AjIgTq1CwMvOOiNgMGAg8XVKM+4HxJT33aomItwFLKe8YadXuB/6leSEzjy5e17PKi6SyWHdXS6XrrjW3R7DuCrDmrqZK11yw7vYA1lwB1a+5UIm6a81VV+jTdbc3z0k7HvhJZm6VmcMzcxjwCPBPJecCIGqfBtkPeKbEGDcBb4mIKc0rImJ0RFTlGA0Evg98pypvfFrBTcDaEXFk3bp1ywqj0ll321bZumvN7TGsu2pmzW1bZWsuWHd7CGuumlW65kIl6q41V12hT9fdXjuSltqlB2e0WHdlsf4PjY8DLD+PRQATM3NpSVnIzIyIg4FvRcTJwKvAo8AXysrEP47RmsAS4CfAN0vMAyvOP3JDZp5SVpgqKV5DBwHnRMRJwCJgMXByqcFUFutuGypYd625PYx1V3WsuW2oYM0F626PYs1VnSrWXKhQ3bXmrjZr7ir09bob/gFBkiRJkiRJksrTm6c7kCRJkiRJkqTKs0krSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEklskkrSZIkSZIkSSWySStJkiRJkiRJJbJJK0mSJEmSJEkl+v+QxBQdm3BoGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1728x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "current_palette = sns.color_palette()\n",
    "#dict1 = pd.DataFrame(pd.Series(f1),columns=[\"numbers\"],index=[\"fire\",\"soil\",\"water\",\"wood\",\"gas\",\"sky\",\"human\",\"life\"])\n",
    "x=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]\n",
    "dict1=pd.Series(one1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict1=dict1.fillna(0)\n",
    "dict2=pd.Series(two1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict2=dict2.fillna(0)\n",
    "dict3=pd.Series(three1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict3=dict3.fillna(0)\n",
    "dict4=pd.Series(four1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict4=dict4.fillna(0)\n",
    "#dict4[np.squeeze(np.argwhere(np.isnan(dict4)))]=0\n",
    "dict5=pd.Series(five1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict5=dict5.fillna(0)\n",
    "#dict5[np.squeeze(np.argwhere(np.isnan(dict5)))]=0\n",
    "dict6=pd.Series(six1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict6=dict6.fillna(0)\n",
    "#dict6[np.squeeze(np.argwhere(np.isnan(dict6)))]=0\n",
    "dict7=pd.Series(seven1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict7=dict7.fillna(0)\n",
    "#dict7[np.squeeze(np.argwhere(np.isnan(dict7)))]=0\n",
    "dict8=pd.Series(eight1).reindex([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"])\n",
    "dict8=dict8.fillna(0)\n",
    "#dict8[np.squeeze(np.argwhere(np.isnan(dict8)))]=0\n",
    "plt.figure(figsize=(24,10))\n",
    "plt.subplot(241)\n",
    "#plt.bar(x,dict1,color=\"red\")\n",
    "sns.barplot(x,dict1,palette=\"deep\")\n",
    "plt.title(\"A regonition\")\n",
    "for i,j in zip(range(8), dict1):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(242)\n",
    "sns.barplot(x,dict2,palette=\"deep\")\n",
    "plt.title(\"B regonition\")\n",
    "for i,j in zip(range(8), dict2):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict2)\n",
    "plt.subplot(243)\n",
    "sns.barplot(x,dict3,palette=\"deep\")\n",
    "plt.title(\"C regonition\")\n",
    "for i,j in zip(range(8), dict3):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(244)\n",
    "sns.barplot(x,dict4,palette=\"deep\")\n",
    "plt.title(\"D regonition\")\n",
    "for i,j in zip(range(8), dict4):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(245)\n",
    "sns.barplot(x,dict5,palette=\"deep\")\n",
    "plt.title(\"E regonition\")\n",
    "for i,j in zip(range(8), dict5):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(246)\n",
    "sns.barplot(x,dict6,palette=\"deep\")\n",
    "plt.title(\"F regonition\")\n",
    "for i,j in zip(range(8), dict6):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(247)\n",
    "sns.barplot(x,dict7,palette=\"deep\")\n",
    "plt.title(\"G regonition\")\n",
    "for i,j in zip(range(8), dict7):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "plt.subplot(248)\n",
    "sns.barplot(x,dict8,palette=\"deep\")\n",
    "plt.title(\"H regonition\")\n",
    "for i,j in zip(range(8), dict8):\n",
    "        plt.text(i, j, str(int(j)), ha='center', va='bottom', fontsize=10.5)\n",
    "#print(dict1)\n",
    "#list1=dict1.values.tolist()\n",
    "#plt.savefig(\"regonition.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
